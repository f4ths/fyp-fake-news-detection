{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743ddb1b-5ec9-42eb-b6b2-3a6513737bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "\n",
    "# from nltk import word_tokenize, sent_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6592a06-c79b-408c-bb60-ce11f2c6241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\fatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3ff5a7-07ee-4175-a03a-b7d9be841ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f22002-edb2-4591-9303-b13272354e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fafb128-0588-4ab7-a78a-f58fd11270d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column titles and label maps\n",
    "columns = ['id','label','statement','subject','speaker','job title','state info','party','barely true','false','half-true','mostly-true','pants-on-fire','context']\n",
    "label_map = {'pants-fire':-3, 'false':-2, 'barely-true':-1, 'half-true':1, 'mostly-true':2, 'true':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6d5ffb3-4246-4dc9-a0e5-4b0ea2786482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           id        label                                          statement  \\\n0   2635.json        false  Says the Annies List political group supports ...   \n1  10540.json    half-true  When did the decline of coal start? It started...   \n2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n3   1123.json        false  Health care reform legislation is likely to ma...   \n4   9028.json    half-true  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n  state info       party  barely true  false  half-true  mostly-true  \\\n0      Texas  republican          0.0    1.0        0.0          0.0   \n1   Virginia    democrat          0.0    0.0        1.0          1.0   \n2   Illinois    democrat         70.0   71.0      160.0        163.0   \n3        NaN        none          7.0   19.0        3.0          5.0   \n4    Florida    democrat         15.0    9.0       20.0         19.0   \n\n   pants-on-fire              context  \n0            0.0             a mailer  \n1            0.0      a floor speech.  \n2            9.0               Denver  \n3           44.0       a news release  \n4            2.0  an interview on CNN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>a mailer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>a floor speech.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>Denver</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>a news release</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>an interview on CNN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset files as pandas dataframes\n",
    "train_data = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
    "val_data = pd.read_csv('valid.tsv', sep='\\t', header=None, names=columns)\n",
    "test_data = pd.read_csv('test.tsv', sep='\\t', header=None, names=columns)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "beebe2c5-e116-43f5-8b0b-1838d1117c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbc8de-971a-4c43-b12d-4f7c5183d41e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sunday 12 March\n",
    "\n",
    "TO DO FOR the WEEK: <br>\n",
    "    - add function to remove stopwords from pos_id X\n",
    "1. og statement -> get pos -> pos_id\n",
    "\t- train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "\n",
    "2. og statement -> # preprocess statement: words lemmatized and stopwords are removed -> pred_statement\n",
    "\t- train_data['pred_statement'] = train_data['statement'].apply(preprocess_statement)\n",
    "\n",
    "3. pred_statement -> add to vocab dict: add preprocessed statements to vocab dict -> vocab_dict\n",
    "\t- vocabulary_dict = load_statement_vocab_dict(train_data)\n",
    "\n",
    "4. vocab_dict, pred_statement -> getWordID(): turn preprocessed statements to vector -> val\n",
    "\t- train_data['word_id'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict)\n",
    "\n",
    "**NOTE** it is generally fine to add pos tags without stopwords removed.\n",
    "\tin siddarthhari, padding used to put pos tags as separate input layer.\n",
    "\n",
    "15 mar: <br>\n",
    "    - extracted getWordId() from preprocess_statement()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64bc69-41e0-4940-8581-4a50d895417d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 19 March\n",
    "TODO: \n",
    "1. POS tags - incorporate stop words into pos tags \n",
    "- update: no need since separate input.\n",
    "2. preprocess_statement() - configure best ones. confirm lemmatizer works"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "    ADJ: Adjective - a word that describes a noun or pronoun. Examples: \"red\", \"happy\", \"big\"\n",
    "    ADP: Adposition - a word that expresses a relationship between a noun or pronoun and other words in a sentence. Examples: \"in\", \"on\", \"at\"\n",
    "    ADV: Adverb - a word that modifies a verb, adjective, or other adverb. Examples: \"quickly\", \"very\", \"well\"\n",
    "    AUX: Auxiliary verb - a verb used in combination with a main verb to express tense, aspect, modality, or voice. Examples: \"is\", \"have\", \"will\"\n",
    "    CONJ: Coordinating conjunction - a word that connects words, phrases, or clauses of equal importance. Examples: \"and\", \"or\", \"but\"\n",
    "    DET: Determiner - a word that introduces a noun and provides information about the quantity or identity of the noun. Examples: \"the\", \"a\", \"some\"\n",
    "    INTJ: Interjection - a word or phrase that expresses strong emotion or surprise. Examples: \"oh\", \"wow\", \"ouch\"\n",
    "    NOUN: Noun - a word that refers to a person, place, thing, or idea. Examples: \"dog\", \"house\", \"happiness\"\n",
    "    NUM: Numeral - a word that represents a number or quantity. Examples: \"one\", \"two\", \"hundred\"\n",
    "    PART: Particle - a word that functions as an auxiliary to a verb or as a discourse marker. Examples: \"not\", \"to\", \"up\"\n",
    "    PRON: Pronoun - a word that takes the place of a noun or noun phrase. Examples: \"he\", \"she\", \"it\"\n",
    "    PROPN: Proper noun - a noun that refers to a specific person, place, or thing. Examples: \"New York\", \"John\", \"Nike\"\n",
    "    PUNCT: Punctuation - a character or mark used in writing to separate sentences, clauses, or phrases, or to indicate pauses or intonation. Examples: \".\", \",\", \"!\"\n",
    "    X: Other - a catch-all category for words that don't fit into any other part-of-speech category. Examples: foreign words, abbreviations, etc.\n",
    "    SCONJ: Subordinating conjunction - a word that connects a dependent clause to an independent clause. Examples: \"although\", \"because\", \"unless\"\n",
    "    SYM: Symbol - a character or glyph that represents a specific meaning or concept. Examples: \"$\", \"%\", \"#\"\n",
    "    VERB: Verb - a word that describes an action or state of being. Examples: \"run\", \"think\", \"be\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pos_tags = {'ADJ': 'adjective', 'ADP': 'adposition', 'ADV': 'adverb',\n",
    "            'AUX': 'auxiliary verb', 'CONJ': 'coordinating conjunction',\n",
    "            'DET': 'determiner', 'INTJ': 'interjection', 'NOUN': 'noun',\n",
    "            'NUM': 'numeral', 'PART': 'particle', 'PRON': 'pronoun',\n",
    "            'PROPN': 'proper noun', 'PUNCT': 'punctuation', 'X': 'other',\n",
    "            'SCONJ': 'subordinating conjunction', 'SYM': 'symbol', 'VERB': 'verb'}\n",
    "\n",
    "# proposed pos_dict: values correspond to pos tag importance\n",
    "dict1 = {'NOUN': 0, 'VERB': 1, 'ADJ': 2, 'ADV': 3, 'ADP': 4, 'PRON': 5,\n",
    "            'NUM': 6, 'SCONJ': 7, 'PROPN': 8, 'CONJ': 9, 'PUNCT': 10, 'AUX': 11,\n",
    "            'PART': 12, 'INTJ': 13, 'DET': 14, 'SYM': 14, 'X': 14}\n",
    "\n",
    "dict2 = {'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CONJ': 4,\n",
    "            'DET': 5, 'INTJ': 6, 'NOUN': 7, 'NUM': 8, 'PART': 9,\n",
    "            'PRON': 10, 'PROPN': 11, 'PUNCT': 12, 'X': 13,\n",
    "            'SCONJ': 14, 'SYM': 15, 'VERB': 16}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_pos(statement, pos_dict):\n",
    "    doc = nlp(statement)\n",
    "    taglist = []\n",
    "    for token in doc:\n",
    "        # labels stopwords from list of pos tags as 12\n",
    "        # if token.is_stop:\n",
    "        #     taglist.append(12)\n",
    "        # else:\n",
    "            taglist.append(pos_dict.get(token.pos_, max(pos_dict.values())))\n",
    "    return taglist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# words lemmatized and stopwords are removed\n",
    "def preprocess_statement(statement):\n",
    "    doc = nlp(statement)\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        # option to remove stopwords, punctuation, or specific POS tags from word list\n",
    "        if not token.is_punct and not token.is_space and \\\n",
    "                token.pos_ not in ['SYM', 'DET', 'X', 'PRON', 'PART', 'CONJ', 'ADP']: # and not token.is_stop:\n",
    "            words.append(token.lemma_.lower()) # lemmatize and lowercase\n",
    "    return ' '.join(words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def preprocess_statement2(statement, exclude_pos=None, remove_stopwords=False):\n",
    "# lemmatizes and lowercases tokens that are not punctuation or whitespace.\n",
    "# params: statement - string\n",
    "#         exclude_pos - list of POS tags to exclude from word list\n",
    "#         remove_stopwords - boolean to remove stopwords from word list\n",
    "# returns: tokens joined into a string\n",
    "    doc = nlp(statement)\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        # check if token should be excluded based on part of speech and stopword status\n",
    "        if exclude_pos and token.pos_ in exclude_pos:\n",
    "            continue\n",
    "        if remove_stopwords and token.is_stop:\n",
    "            continue\n",
    "        # only include tokens that are not punctuation or whitespace\n",
    "        if not token.is_punct and not token.is_space:\n",
    "            words.append(token.lemma_.lower()) # lemmatize and lowercase\n",
    "    return ' '.join(words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "prep_pos_dict = ['SYM', 'DET', 'X', 'PRON', 'PART', 'CONJ', 'ADP']\n",
    "preprocess_statement2(train_data['statement'], exclude_pos=prep_pos_dict, remove_stopwords=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "The decision of which POS tags to remove as stop words in a short form news classification task depends on the specific requirements of the task and the nature of the data. However, in general, the following POS tags are commonly considered as candidates for removal as stop words in text classification tasks:\n",
    "\n",
    "    DET (determiner): This POS tag includes words like \"the\", \"an\", \"a\", which are commonly used in text but do not contribute much to the meaning of the text.\n",
    "    PRON (pronoun): This POS tag includes words like \"he\", \"she\", \"it\", \"they\", which are used to refer to previously mentioned nouns, but can be safely removed without losing much meaning.\n",
    "    PART (particle): This POS tag includes words like \"to\", \"up\", \"out\", which are used in phrasal verbs and idiomatic expressions, but can be removed without significantly affecting the meaning.\n",
    "    CONJ (coordinating conjunction): This POS tag includes words like \"and\", \"or\", \"but\", which are used to connect words, phrases, or clauses. However, in short form news, removing them as stop words might not significantly impact the meaning.\n",
    "    ADP (adposition): This POS tag includes prepositions like \"in\", \"on\", \"at\", which can be removed as stop words in some text classification tasks.\n",
    "\n",
    "However, it is important to note that removing too many stop words can result in the loss of important information and context in the text. Therefore, it is recommended to experiment with different combinations of stop words and evaluate the impact on the performance of the"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536e00b2-5ac6-484e-bcbe-a8841cf0dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if vocabulary.p exists, if not creates it\n",
    "def load_statement_vocab_dict(train_data):\n",
    "    if not os.path.exists('vocabulary.p'):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(train_data['pred_statement'])\n",
    "        vocabulary_dict = tokenizer.word_index\n",
    "        print(len(vocabulary_dict))\n",
    "        with open(\"vocabulary.p\", \"wb\") as f:\n",
    "            pickle.dump(vocabulary_dict, f)\n",
    "        print('Created Vocabulary Dictionary...')\n",
    "        print('Saved Vocabulary Dictionary...')\n",
    "    else:\n",
    "        print('Loading Vocabulary Dictionary...')\n",
    "        with open(\"vocabulary.p\", \"rb\") as f:\n",
    "            vocabulary_dict = pickle.load(f)\n",
    "    return vocabulary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# checks for vocabulary.p, if exists delete and update\n",
    "def create_statement_vocab_dict(train_data):\n",
    "\n",
    "    if os.path.exists('vocabulary.p'):\n",
    "        os.remove('vocabulary.p')\n",
    "        print('Deleted existing Vocabulary Dictionary...')\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_data['pred_statement'])\n",
    "    vocabulary_dict = tokenizer.word_index\n",
    "    print(len(vocabulary_dict))\n",
    "    with open(\"vocabulary.p\", \"wb\") as f:\n",
    "        pickle.dump(vocabulary_dict, f)\n",
    "    print('Created Vocabulary Dictionary...')\n",
    "    print('Saved Vocabulary Dictionary...')\n",
    "\n",
    "    return vocabulary_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49dd98b5-c087-4cc0-a7d7-700156a294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed statement to vector\n",
    "def getWordId(pred_statement, vocabulary_dict):\n",
    "    text = text_to_word_sequence(pred_statement)\n",
    "    val = [0] * 10\n",
    "    val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbef46-dc82-486c-9213-9a841352c1fe",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c53b9e3a-5fb4-4880-9154-5524c4091033",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame Cleaning\n",
    "\n",
    "- train_data['label'] -> num values\n",
    "- drops all rows where 'subject' and 'speaker' columns are missing\n",
    "- drops all rows that have missing values in 'statement'\n",
    "- drops context column\n",
    "\n",
    "<h3>Mar 19 todo:</h3>\n",
    "\n",
    "- refactor to single function\n",
    "- instead of dropping rows, replace missing values in 'subject' and 'speaker' as empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def clean_data(data, label_map):\n",
    "    # maps labels to numerical values\n",
    "    data['label'] = data['label'].map(label_map)\n",
    "\n",
    "    # replace missing values in 'subject' and 'speaker' with empty strings\n",
    "    data['subject'] = data['subject'].fillna('')\n",
    "    data['speaker'] = data['speaker'].fillna('')\n",
    "\n",
    "    # drop rows where there are missing values in 'statement'\n",
    "    data.drop(index=data[data.statement==' '].index, inplace=True)\n",
    "    data.drop(index=data[data.statement=='  '].index, inplace=True)\n",
    "    data.drop(index=data[data.statement=='\\n'].index, inplace=True)\n",
    "\n",
    "    # drop context column\n",
    "    data.drop(columns=['context'], inplace=True)\n",
    "\n",
    "    # reset index\n",
    "    data = data.reset_index()\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "train_data = clean_data(train_data, label_map)\n",
    "val_data = clean_data(val_data, label_map)\n",
    "test_data = clean_data(test_data, label_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id  label  \\\n0      0   2635.json     -2   \n1      1  10540.json      1   \n2      2    324.json      2   \n3      3   1123.json     -2   \n4      4   9028.json      1   \n\n                                           statement  \\\n0  Says the Annies List political group supports ...   \n1  When did the decline of coal start? It started...   \n2  Hillary Clinton agrees with John McCain \"by vo...   \n3  Health care reform legislation is likely to ma...   \n4  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n  state info       party  barely true  false  half-true  mostly-true  \\\n0      Texas  republican          0.0    1.0        0.0          0.0   \n1   Virginia    democrat          0.0    0.0        1.0          1.0   \n2   Illinois    democrat         70.0   71.0      160.0        163.0   \n3        NaN        none          7.0   19.0        3.0          5.0   \n4    Florida    democrat         15.0    9.0       20.0         19.0   \n\n   pants-on-fire  \n0            0.0  \n1            0.0  \n2            9.0  \n3           44.0  \n4            2.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "028f89fe-ea6d-4294-9826-a473f971ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real news count\n"
     ]
    },
    {
     "data": {
      "text/plain": "index            5752\nid               5752\nlabel            5752\nstatement        5752\nsubject          5752\nspeaker          5752\njob title        4264\nstate info       4663\nparty            5752\nbarely true      5752\nfalse            5752\nhalf-true        5752\nmostly-true      5752\npants-on-fire    5752\ndtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('real news count')\n",
    "train_data[train_data['label']>0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b67e73-4b4a-49f1-b9e4-7bd25eeb47f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pos_tags = {'ADJ': 'adjective', 'ADP': 'adposition', 'ADV': 'adverb',\n",
    "            'AUX': 'auxiliary verb', 'CONJ': 'coordinating conjunction',\n",
    "            'DET': 'determiner', 'INTJ': 'interjection', 'NOUN': 'noun',\n",
    "            'NUM': 'numeral', 'PART': 'particle', 'PRON': 'pronoun',\n",
    "            'PROPN': 'proper noun', 'PUNCT': 'punctuation', 'X': 'other',\n",
    "            'SCONJ': 'subordinating conjunction', 'SYM': 'symbol', 'VERB': 'verb'}\n",
    "\n",
    "# proposed pos_dict: values correspond to pos tag importance\n",
    "dict1 = {'NOUN': 0, 'VERB': 1, 'ADJ': 2, 'ADV': 3, 'ADP': 4, 'PRON': 5,\n",
    "            'NUM': 6, 'SCONJ': 7, 'PROPN': 8, 'CONJ': 9, 'PUNCT': 10, 'AUX': 11,\n",
    "            'PART': 12, 'INTJ': 13, 'DET': 14, 'SYM': 14, 'X': 14}\n",
    "\n",
    "dict2 = {'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CONJ': 4,\n",
    "            'DET': 5, 'INTJ': 6, 'NOUN': 7, 'NUM': 8, 'PART': 9,\n",
    "            'PRON': 10, 'PROPN': 11, 'PUNCT': 12, 'X': 13,\n",
    "            'SCONJ': 14, 'SYM': 15, 'VERB': 16}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a4a3ee4-275a-4a21-ab15-1ed6f2f08052",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pos_id'] = train_data['statement'].apply(get_pos, pos_dict=dict1)\n",
    "# val_data['pos_id'] = val_data['statement'].apply(get_pos, pos_dict=dict1)\n",
    "# test_data['pos_id'] = test_data['statement'].apply(get_pos, pos_dict=dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30c910-33df-4be0-8a96-f4d9f63aa6b5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ee13d-2069-422f-a763-9e3c725ca7d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### preprocess statements, get word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "prep_pos_dict = ['SYM', 'DET', 'X', 'PRON', 'PART', 'CONJ', 'ADP']\n",
    "# preprocess_statement2(train_data['statement'], exclude_pos=prep_pos_dict, remove_stopwords=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eab6f0d4-df00-486b-9b93-d398f6bafda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pred_statement'] = train_data['statement'].apply(preprocess_statement2, exclude_pos=prep_pos_dict, remove_stopwords=True)\n",
    "# val_data['pred_statement'] = val_data['statement'].apply(preprocess_statement)\n",
    "# test_data['pred_statement'] = test_data['statement'].apply(preprocess_statement)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df206dac-9f21-4343-b875-18a27db83955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9459\n",
      "Created Vocabulary Dictionary...\n",
      "Saved Vocabulary Dictionary...\n"
     ]
    }
   ],
   "source": [
    "vocabulary_dict = load_statement_vocab_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f7cd063-5e56-4910-bc0b-6e376fede4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['word_id'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict))\n",
    "# val_data['word_id'] = val_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict))\n",
    "# test_data['word_id'] = test_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict))\n",
    "# train_data.drop('pred_statement', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1a34463-c0ba-41f1-b9a5-c421c0f9fd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id  label  \\\n0      0   2635.json     -2   \n1      1  10540.json      1   \n2      2    324.json      2   \n3      3   1123.json     -2   \n4      4   9028.json      1   \n\n                                           statement  \\\n0  Says the Annies List political group supports ...   \n1  When did the decline of coal start? It started...   \n2  Hillary Clinton agrees with John McCain \"by vo...   \n3  Health care reform legislation is likely to ma...   \n4  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n  state info       party  barely true  false  half-true  mostly-true  \\\n0      Texas  republican          0.0    1.0        0.0          0.0   \n1   Virginia    democrat          0.0    0.0        1.0          1.0   \n2   Illinois    democrat         70.0   71.0      160.0        163.0   \n3        NaN        none          7.0   19.0        3.0          5.0   \n4    Florida    democrat         15.0    9.0       20.0         19.0   \n\n   pants-on-fire                                     pred_statement  \\\n0            0.0  say annies list political group support trimes...   \n1            0.0  decline coal start start natural gas take star...   \n2            9.0  hillary clinton agree john mccain vote george ...   \n3           44.0  health care reform legislation likely mandate ...   \n4            2.0                 economic turnaround start end term   \n\n                                             word_id  \\\n0       [1, 5297, 632, 420, 330, 36, 3906, 117, 931]   \n1  [718, 771, 246, 246, 886, 201, 45, 246, 525, 1...   \n2  [73, 48, 648, 122, 155, 12, 209, 102, 205, 273...   \n3  [13, 15, 163, 200, 512, 340, 299, 370, 137, 2738]   \n4                         [222, 3196, 246, 196, 197]   \n\n                                              pos_id  \n0      [1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]  \n1  [7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...  \n2  [8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...  \n3         [0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]  \n4               [14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>pred_statement</th>\n      <th>word_id</th>\n      <th>pos_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[1, 5297, 632, 420, 330, 36, 3906, 117, 931]</td>\n      <td>[1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[718, 771, 246, 246, 886, 201, 45, 246, 525, 1...</td>\n      <td>[7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[73, 48, 648, 122, 155, 12, 209, 102, 205, 273...</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[13, 15, 163, 200, 512, 340, 299, 370, 137, 2738]</td>\n      <td>[0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>economic turnaround start end term</td>\n      <td>[222, 3196, 246, 196, 197]</td>\n      <td>[14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0dbe55-900a-473b-9e8c-6c386db6ecae",
   "metadata": {},
   "source": [
    "### compare preprocessed statements with original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29378b-73f0-4c83-a014-19bd34f8c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['statement']) \n",
    "print(train_data['pred_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4dbc73-a1a1-4ac3-a015-ca9a14269f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.loc[25,'statement'])\n",
    "print(train_data.loc[25,'pred_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def print_row_info(row_num, df):\n",
    "    print(f\"#### label #####\\n{df.loc[row_num, 'label']}\")\n",
    "    print(f\"#### original statement #####\\n{df.loc[row_num, 'statement']}\")\n",
    "    print(f\"#### pos_id #####\\n{df.loc[row_num, 'pos_id']}\")\n",
    "    print(f\"#### preprocessed statement #####\\n{df.loc[row_num, 'pred_statement']}\")\n",
    "    print(f\"#### word_id #####\\n{df.loc[row_num, 'word_id']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "3\n",
      "#### original statement #####\n",
      "At Bain Capital, we helped start an early childhood learning company called Bright Horizons that First Lady Michelle Obama rightly praised.\n",
      "#### pos_id #####\n",
      "[4, 8, 8, 10, 5, 1, 1, 14, 2, 0, 1, 0, 1, 8, 8, 5, 8, 8, 8, 8, 3, 1, 10]\n",
      "#### preprocessed statement #####\n",
      "bain capital help start early childhood learn company call bright horizons lady michelle obama rightly praise\n",
      "#### word_id #####\n",
      "[2419, 654, 146, 246, 402, 1694, 1406, 107, 187, 3207, 5326, 2157, 1235, 5, 5327, 2420]\n"
     ]
    }
   ],
   "source": [
    "print_row_info(2000, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "Said he's the only Republican candidate \"who's actually turned around a government economy.\"\n",
      "#### preprocessed statement #####\n",
      "say he be only republican candidate who be actually turn around government economy\n",
      "#### word_id #####\n",
      "[6, 25, 1, 65, 100, 181, 52, 1, 227, 494, 580, 71, 220]\n"
     ]
    }
   ],
   "source": [
    "# 22 mar 11:25 AM\n",
    "print_row_info(61, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "The DREAM Act was written by members of both parties. When it came up for a vote a year and a half ago, Republicans in Congress blocked it. The bill hadnt changed. ... The only thing that had changed was politics.\n",
      "#### preprocessed statement #####\n",
      "dream act be write by member of party when it come up for vote year and half ago republicans in congress block it bill have not change only thing that have change be politic\n",
      "#### word_id #####\n",
      "[1390, 209, 1, 551, 19, 243, 3, 257, 62, 20, 123, 78, 8, 35, 12, 7, 236, 327, 223, 2, 150, 753, 20, 51, 5, 11, 217, 65, 451, 9, 5, 217, 1, 1612]\n"
     ]
    }
   ],
   "source": [
    "# 21 mar 1:20 pm\n",
    "print_row_info(2000, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 21 mar 10:00 am\n",
    "print_row_info(100, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# removed det, sym, etc from pred_statement\n",
    "print_row_info(2000, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stop words = 17\n",
    "print_row_info(100, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f952127-0f98-4561-8632-74617de817c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data['pred_statement']) \n",
    "ROW = 101\n",
    "print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\") \n",
    "print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "print(train_data.loc[ROW, 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # if not token.is_punct and not token.is_space\n",
    "# ROW = 100\n",
    "# print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "# print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\")\n",
    "# print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "# print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "# print(train_data.loc[ROW, 'label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # if not token.is_punct and not token.is_space and token.pos_ not in ['DET', 'ADP', 'CONJ', 'PRON']: # and not token.is_stop:\n",
    "# ROW = 4\n",
    "# print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "# print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\")\n",
    "# print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "# print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "# print(train_data.loc[ROW, 'label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
