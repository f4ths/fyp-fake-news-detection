{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743ddb1b-5ec9-42eb-b6b2-3a6513737bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "\n",
    "# from nltk import word_tokenize, sent_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6592a06-c79b-408c-bb60-ce11f2c6241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3ff5a7-07ee-4175-a03a-b7d9be841ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f22002-edb2-4591-9303-b13272354e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f11b5c8",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebe2c5-e116-43f5-8b0b-1838d1117c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbc8de-971a-4c43-b12d-4f7c5183d41e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sunday 12 March\n",
    "\n",
    "TO DO FOR the WEEK: <br>\n",
    "    - add function to remove stopwords from pos_id X\n",
    "1. og statement -> get pos -> pos_id\n",
    "\t- train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "\n",
    "2. og statement -> # preprocess statement: words lemmatized and stopwords are removed -> pred_statement\n",
    "\t- train_data['pred_statement'] = train_data['statement'].apply(preprocess_statement)\n",
    "\n",
    "3. pred_statement -> add to vocab dict: add preprocessed statements to vocab dict -> vocab_dict\n",
    "\t- vocabulary_dict = load_statement_vocab_dict(train_data)\n",
    "\n",
    "4. vocab_dict, pred_statement -> getWordID(): turn preprocessed statements to vector -> val\n",
    "\t- train_data['word_id'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict)\n",
    "\n",
    "**NOTE** it is generally fine to add pos tags without stopwords removed.\n",
    "\tin siddarthhari, padding used to put pos tags as separate input layer.\n",
    "\n",
    "15 mar: <br>\n",
    "    - extracted getWordId() from preprocess_statement()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64bc69-41e0-4940-8581-4a50d895417d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 19 March\n",
    "TODO: \n",
    "1. POS tags - incorporate stop words into pos tags \n",
    "- update: no need since separate input.\n",
    "2. preprocess_statement() - configure best ones. confirm lemmatizer works"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6630c1c0",
   "metadata": {},
   "source": [
    "    ADJ: Adjective - a word that describes a noun or pronoun. Examples: \"red\", \"happy\", \"big\"\n",
    "    ADP: Adposition - a word that expresses a relationship between a noun or pronoun and other words in a sentence. Examples: \"in\", \"on\", \"at\"\n",
    "    ADV: Adverb - a word that modifies a verb, adjective, or other adverb. Examples: \"quickly\", \"very\", \"well\"\n",
    "    AUX: Auxiliary verb - a verb used in combination with a main verb to express tense, aspect, modality, or voice. Examples: \"is\", \"have\", \"will\"\n",
    "    CONJ: Coordinating conjunction - a word that connects words, phrases, or clauses of equal importance. Examples: \"and\", \"or\", \"but\"\n",
    "    DET: Determiner - a word that introduces a noun and provides information about the quantity or identity of the noun. Examples: \"the\", \"a\", \"some\"\n",
    "    INTJ: Interjection - a word or phrase that expresses strong emotion or surprise. Examples: \"oh\", \"wow\", \"ouch\"\n",
    "    NOUN: Noun - a word that refers to a person, place, thing, or idea. Examples: \"dog\", \"house\", \"happiness\"\n",
    "    NUM: Numeral - a word that represents a number or quantity. Examples: \"one\", \"two\", \"hundred\"\n",
    "    PART: Particle - a word that functions as an auxiliary to a verb or as a discourse marker. Examples: \"not\", \"to\", \"up\"\n",
    "    PRON: Pronoun - a word that takes the place of a noun or noun phrase. Examples: \"he\", \"she\", \"it\"\n",
    "    PROPN: Proper noun - a noun that refers to a specific person, place, or thing. Examples: \"New York\", \"John\", \"Nike\"\n",
    "    PUNCT: Punctuation - a character or mark used in writing to separate sentences, clauses, or phrases, or to indicate pauses or intonation. Examples: \".\", \",\", \"!\"\n",
    "    X: Other - a catch-all category for words that don't fit into any other part-of-speech category. Examples: foreign words, abbreviations, etc.\n",
    "    SCONJ: Subordinating conjunction - a word that connects a dependent clause to an independent clause. Examples: \"although\", \"because\", \"unless\"\n",
    "    SYM: Symbol - a character or glyph that represents a specific meaning or concept. Examples: \"$\", \"%\", \"#\"\n",
    "    VERB: Verb - a word that describes an action or state of being. Examples: \"run\", \"think\", \"be\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ab88366",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pos_tags = { 'ADJ': 'adjective', 'ADP': 'adposition', 'ADV': 'adverb', 'AUX': 'auxiliary verb', 'CONJ': 'coordinating conjunction',\n",
    "                    'DET': 'determiner', 'INTJ': 'interjection', 'NOUN': 'noun',  'NUM': 'numeral', 'PART': 'particle', 'PRON': 'pronoun',\n",
    "                    'PROPN': 'proper noun', 'PUNCT': 'punctuation', 'X': 'other', 'SCONJ': 'subordinating conjunction', 'SYM': 'symbol', 'VERB': 'verb'}\n",
    "\n",
    "# proposed pos_dict: values correspond to pos tag importance\n",
    "dict1 = {'NOUN': 0, 'VERB': 1, 'ADJ': 2, 'ADV': 3, 'ADP': 4, 'PRON': 5,\n",
    "              'NUM': 6, 'SCONJ': 7, 'PROPN': 8, 'CONJ': 9, 'PUNCT': 10, 'AUX': 11,\n",
    "              'PART': 12, 'INTJ': 13, 'DET': 14, 'SYM': 14, 'X': 14}\n",
    "\n",
    "dict2 = {'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CONJ': 4,\n",
    "              'DET': 5, 'INTJ': 6, 'NOUN': 7, 'NUM': 8, 'PART': 9,\n",
    "              'PRON': 10, 'PROPN': 11, 'PUNCT': 12, 'X': 13,  'SCONJ': 14, 'SYM': 15, 'VERB': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd20b25f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_pos(statement, pos_dict):\n",
    "    doc = nlp(statement)\n",
    "    taglist = []\n",
    "    for token in doc:\n",
    "        # labels stopwords from list of pos tags as 12\n",
    "        # if token.is_stop:\n",
    "        #     taglist.append(12)\n",
    "        # else:\n",
    "            taglist.append(pos_dict.get(token.pos_, max(pos_dict.values())))\n",
    "    return taglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f0725b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_statement2(statement, pos_remove=None, spacy_stopword_removal=False):\n",
    "# lemmatizes and lowercases tokens that are not punctuation or whitespace.\n",
    "# params: statement - string\n",
    "#         exclude_pos - list of POS tags to exclude from word list\n",
    "#         remove_stopwords - removes stopwords based on pretrained spacy model\n",
    "#         **warning** not recommended to toggle both params to True\n",
    "# returns: tokens joined into a string\n",
    "    doc = nlp(statement)\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        # check if token should be excluded based on part of speech or stopword status\n",
    "        if pos_remove and token.pos_ in pos_remove:\n",
    "            continue\n",
    "        if spacy_stopword_removal and token.is_stop:\n",
    "            continue\n",
    "        # only include tokens that are not punctuation or whitespace\n",
    "        if not token.is_punct and not token.is_space:\n",
    "            # lemmatize and lowercase\n",
    "            words.append(token.lemma_.lower())\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6843b2b",
   "metadata": {},
   "source": [
    "prep_pos_dict = ['SYM', 'DET', 'X', 'PRON', 'PART', 'CONJ', 'ADP']\n",
    "preprocess_statement2(train_data['statement'], exclude_pos=prep_pos_dict, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e25fe71",
   "metadata": {},
   "source": [
    "The decision of which POS tags to remove as stop words in a short form news classification task depends on the specific requirements of the task and the nature of the data. However, in general, the following POS tags are commonly considered as candidates for removal as stop words in text classification tasks:\n",
    "\n",
    "    DET (determiner): This POS tag includes words like \"the\", \"an\", \"a\", which are commonly used in text but do not contribute much to the meaning of the text.\n",
    "    PRON (pronoun): This POS tag includes words like \"he\", \"she\", \"it\", \"they\", which are used to refer to previously mentioned nouns, but can be safely removed without losing much meaning.\n",
    "    PART (particle): This POS tag includes words like \"to\", \"up\", \"out\", which are used in phrasal verbs and idiomatic expressions, but can be removed without significantly affecting the meaning.\n",
    "    CONJ (coordinating conjunction): This POS tag includes words like \"and\", \"or\", \"but\", which are used to connect words, phrases, or clauses. However, in short form news, removing them as stop words might not significantly impact the meaning.\n",
    "    ADP (adposition): This POS tag includes prepositions like \"in\", \"on\", \"at\", which can be removed as stop words in some text classification tasks.\n",
    "\n",
    "However, it is important to note that removing too many stop words can result in the loss of important information and context in the text. Therefore, it is recommended to experiment with different combinations of stop words and evaluate the impact on the performance of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536e00b2-5ac6-484e-bcbe-a8841cf0dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if vocabulary.p exists, if not creates it\n",
    "def load_statement_vocab_dict(train_data):\n",
    "    if not os.path.exists('vocabulary.p'):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(train_data['pred_statement'])\n",
    "        vocabulary_dict = tokenizer.word_index\n",
    "        print(len(vocabulary_dict))\n",
    "        with open(\"vocabulary.p\", \"wb\") as f:\n",
    "            pickle.dump(vocabulary_dict, f)\n",
    "        print('Created Vocabulary Dictionary...')\n",
    "        print('Saved Vocabulary Dictionary...')\n",
    "    else:\n",
    "        print('Loading Vocabulary Dictionary...')\n",
    "        with open(\"vocabulary.p\", \"rb\") as f:\n",
    "            vocabulary_dict = pickle.load(f)\n",
    "    return vocabulary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a093788e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_statement_vocab_dict2(data, column_name):\n",
    "\n",
    "    vocab_file_name = f\"vocabulary_{column_name}.p\"\n",
    "\n",
    "    if os.path.exists(vocab_file_name):\n",
    "        with open(vocab_file_name, \"rb\") as f:\n",
    "            old_vocabulary_dict = pickle.load(f)\n",
    "        if column_name in old_vocabulary_dict:\n",
    "            os.remove(vocab_file_name)\n",
    "            print(f\"Deleted existing Vocabulary Dictionary for column {column_name}...\")\n",
    "        else:\n",
    "            print(f\"Existing Vocabulary Dictionary does not match column {column_name}. Creating new Vocabulary Dictionary...\")\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data[column_name])\n",
    "    vocabulary_dict = tokenizer.word_index\n",
    "    print(f\"Created Vocabulary Dictionary for column {column_name}.\")\n",
    "    print('Size: ' + str(len(vocabulary_dict)))\n",
    "    with open(vocab_file_name, \"wb\") as f:\n",
    "        pickle.dump(vocabulary_dict, f)\n",
    "    print(f\"Saved Vocabulary Dictionary as {vocab_file_name}\")\n",
    "\n",
    "    return vocabulary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84dcc97",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_statement_vocab_dict3(data, column_name):\n",
    "    vocab_file_name = f\"vocabulary_{column_name}.p\"\n",
    "\n",
    "    if os.path.exists(vocab_file_name):\n",
    "        print(f\"Loading existing Vocabulary Dictionary for column {column_name}...\")\n",
    "        with open(vocab_file_name, \"rb\") as f:\n",
    "            vocabulary_dict = pickle.load(f)\n",
    "        print(f'Size: {len(vocabulary_dict)}')\n",
    "    else:\n",
    "        print(f\"Creating new Vocabulary Dictionary for column {column_name}...\")\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(data[column_name])\n",
    "        vocabulary_dict = tokenizer.word_index\n",
    "        print(f\"Created Vocabulary Dictionary for column {column_name}.\")\n",
    "        print(f'Size: {len(vocabulary_dict)}')\n",
    "        with open(vocab_file_name, \"wb\") as f:\n",
    "            pickle.dump(vocabulary_dict, f)\n",
    "        print(f\"Saved Vocabulary Dictionary as {vocab_file_name}\")\n",
    "\n",
    "    return vocabulary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61eb3f28",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_statement_vocab_dict(data, column_name):\n",
    "    vocab_file_name = f\"vocabulary_{column_name}.p\"\n",
    "\n",
    "    if os.path.exists(vocab_file_name):\n",
    "        with open(vocab_file_name, \"rb\") as f:\n",
    "            old_vocabulary_dict = pickle.load(f)\n",
    "        # Check length of existing vocabulary dictionary and length of vocabulary dictionary created from the text data\n",
    "        if len(old_vocabulary_dict) == len(set(data[column_name].str.split().sum())):\n",
    "            print(f\"Using existing Vocabulary Dictionary for column {column_name}...\")\n",
    "            return old_vocabulary_dict\n",
    "\n",
    "        # If the length is different, delete the existing vocabulary dictionary file\n",
    "        else:\n",
    "            os.remove(vocab_file_name)\n",
    "            print(f\"Deleted existing Vocabulary Dictionary for column {column_name}...\")\n",
    "\n",
    "    # Create a new tokenizer object and fit it on the text data for the specified column\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data[column_name])\n",
    "\n",
    "    vocabulary_dict = tokenizer.word_index\n",
    "    print(f\"Created Vocabulary Dictionary for column {column_name}.\")\n",
    "    print('Size: ' + str(len(vocabulary_dict)))\n",
    "\n",
    "    # Save the vocabulary dictionary to a file\n",
    "    with open(vocab_file_name, \"wb\") as f:\n",
    "        pickle.dump(vocabulary_dict, f)\n",
    "    print(f\"Saved Vocabulary Dictionary as {vocab_file_name}\")\n",
    "    return vocabulary_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49dd98b5-c087-4cc0-a7d7-700156a294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed statement to vector\n",
    "def getWordId(pred_statement, vocabulary_dict):\n",
    "    text = text_to_word_sequence(pred_statement)\n",
    "    val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f710fe7b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # preprocessed statement to vector\n",
    "# def getWordId(pred_statement, vocab_file_name):\n",
    "#     with open(vocab_file_name, \"rb\") as f:\n",
    "#         vocabulary_dict = pickle.load(f)\n",
    "#     text = text_to_word_sequence(pred_statement)\n",
    "#     val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "#     return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9737a6e3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def print_row_info(row_num, df):\n",
    "    print(f\"#### label #####\\n{df.loc[row_num, 'label']}\")\n",
    "    print(f\"#### original statement #####\\n{df.loc[row_num, 'statement']}\")\n",
    "    print(f\"#### pos_id #####\\n{df.loc[row_num, 'pos_id']}\")\n",
    "    print(f\"#### custom stopwords #####\\n{df.loc[row_num, 'pred_statement']}\")\n",
    "    print(f\"#### word_id #####\\n{df.loc[row_num, 'word_id_custom']}\")\n",
    "    print(f\"#### spacy stopwords #####\\n{df.loc[row_num, 'pred_statement_spacyswr']}\")\n",
    "    print(f\"#### spacy word_id #####\\n{df.loc[row_num, 'word_id_spacy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd357ebe-345e-4a37-8210-467086da73a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_data\u001B[49m\u001B[38;5;241m.\u001B[39mtail()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "085fe8b3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(data, label_map):\n",
    "    # maps labels to numerical values\n",
    "    data['label'] = data['label'].map(label_map)\n",
    "\n",
    "    # replace missing values in 'subject' and 'speaker' with empty strings\n",
    "    data['subject'] = data['subject'].fillna('')\n",
    "    data['speaker'] = data['speaker'].fillna('')\n",
    "\n",
    "    # drop rows where there are missing values in 'statement'\n",
    "    data.drop(index=data[data.statement==' '].index, inplace=True)\n",
    "    data.drop(index=data[data.statement=='  '].index, inplace=True)\n",
    "    data.drop(index=data[data.statement=='\\n'].index, inplace=True)\n",
    "\n",
    "    # drop context column\n",
    "    data.drop(columns=['context'], inplace=True)\n",
    "    data.drop(columns=['id'], inplace=True)\n",
    "    data.drop(columns=['state info'], inplace=True)\n",
    "    data.drop(columns=['party'], inplace=True)\n",
    "\n",
    "    # reset index\n",
    "    data = data.reset_index()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b9e3a-5fb4-4880-9154-5524c4091033",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame Cleaning\n",
    "\n",
    "- train_data['label'] -> num values\n",
    "- drops all rows where 'subject' and 'speaker' columns are missing\n",
    "- drops all rows that have missing values in 'statement'\n",
    "- drops context column\n",
    "\n",
    "<h3>Mar 19 todo:</h3>\n",
    "\n",
    "- refactor to single function\n",
    "- instead of dropping rows, replace missing values in 'subject' and 'speaker' as empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fafb128-0588-4ab7-a78a-f58fd11270d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column titles and label maps\n",
    "columns = ['id','label','statement','subject','speaker','job title','state info','party','barely true','false','half-true','mostly-true','pants-on-fire','context']\n",
    "label_map = {'pants-fire':-3, 'false':-2, 'barely-true':-1, 'half-true':1, 'mostly-true':2, 'true':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6d5ffb3-4246-4dc9-a0e5-4b0ea2786482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset files as pandas dataframes\n",
    "train_data = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
    "val_data = pd.read_csv('valid.tsv', sep='\\t', header=None, names=columns)\n",
    "test_data = pd.read_csv('test.tsv', sep='\\t', header=None, names=columns)\n",
    "\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1fc96bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = clean_data(train_data, label_map)\n",
    "val_data = clean_data(val_data, label_map)\n",
    "test_data = clean_data(test_data, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93906f3f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   index  label                                          statement  \\\n0      0     -2  Says the Annies List political group supports ...   \n1      1      1  When did the decline of coal start? It started...   \n2      2      2  Hillary Clinton agrees with John McCain \"by vo...   \n3      3     -2  Health care reform legislation is likely to ma...   \n4      4      1  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n   barely true  false  half-true  mostly-true  pants-on-fire  \n0          0.0    1.0        0.0          0.0            0.0  \n1          0.0    0.0        1.0          1.0            0.0  \n2         70.0   71.0      160.0        163.0            9.0  \n3          7.0   19.0        3.0          5.0           44.0  \n4         15.0    9.0       20.0         19.0            2.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "028f89fe-ea6d-4294-9826-a473f971ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real news count\n"
     ]
    },
    {
     "data": {
      "text/plain": "index            5752\nlabel            5752\nstatement        5752\nsubject          5752\nspeaker          5752\njob title        4264\nbarely true      5752\nfalse            5752\nhalf-true        5752\nmostly-true      5752\npants-on-fire    5752\ndtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('real news count')\n",
    "train_data[train_data['label']>0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a1369e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### for this experiment, siddarth's results will be used as benchmark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871661e2-2497-474d-a418-443a9f93abd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### to test the different preprocessing methods, the following experiments will be run:\n",
    "1. siddarth - baseline\n",
    "    - ogdict\n",
    "    - nltk stopword removal only\n",
    "2. fathan - pos tag check\n",
    "    - dict1\n",
    "    - spacy stopword removal only\n",
    "    - glove\n",
    "3. fathan - preprocess\n",
    "    - dict1\n",
    "    - full preprocessing\n",
    "    - glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b67e73-4b4a-49f1-b9e4-7bd25eeb47f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### get pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa7b8a63",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pos_tags = {\n",
    "    'ADJ': 'adjective', 'ADP': 'adposition', 'ADV': 'adverb',\n",
    "    'AUX': 'auxiliary verb', 'CONJ': 'coordinating conjunction',\n",
    "    'DET': 'determiner', 'INTJ': 'interjection', 'NOUN': 'noun',\n",
    "    'NUM': 'numeral', 'PART': 'particle', 'PRON': 'pronoun',\n",
    "    'PROPN': 'proper noun', 'PUNCT': 'punctuation', 'X': 'other',\n",
    "    'SCONJ': 'subordinating conjunction', 'SYM': 'symbol', 'VERB': 'verb'\n",
    "    }\n",
    "\n",
    "# proposed pos_dict: values correspond to pos tag importance\n",
    "dict1 = {\n",
    "    'NOUN': 0, 'VERB': 1, 'ADJ': 2, 'ADV': 3, 'ADP': 4, 'PRON': 5,\n",
    "    'NUM': 6, 'SCONJ': 7, 'PROPN': 8, 'CONJ': 9, 'PUNCT': 10, 'AUX': 11,\n",
    "    'PART': 12, 'INTJ': 13, 'DET': 14, 'SYM': 14, 'X': 14\n",
    "    }\n",
    "\n",
    "# unordered pos_dict\n",
    "dict2 = {\n",
    "    'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CONJ': 4,\n",
    "    'DET': 5, 'INTJ': 6, 'NOUN': 7, 'NUM': 8, 'PART': 9,\n",
    "    'PRON': 10, 'PROPN': 11, 'PUNCT': 12, 'X': 13,\n",
    "    'SCONJ': 14, 'SYM': 15, 'VERB': 16\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a4a3ee4-275a-4a21-ab15-1ed6f2f08052",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pos_id'] = train_data['statement'].apply(get_pos, pos_dict=dict1)\n",
    "train_data['pos2_id'] = train_data['statement'].apply(get_pos, pos_dict=dict2)\n",
    "# val_data['pos_id'] = val_data['statement'].apply(get_pos, pos_dict=dict1)\n",
    "# test_data['pos_id'] = test_data['statement'].apply(get_pos, pos_dict=dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb30c910-33df-4be0-8a96-f4d9f63aa6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   index  label                                          statement  \\\n0      0     -2  Says the Annies List political group supports ...   \n1      1      1  When did the decline of coal start? It started...   \n2      2      2  Hillary Clinton agrees with John McCain \"by vo...   \n3      3     -2  Health care reform legislation is likely to ma...   \n4      4      1  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n   barely true  false  half-true  mostly-true  pants-on-fire  \\\n0          0.0    1.0        0.0          0.0            0.0   \n1          0.0    0.0        1.0          1.0            0.0   \n2         70.0   71.0      160.0        163.0            9.0   \n3          7.0   19.0        3.0          5.0           44.0   \n4         15.0    9.0       20.0         19.0            2.0   \n\n                                              pos_id  \\\n0      [1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]   \n1  [7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...   \n2  [8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...   \n3         [0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]   \n4               [14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]   \n\n                                             pos2_id  \n0   [16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]  \n1  [14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...  \n2  [11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...  \n3          [7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]  \n4               [5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>pos_id</th>\n      <th>pos2_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n      <td>[16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>[7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n      <td>[14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...</td>\n      <td>[11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>[0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]</td>\n      <td>[7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>[14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]</td>\n      <td>[5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ee13d-2069-422f-a763-9e3c725ca7d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### preprocess statements, get word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d0bbf5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pos_exclusion_list = ['SYM', 'DET', 'X', 'PRON', 'PART', 'CONJ', 'ADP']\n",
    "# pos_exclusion_list2 = ['']\n",
    "# preprocess_statement2(train_data['statement'], exclude_pos=prep_pos_dict, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eab6f0d4-df00-486b-9b93-d398f6bafda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom stopword removal\n",
    "train_data['pred_statement'] = train_data['statement'].apply(preprocess_statement2, pos_remove=pos_exclusion_list, spacy_stopword_removal=False)\n",
    "# spacy stopword removal\n",
    "train_data['pred_statement_spacyswr'] = train_data['statement'].apply(preprocess_statement2, pos_remove=None, spacy_stopword_removal=True)\n",
    "\n",
    "# val_data['pred_statement'] = val_data['statement'].apply(preprocess_statement)\n",
    "# test_data['pred_statement'] = test_data['statement'].apply(preprocess_statement)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "625cc10a-ac2e-47b2-b6f8-9a712b567fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   index  label                                          statement  \\\n0      0     -2  Says the Annies List political group supports ...   \n1      1      1  When did the decline of coal start? It started...   \n2      2      2  Hillary Clinton agrees with John McCain \"by vo...   \n3      3     -2  Health care reform legislation is likely to ma...   \n4      4      1  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n   barely true  false  half-true  mostly-true  pants-on-fire  \\\n0          0.0    1.0        0.0          0.0            0.0   \n1          0.0    0.0        1.0          1.0            0.0   \n2         70.0   71.0      160.0        163.0            9.0   \n3          7.0   19.0        3.0          5.0           44.0   \n4         15.0    9.0       20.0         19.0            2.0   \n\n                                              pos_id  \\\n0      [1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]   \n1  [7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...   \n2  [8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...   \n3         [0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]   \n4               [14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]   \n\n                                             pos2_id  \\\n0   [16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]   \n1  [14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...   \n2  [11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...   \n3          [7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]   \n4               [5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]   \n\n                                      pred_statement  \\\n0  say annies list political group support third ...   \n1  when do decline coal start start when natural ...   \n2  hillary clinton agree john mccain vote give ge...   \n3  health care reform legislation be likely manda...   \n4                 economic turnaround start end term   \n\n                             pred_statement_spacyswr  \\\n0  say annies list political group support trimes...   \n1  decline coal start start natural gas take star...   \n2  hillary clinton agree john mccain vote george ...   \n3  health care reform legislation likely mandate ...   \n4                 economic turnaround start end term   \n\n                                      word_id_custom  \\\n0  [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1  [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2  [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3  [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                         [282, 3331, 308, 247, 248]   \n\n                                       word_id_spacy  \n0  [1, 5315, 633, 423, 332, 37, 679, 3919, 120, 936]  \n1  [6135, 8949, 720, 773, 249, 249, 6135, 891, 20...  \n2  [74, 49, 649, 125, 157, 12, 127, 212, 103, 208...  \n3  [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]  \n4                         [224, 3208, 249, 198, 199]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>pos_id</th>\n      <th>pos2_id</th>\n      <th>pred_statement</th>\n      <th>pred_statement_spacyswr</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n      <td>[16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 679, 3919, 120, 936]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>[7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n      <td>[14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[6135, 8949, 720, 773, 249, 249, 6135, 891, 20...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...</td>\n      <td>[11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 127, 212, 103, 208...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>[0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]</td>\n      <td>[7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>[14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]</td>\n      <td>[5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32a38c82",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing Vocabulary Dictionary for column pred_statement...\n",
      "Created Vocabulary Dictionary for column pred_statement.\n",
      "Size: 9606\n",
      "Saved Vocabulary Dictionary as vocabulary_pred_statement.p\n"
     ]
    }
   ],
   "source": [
    "vocabulary_dict_custom = create_statement_vocab_dict(train_data, 'pred_statement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "384088de-ea5b-46dd-8903-12063c2cd19e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing Vocabulary Dictionary for column pred_statement_spacyswr...\n",
      "Created Vocabulary Dictionary for column pred_statement_spacyswr.\n",
      "Size: 9495\n",
      "Saved Vocabulary Dictionary as vocabulary_pred_statement_spacyswr.p\n"
     ]
    }
   ],
   "source": [
    "vocabulary_dict_spacy = create_statement_vocab_dict(train_data, 'pred_statement_spacyswr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d346d65",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# vocab_file_name = \"vocabulary_pred_statement.p\"\n",
    "# train_data['word_id'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocab_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f7cd063-5e56-4910-bc0b-6e376fede4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['word_id_custom'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict_custom))\n",
    "train_data['word_id_spacy'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict_spacy))\n",
    "# val_data['word_id'] = val_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict))\n",
    "# test_data['word_id'] = test_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict))\n",
    "# train_data.drop('pred_statement', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1a34463-c0ba-41f1-b9a5-c421c0f9fd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job title</th>\n",
       "      <th>barely true</th>\n",
       "      <th>false</th>\n",
       "      <th>half-true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>pants-on-fire</th>\n",
       "      <th>pred_statement</th>\n",
       "      <th>pred_statement_spacyswr</th>\n",
       "      <th>word_id_custom</th>\n",
       "      <th>word_id_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>say annies list political group support third ...</td>\n",
       "      <td>say annies list political group support trimes...</td>\n",
       "      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n",
       "      <td>[1, 5315, 633, 423, 332, 37, 679, 3919, 120, 936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when do decline coal start start when natural ...</td>\n",
       "      <td>decline coal start start natural gas take star...</td>\n",
       "      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n",
       "      <td>[6135, 8949, 720, 773, 249, 249, 6135, 891, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>hillary clinton agree john mccain vote give ge...</td>\n",
       "      <td>hillary clinton agree john mccain vote george ...</td>\n",
       "      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n",
       "      <td>[74, 49, 649, 125, 157, 12, 127, 212, 103, 208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>health care reform legislation be likely manda...</td>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n",
       "      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>economic turnaround start end term</td>\n",
       "      <td>economic turnaround start end term</td>\n",
       "      <td>[282, 3331, 308, 247, 248]</td>\n",
       "      <td>[224, 3208, 249, 198, 199]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index  label                                          statement  \\\n",
       "0        0      0    NaN  Says the Annies List political group supports ...   \n",
       "1        1      1    NaN  When did the decline of coal start? It started...   \n",
       "2        2      2    NaN  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3        3      3    NaN  Health care reform legislation is likely to ma...   \n",
       "4        4      4    NaN  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker             job title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "   barely true  false  half-true  mostly-true  pants-on-fire  \\\n",
       "0          0.0    1.0        0.0          0.0            0.0   \n",
       "1          0.0    0.0        1.0          1.0            0.0   \n",
       "2         70.0   71.0      160.0        163.0            9.0   \n",
       "3          7.0   19.0        3.0          5.0           44.0   \n",
       "4         15.0    9.0       20.0         19.0            2.0   \n",
       "\n",
       "                                      pred_statement  \\\n",
       "0  say annies list political group support third ...   \n",
       "1  when do decline coal start start when natural ...   \n",
       "2  hillary clinton agree john mccain vote give ge...   \n",
       "3  health care reform legislation be likely manda...   \n",
       "4                 economic turnaround start end term   \n",
       "\n",
       "                             pred_statement_spacyswr  \\\n",
       "0  say annies list political group support trimes...   \n",
       "1  decline coal start start natural gas take star...   \n",
       "2  hillary clinton agree john mccain vote george ...   \n",
       "3  health care reform legislation likely mandate ...   \n",
       "4                 economic turnaround start end term   \n",
       "\n",
       "                                      word_id_custom  \\\n",
       "0  [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n",
       "1  [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n",
       "2  [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n",
       "3  [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n",
       "4                         [282, 3331, 308, 247, 248]   \n",
       "\n",
       "                                       word_id_spacy  \n",
       "0  [1, 5315, 633, 423, 332, 37, 679, 3919, 120, 936]  \n",
       "1  [6135, 8949, 720, 773, 249, 249, 6135, 891, 20...  \n",
       "2  [74, 49, 649, 125, 157, 12, 127, 212, 103, 208...  \n",
       "3  [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]  \n",
       "4                         [224, 3208, 249, 198, 199]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0dbe55-900a-473b-9e8c-6c386db6ecae",
   "metadata": {},
   "source": [
    "### compare statement, pred_statement, word_id, pos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a427c867-efb1-466a-82c9-11364e146896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "-3\n",
      "#### original statement #####\n",
      "Says that in a hearing, Rep. Gabrielle Giffords suggested to Gen. David Petraeus that the Army put more emphasis on less environmentally damaging methods, like stabbing or clubbing enemy forces in order to minimize the carbon output.\n",
      "#### custom stopwords #####\n",
      "say that hearing rep. gabrielle giffords suggest gen. david petraeus that army put more emphasis less environmentally damaging method stab or club enemy force order minimize carbon output\n",
      "#### word_id #####\n",
      "[3, 10, 1266, 227, 5514, 5515, 922, 2562, 431, 2900, 10, 1147, 197, 8, 5516, 146, 4084, 3363, 2563, 4085, 31, 1351, 2288, 188, 469, 4086, 1203, 3364]\n",
      "#### spacy stopwords #####\n",
      "say hearing rep. gabrielle giffords suggest gen. david petraeus army emphasis environmentally damaging method like stab club enemy force order minimize carbon output\n",
      "#### spacy word_id #####\n",
      "[1, 1168, 180, 5389, 5390, 831, 2449, 364, 2780, 1053, 879, 5391, 9029, 3963, 3241, 2450, 3964, 1251, 2181, 150, 402, 3965, 1108, 3242]\n"
     ]
    }
   ],
   "source": [
    "print_row_info(192, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c12f090-263a-42a2-8f25-42db84f50b44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "Said he's the only Republican candidate \"who's actually turned around a government economy.\"\n",
      "#### custom stopwords #####\n",
      "say be only republican candidate be actually turn government economy\n",
      "#### word_id #####\n",
      "[3, 1, 40, 71, 149, 1, 186, 446, 44, 179]\n",
      "#### spacy stopwords #####\n",
      "say republican candidate actually turn government economy\n",
      "#### spacy word_id #####\n",
      "[1, 50, 113, 148, 379, 30, 142]\n"
     ]
    }
   ],
   "source": [
    "print_row_info(61, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a1f512f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "Said he's the only Republican candidate \"who's actually turned around a government economy.\"\n",
      "#### pos_id #####\n",
      "[1, 5, 11, 14, 2, 2, 0, 10, 5, 11, 3, 1, 4, 14, 0, 0, 10, 10]\n",
      "#### preprocessed statement #####\n",
      "say republican candidate actually turn government economy\n",
      "#### word_id #####\n",
      "[1, 49, 111, 145, 377, 29, 139]\n"
     ]
    }
   ],
   "source": [
    "print_row_info(61, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21738c99",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "Said he's the only Republican candidate \"who's actually turned around a government economy.\"\n",
      "#### preprocessed statement #####\n",
      "say he be only republican candidate who be actually turn around government economy\n",
      "#### word_id #####\n",
      "[6, 25, 1, 65, 100, 181, 52, 1, 227, 494, 580, 71, 220]\n"
     ]
    }
   ],
   "source": [
    "# 22 mar 11:25 AM\n",
    "print_row_info(61, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec268ed1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "The DREAM Act was written by members of both parties. When it came up for a vote a year and a half ago, Republicans in Congress blocked it. The bill hadnt changed. ... The only thing that had changed was politics.\n",
      "#### preprocessed statement #####\n",
      "dream act be write by member of party when it come up for vote year and half ago republicans in congress block it bill have not change only thing that have change be politic\n",
      "#### word_id #####\n",
      "[1390, 209, 1, 551, 19, 243, 3, 257, 62, 20, 123, 78, 8, 35, 12, 7, 236, 327, 223, 2, 150, 753, 20, 51, 5, 11, 217, 65, 451, 9, 5, 217, 1, 1612]\n"
     ]
    }
   ],
   "source": [
    "# 21 mar 1:20 pm\n",
    "print_row_info(2000, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0c63f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 21 mar 10:00 am\n",
    "print_row_info(100, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b26302",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# removed det, sym, etc from pred_statement\n",
    "print_row_info(2000, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fedcb2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# stop words = 17\n",
    "print_row_info(100, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f952127-0f98-4561-8632-74617de817c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data['pred_statement']) \n",
    "ROW = 101\n",
    "print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\") \n",
    "print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "print(train_data.loc[ROW, 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235e72b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # if not token.is_punct and not token.is_space\n",
    "# ROW = 100\n",
    "# print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "# print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\")\n",
    "# print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "# print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "# print(train_data.loc[ROW, 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a7ae1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # if not token.is_punct and not token.is_space and token.pos_ not in ['DET', 'ADP', 'CONJ', 'PRON']: # and not token.is_stop:\n",
    "# ROW = 4\n",
    "# print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "# print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\")\n",
    "# print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "# print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "# print(train_data.loc[ROW, 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "-3\n",
      "#### original statement #####\n",
      "Says that in a hearing, Rep. Gabrielle Giffords suggested to Gen. David Petraeus that the Army put more emphasis on less environmentally damaging methods, like stabbing or clubbing enemy forces in order to minimize the carbon output.\n",
      "#### custom stopwords #####\n",
      "say that hearing rep. gabrielle giffords suggest gen. david petraeus that army put more emphasis less environmentally damaging method stab or club enemy force order minimize carbon output\n",
      "#### word_id #####\n",
      "[3, 10, 1266, 227, 5514, 5515, 922, 2562, 431, 2900, 10, 1147, 197, 8, 5516, 146, 4084, 3363, 2563, 4085, 31, 1351, 2288, 188, 469, 4086, 1203, 3364]\n",
      "#### spacy stopwords #####\n",
      "say hearing rep. gabrielle giffords suggest gen. david petraeus army emphasis environmentally damaging method like stab club enemy force order minimize carbon output\n",
      "#### spacy word_id #####\n",
      "[1, 1168, 180, 5389, 5390, 831, 2449, 364, 2780, 1053, 879, 5391, 9029, 3963, 3241, 2450, 3964, 1251, 2181, 150, 402, 3965, 1108, 3242]\n"
     ]
    }
   ],
   "source": [
    "print_row_info(192, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# define function to read GloVe embeddings\n",
    "def read_glove_embeddings():\n",
    "    embeddings = {}\n",
    "    with open(\"glove.6B.100d.txt\", encoding=\"utf8\") as file_object:\n",
    "        for line in file_object:\n",
    "            word_embed = line.split()\n",
    "            word = word_embed[0]\n",
    "            embed = np.array(word_embed[1:], dtype=\"float32\")\n",
    "            # if word.lower() in dictionary:\n",
    "            embeddings[word.lower()] = embed\n",
    "    return embeddings\n",
    "\n",
    "# # create embedding matrix for vocabulary_dict1\n",
    "# num_words1 = len(vocabulary_dict1) + 1\n",
    "# embedding_matrix1 = np.zeros((num_words1, EMBED_DIM))\n",
    "#\n",
    "# for word, i in vocabulary_dict1.items():\n",
    "#     embedding_vector = embeddings_dict1.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix1[i] = embedding_vector\n",
    "#\n",
    "# # create embedding matrix for vocabulary_dict2\n",
    "# num_words2 = len(vocabulary_dict2) + 1\n",
    "# embedding_matrix2 = np.zeros((num_words2, EMBED_DIM))\n",
    "#\n",
    "# for word, i in vocabulary_dict2.items():\n",
    "#     embedding_vector = embeddings_dict2.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix2[i] = embedding_vector\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400001  : Word Embeddings Found\n"
     ]
    }
   ],
   "source": [
    "# read GloVe embeddings\n",
    "embeddings_dict = read_glove_embeddings()\n",
    "print(len(embeddings_dict), \" : Word Embeddings Found\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def create_embedding_matrix(vocabulary_dict, embeddings_dictionary, embed_dim):\n",
    "    num_words = len(vocabulary_dict) + 1\n",
    "    embedding_matrix = np.zeros((num_words, embed_dim))\n",
    "\n",
    "    for word, i in vocabulary_dict.items():\n",
    "        embedding_vector = embeddings_dictionary.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "EMBED_DIM = 100\n",
    "embedding_matrix_custom = create_embedding_matrix(vocabulary_dict_custom, embeddings_dict, EMBED_DIM)\n",
    "embedding_matrix_spacy = create_embedding_matrix(vocabulary_dict_spacy, embeddings_dict, EMBED_DIM)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reads pre-trained GloVe embeddings and store in a dictionary\n",
    "# embeddings = {}\n",
    "# with open(\"glove.6B.100d.txt\", encoding=\"utf8\") as file_object:\n",
    "#     for line in file_object:\n",
    "#         word_embed = line.split()\n",
    "#         word = word_embed[0]\n",
    "#         embed = np.array(word_embed[1:], dtype=\"float32\")\n",
    "#         embeddings[word.lower()] = embed\n",
    "#\n",
    "# print(len(embeddings), \" : Word Embeddings Found\")\n",
    "# print(len(embeddings[word]), \" : Embedding Dimension\")\n",
    "#\n",
    "# EMBED_DIM = 100\n",
    "# num_words = len(vocabulary_dict) + 1\n",
    "# embedding_matrix = np.zeros((num_words, EMBED_DIM))\n",
    "#\n",
    "# # assign embedding vector to each word in vocabulary_dict\n",
    "# for word, i in vocabulary_dict.items():\n",
    "#     embedding_vector = embeddings.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "#\n",
    "# embeddings_index = None"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
