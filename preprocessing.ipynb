{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743ddb1b-5ec9-42eb-b6b2-3a6513737bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "\n",
    "# from nltk import word_tokenize, sent_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6592a06-c79b-408c-bb60-ce11f2c6241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\fatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3ff5a7-07ee-4175-a03a-b7d9be841ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f22002-edb2-4591-9303-b13272354e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fafb128-0588-4ab7-a78a-f58fd11270d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column titles and label maps\n",
    "columns = ['id','label','statement','subject','speaker','job title','state info','party','barely true','false','half-true','mostly-true','pants-on-fire','context']\n",
    "label_map = {'pants-fire':-3, 'false':-2, 'barely-true':-1, 'half-true':1, 'mostly-true':2, 'true':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6d5ffb3-4246-4dc9-a0e5-4b0ea2786482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           id        label                                          statement  \\\n0   2635.json        false  Says the Annies List political group supports ...   \n1  10540.json    half-true  When did the decline of coal start? It started...   \n2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n3   1123.json        false  Health care reform legislation is likely to ma...   \n4   9028.json    half-true  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n  state info       party  barely true  false  half-true  mostly-true  \\\n0      Texas  republican          0.0    1.0        0.0          0.0   \n1   Virginia    democrat          0.0    0.0        1.0          1.0   \n2   Illinois    democrat         70.0   71.0      160.0        163.0   \n3        NaN        none          7.0   19.0        3.0          5.0   \n4    Florida    democrat         15.0    9.0       20.0         19.0   \n\n   pants-on-fire              context  \n0            0.0             a mailer  \n1            0.0      a floor speech.  \n2            9.0               Denver  \n3           44.0       a news release  \n4            2.0  an interview on CNN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>a mailer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>a floor speech.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>Denver</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>a news release</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>an interview on CNN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset files as pandas dataframes\n",
    "train_data = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
    "val_data = pd.read_csv('valid.tsv', sep='\\t', header=None, names=columns)\n",
    "test_data = pd.read_csv('test.tsv', sep='\\t', header=None, names=columns)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebe2c5-e116-43f5-8b0b-1838d1117c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11934c-40a3-4925-8e03-66cd2a6369e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 7 March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9d30b6-8c46-4601-a33b-8792eca2f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "#\n",
    "# def load_statement_vocab_dict(train_data):\n",
    "#     vocabulary_dict = {}\n",
    "#     if not os.path.exists('vocabulary.p'):\n",
    "#         tokenizer = Tokenizer()\n",
    "#         tokenizer.fit_on_texts(train_data['statement'])\n",
    "#         vocabulary_dict = tokenizer.word_index\n",
    "#         print(len(vocabulary_dict))\n",
    "#         cp.dump(vocabulary_dict, open(\"vocabulary.p\", \"wb\"))\n",
    "#         print('Created Vocabulary Dictionary...')\n",
    "#         print('Saved Vocabulary Dictionary...')\n",
    "#     else:\n",
    "#         print('Loading Vocabulary Dictionary...')\n",
    "#         vocabulary_dict = cp.load(open(\"vocabulary.p\", \"rb\"))\n",
    "#     return vocabulary_dict\n",
    "#\n",
    "# def preprocess_statement(statement, vocabulary_dict):\n",
    "#     statement = statement.lower() # lowercasing\n",
    "#     doc = nlp(statement)\n",
    "#     taglist = []\n",
    "#     wordlist = []\n",
    "#     for token in doc:\n",
    "#         if not token.is_stop:\n",
    "#             wordlist.append(token.lemma_)\n",
    "#             taglist.append(pos_dict.get(token.pos_, max(pos_dict.values())))\n",
    "#     wordlist = ' '.join(wordlist)\n",
    "#     text = text_to_word_sequence(wordlist)\n",
    "#     val = [0] * 10\n",
    "#     val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "#     return val, taglist\n",
    "\n",
    "\n",
    "\n",
    "# def load_statement_vocab_dict(train_data):\n",
    "#     vocabulary_dict = {}\n",
    "#     if not os.path.exists('vocabulary.p'):\n",
    "#         tokenizer = Tokenizer()\n",
    "#         tokenizer.fit_on_texts(train_data['statement'])\n",
    "#         vocabulary_dict = tokenizer.word_index\n",
    "#         print(len(vocabulary_dict))\n",
    "#         cp.dump(vocabulary_dict, open(\"vocabulary.p\", \"wb\"))\n",
    "#         print('Created Vocabulary Dictionary...')\n",
    "#         print('Saved Vocabulary Dictionary...')\n",
    "#     else:\n",
    "#         print('Loading Vocabulary Dictionary...')\n",
    "#         vocabulary_dict = cp.load(open(\"vocabulary.p\", \"rb\"))\n",
    "#     return vocabulary_dict\n",
    "\n",
    "# def preprocess_statement(statement, vocabulary_dict):\n",
    "#     statement = [w for w in statement.split(' ') if w not in stop_words]\n",
    "#     statement = ' '.join(statement)\n",
    "#     text = text_to_word_sequence(statement)\n",
    "#     val = [0] * 10\n",
    "#     val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "#     return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f6be2f-656a-4487-8175-c877e2863815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_dict = {'NOUN' : 0, 'VERB' : 1, 'ADP' : 2, 'PROPN' : 3, 'PUNCT' : 4,\n",
    "#             'DET' : 5, 'ADJ' : 6, 'NUM' : 7, 'ADV' : 8, 'PRON' : 9, 'X' : 9,\n",
    "#             'PART' : 9, 'SYM' : 9, 'INTJ' : 9 }\n",
    "#\n",
    "# def get_pos(statement):\n",
    "#     doc = nlp(statement)\n",
    "#     taglist = []\n",
    "#     for token in doc:\n",
    "#         taglist.append(pos_dict.get(token.pos_, max(pos_dict.values())))\n",
    "#     return taglist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbc8de-971a-4c43-b12d-4f7c5183d41e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sunday 12 March\n",
    "\n",
    "TO DO FOR the WEEK: <br>\n",
    "    - add function to remove stopwords from pos_id X\n",
    "1. og statement -> get pos -> pos_id\n",
    "\t- train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "\n",
    "2. og statement -> # preprocess statement: words lemmatized and stopwords are removed -> pred_statement\n",
    "\t- train_data['pred_statement'] = train_data['statement'].apply(preprocess_statement)\n",
    "\n",
    "3. pred_statement -> add to vocab dict: add preprocessed statements to vocab dict -> vocab_dict\n",
    "\t- vocabulary_dict = load_statement_vocab_dict(train_data)\n",
    "\n",
    "4. vocab_dict, pred_statement -> getWordID(): turn preprocessed statements to vector -> val\n",
    "\t- train_data['word_id'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict)\n",
    "\n",
    "**NOTE** it is generally fine to add pos tags without stopwords removed.\n",
    "\tin siddarthhari, padding used to put pos tags as separate input layer.\n",
    "\n",
    "15 mar: <br>\n",
    "    - extracted getWordId() from preprocess_statement()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1988bb58-a870-4942-a53e-7ff633da3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = {'ADJ': 'adjective', 'ADP': 'adposition', 'ADV': 'adverb', \n",
    "            'AUX': 'auxiliary verb', 'CONJ': 'coordinating conjunction', \n",
    "            'DET': 'determiner', 'INTJ': 'interjection', 'NOUN': 'noun', \n",
    "            'NUM': 'numeral', 'PART': 'particle', 'PRON': 'pronoun', \n",
    "            'PROPN': 'proper noun', 'PUNCT': 'punctuation', 'X': 'other', \n",
    "            'SCONJ': 'subord conjunction', 'SYM': 'symbol', 'VERB': 'verb'}\n",
    "\n",
    "# pos_dict_1 = {'NOUN' : 1, 'VERB' : 2, 'ADP' : 3, 'PROPN' : 4, 'PUNCT' : 5, \n",
    "#             'DET' : 6, 'ADJ' : 7, 'NUM' : 8, 'ADV' : 9, 'PRON' : 10, 'X' : 11, \n",
    "#             'PART' : 11, 'SYM' : 11, 'INTJ' : 11 }\n",
    "\n",
    "pos_dict = {'NOUN' : 0, 'VERB' : 1, 'ADP' : 2, 'PROPN' : 3, 'PUNCT' : 4, \n",
    "            'DET' : 5, 'ADJ' : 6, 'NUM' : 7, 'ADV' : 8, 'PRON' : 9, 'X' : 9, \n",
    "            'PART' : 9, 'SYM' : 9, 'INTJ' : 9 }\n",
    "\n",
    "\n",
    "# pos_dict = {'NOUN' : 0, 'VERB' : 1, 'ADP' : 2, 'PROPN' : 3, 'PUNCT' : 4, \n",
    "#             'DET' : 5, 'ADJ' : 6, 'NUM' : 7, 'ADV' : 8, 'PRON' : 9, 'X' : 9, \n",
    "#             'PART' : 9, 'SYM' : 9, 'INTJ' : 9, 'DET' : 9 }  # DET tag as 9\n",
    "\n",
    "def get_pos(statement):\n",
    "    doc = nlp(statement)\n",
    "    taglist = []\n",
    "    deplist = []\n",
    "    for token in doc:\n",
    "        taglist.append(pos_dict.get(token.pos_,max(pos_dict.values())))\n",
    "    return taglist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64bc69-41e0-4940-8581-4a50d895417d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 19 March\n",
    "TODO: \n",
    "1. POS tags - incorporate stop words into pos tags \n",
    "- update: no need since separate input.\n",
    "2. preprocess_statement() - configure best ones. confirm lemmatizer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pos dict for each tag separately, with option for 'STOP' tag:\n",
    "pos_dict3 = {'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CONJ': 4,\n",
    "            'DET': 5, 'INTJ': 6, 'NOUN': 7, 'NUM': 8, 'PART': 9,\n",
    "            'PRON': 10, 'PROPN': 11, 'PUNCT': 12, 'X': 13,\n",
    "            'SCONJ': 14, 'SYM': 15, 'VERB': 16, 'STOP': 17}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# original siddarthhari pos dict\n",
    "\n",
    "pos_dict2 = {'NOUN' : 0, 'VERB' : 1, 'ADP' : 2, 'PROPN' : 3, 'PUNCT' : 4,\n",
    "            'DET' : 5, 'ADJ' : 6, 'NUM' : 7, 'ADV' : 8, 'PRON' : 9, 'X' : 9,\n",
    "            'PART' : 9, 'SYM' : 9, 'INTJ' : 9 }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "pos_tags = {'ADJ': 'adjective', 'ADP': 'adposition', 'ADV': 'adverb', \n",
    "            'AUX': 'auxiliary verb', 'CONJ': 'coordinating conjunction', \n",
    "            'DET': 'determiner', 'INTJ': 'interjection', 'NOUN': 'noun', \n",
    "            'NUM': 'numeral', 'PART': 'particle', 'PRON': 'pronoun', \n",
    "            'PROPN': 'proper noun', 'PUNCT': 'punctuation', 'X': 'other', \n",
    "            'SCONJ': 'subordinating conjunction', 'SYM': 'symbol', 'VERB': 'verb', 'STOP': 'stop word'}\n",
    "\n",
    "# proposed pos_dict, with values that correspond to pos tag importance\n",
    "pos_dict = {'NOUN': 0, 'VERB': 1, 'ADJ': 2, 'ADV': 3, 'ADP': 4, 'PRON': 5,\n",
    "            'NUM': 6, 'SCONJ': 7, 'PROPN': 8, 'CONJ': 9, 'PUNCT': 10,\n",
    "            'PART': 11, 'AUX': 11, 'DET': 11, 'INTJ': 11, 'SYM': 11, 'X': 11}\n",
    "\n",
    "def get_pos(statement):\n",
    "    doc = nlp(statement)\n",
    "    taglist = []\n",
    "    for token in doc:\n",
    "        # labels stopwords from list of pos tags as 12\n",
    "        # if token.is_stop:\n",
    "        #     taglist.append(12)\n",
    "        # else:\n",
    "            taglist.append(pos_dict.get(token.pos_, max(pos_dict.values())))\n",
    "    return taglist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "f48e87ff-0e25-42c7-95c2-4995c5a2e71b",
   "metadata": {},
   "source": [
    "train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "val_data['pos_id'] = val_data['statement'].apply(get_pos)\n",
    "test_data['pos_id'] = test_data['statement'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# preprocess statement: words lemmatized and stopwords are removed\n",
    "def preprocess_statement(statement):\n",
    "    doc = nlp(statement)\n",
    "    words = []\n",
    "\n",
    "    for token in doc:\n",
    "        # option to remove stopwords, punctuation, or specific POS tags from word list\n",
    "        if not token.is_punct and not token.is_space and token.pos_ not in ['X', 'DET', 'INTJ', 'AUX']: # and not token.is_stop:\n",
    "            # lemmatize and lowercase\n",
    "            words.append(token.lemma_.lower())\n",
    "    return ' '.join(words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596ac6fe-f382-484a-96f7-8d9992b9d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "#\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "#\n",
    "# # remove punct, stopwords, and lemmatize\n",
    "# def preprocess_statement(statement):\n",
    "#     statement = statement.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "#     statement = ''.join([i for i in statement if not i.isdigit()]) # remove numbers\n",
    "#     # statement = [w for w in statement.split(' ') if w not in stopwords.words('english')] # only stopwords\n",
    "#     statement = [lemmatizer.lemmatize(w) for w in statement.split(' ') if w not in stopwords.words('english')]\n",
    "#     statement = ' '.join(statement)\n",
    "#     return statement\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4390efd9-f8b9-4a0c-85e6-b880cca1f565",
   "metadata": {},
   "source": [
    "train_data['pred_statement'] = train_data['statement'].apply(preprocess_statement)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536e00b2-5ac6-484e-bcbe-a8841cf0dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_statement_vocab_dict(train_data):\n",
    "    vocabulary_dict = {}\n",
    "    if not os.path.exists('vocabulary.p'):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(train_data['pred_statement'])\n",
    "        vocabulary_dict = tokenizer.word_index\n",
    "        print(len(vocabulary_dict))\n",
    "        with open(\"vocabulary.p\", \"wb\") as f:\n",
    "            pickle.dump(vocabulary_dict, f)\n",
    "        print('Created Vocabulary Dictionary...')\n",
    "        print('Saved Vocabulary Dictionary...')\n",
    "    else:\n",
    "        print('Loading Vocabulary Dictionary...')\n",
    "        with open(\"vocabulary.p\", \"rb\") as f:\n",
    "            vocabulary_dict = pickle.load(f)\n",
    "    return vocabulary_dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6744e12-6ed8-4689-b169-cdb23b1dd27a",
   "metadata": {},
   "source": [
    "vocabulary_dict = load_statement_vocab_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49dd98b5-c087-4cc0-a7d7-700156a294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed statement to vector\n",
    "def getWordId(pred_statement, vocabulary_dict):\n",
    "    text = text_to_word_sequence(pred_statement)\n",
    "    val = [0] * 10\n",
    "    val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37ae10d7-415b-4fcf-982a-55762c41f270",
   "metadata": {},
   "source": [
    "# train_data['word_id'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3102829-99d8-4a5d-9c4f-441bc713d100",
   "metadata": {},
   "source": [
    "# train_data['word_id'] = train_data['statement'].apply(lambda x: preprocess_statement(x, vocabulary_dict))\n",
    "# val_data['word_id'] = val_data['statement'].apply(lambda x: preprocess_statement(x, vocabulary_dict))\n",
    "# test_data['word_id'] = test_data['statement'].apply(lambda x: preprocess_statement(x, vocabulary_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbef46-dc82-486c-9213-9a841352c1fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b9e3a-5fb4-4880-9154-5524c4091033",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame Cleaning\n",
    "\n",
    "- train_data['label'] -> num values\n",
    "- drops all rows where 'subject' and 'speaker' columns are missing\n",
    "- drops all rows that have missing values in 'statement'\n",
    "- drops context column\n",
    "\n",
    "<h3>Mar 19 todo:</h3>\n",
    "\n",
    "- refactor to single function\n",
    "- instead of dropping rows, replace missing values in 'subject' and 'speaker' as empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def clean_data(data, label_map):\n",
    "    # maps labels to numerical values\n",
    "    data['label'] = data['label'].map(label_map)\n",
    "\n",
    "    # replace missing values in 'subject' and 'speaker' with empty strings\n",
    "    data['subject'] = data['subject'].fillna('')\n",
    "    data['speaker'] = data['speaker'].fillna('')\n",
    "\n",
    "    # drop rows where there are missing values in 'statement'\n",
    "    data.drop(index=data[data.statement==' '].index, inplace=True)\n",
    "    data.drop(index=data[data.statement=='  '].index, inplace=True)\n",
    "    data.drop(index=data[data.statement=='\\n'].index, inplace=True)\n",
    "\n",
    "    # drop context column\n",
    "    data.drop(columns=['context'], inplace=True)\n",
    "\n",
    "    # reset index\n",
    "    data = data.reset_index()\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train_data = clean_data(train_data, label_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id  label  \\\n0      0   2635.json     -2   \n1      1  10540.json      1   \n2      2    324.json      2   \n3      3   1123.json     -2   \n4      4   9028.json      1   \n\n                                           statement  \\\n0  Says the Annies List political group supports ...   \n1  When did the decline of coal start? It started...   \n2  Hillary Clinton agrees with John McCain \"by vo...   \n3  Health care reform legislation is likely to ma...   \n4  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n  state info       party  barely true  false  half-true  mostly-true  \\\n0      Texas  republican          0.0    1.0        0.0          0.0   \n1   Virginia    democrat          0.0    0.0        1.0          1.0   \n2   Illinois    democrat         70.0   71.0      160.0        163.0   \n3        NaN        none          7.0   19.0        3.0          5.0   \n4    Florida    democrat         15.0    9.0       20.0         19.0   \n\n   pants-on-fire  \n0            0.0  \n1            0.0  \n2            9.0  \n3           44.0  \n4            2.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1215d43f-2b72-4e3d-b61d-a03d2d040088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count\n"
     ]
    },
    {
     "data": {
      "text/plain": "index            10238\nid               10238\nlabel            10238\nstatement        10238\nsubject          10238\nspeaker          10238\njob title         7343\nstate info        8032\nparty            10238\nbarely true      10238\nfalse            10238\nhalf-true        10238\nmostly-true      10238\npants-on-fire    10238\ndtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maps labels to numerical values\n",
    "train_data['label'] = train_data['label'].map(label_map) \n",
    "\n",
    "# drop rows where 'subject' and 'speaker' are missing\n",
    "train_data.drop(index=train_data[train_data.subject.isna()].index, inplace=True) \n",
    "train_data.drop(index=train_data[train_data.speaker.isna()].index, inplace=True)\n",
    "\n",
    "# drop rows where there are missing values in 'statement'\n",
    "train_data.drop(index=train_data[train_data.statement==' '].index, inplace=True)\n",
    "train_data.drop(index=train_data[train_data.statement=='  '].index, inplace=True)\n",
    "train_data.drop(index=train_data[train_data.statement=='\\n'].index, inplace=True)\n",
    "\n",
    "# drop context column \n",
    "train_data.drop(columns=['context'],inplace=True)\n",
    "\n",
    "train_data = train_data.reset_index()\n",
    "print('train count')\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f362d29-5dd1-4447-b896-33a584e1e89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid count\n"
     ]
    },
    {
     "data": {
      "text/plain": "index            1284\nid               1284\nlabel            1284\nstatement        1284\nsubject          1284\nspeaker          1284\njob title         939\nstate info       1005\nparty            1284\nbarely true      1284\nfalse            1284\nhalf-true        1284\nmostly-true      1284\npants-on-fire    1284\ndtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loads valid.tsv as pandas dataframe\n",
    "# valid_data = pd.read_csv('valid.tsv',sep='\\t',header=None, names=columns)\n",
    "\n",
    "# maps labels to numerical values\n",
    "val_data['label'] = val_data['label'].map(label_map) \n",
    "\n",
    "# drop rows where 'subject' and 'speaker' are missing\n",
    "val_data.drop(index=val_data[val_data.subject.isna()].index, inplace=True)\n",
    "val_data.drop(index=val_data[val_data.speaker.isna()].index, inplace=True)\n",
    "\n",
    "# drop rows where there are missing values in 'statement'\n",
    "val_data.drop(index=val_data[val_data.statement==' '].index, inplace=True)\n",
    "val_data.drop(index=val_data[val_data.statement=='  '].index, inplace=True)\n",
    "val_data.drop(index=val_data[val_data.statement=='\\n'].index, inplace=True)\n",
    "\n",
    "# drop context column \n",
    "val_data.drop(columns=['context'],inplace=True)\n",
    "\n",
    "val_data = val_data.reset_index()\n",
    "print('valid count')\n",
    "val_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1979ded-e75e-4b4c-a11a-22b7f266dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test count\n"
     ]
    },
    {
     "data": {
      "text/plain": "id               1267\nlabel            1267\nstatement        1267\nsubject          1267\nspeaker          1267\njob title         942\nstate info       1005\nparty            1267\nbarely true      1267\nfalse            1267\nhalf-true        1267\nmostly-true      1267\npants-on-fire    1267\ndtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loads test.tsv as pandas dataframe\n",
    "# test_data = pd.read_csv('test.tsv',sep='\\t',header=None, names=columns)\n",
    "## print(len(test))\n",
    "\n",
    "# maps labels to numerical values\n",
    "test_data['label'] = test_data['label'].map(label_map)\n",
    "## test.dropna(inplace=True)\n",
    "\n",
    "# drop rows where 'subject' and 'speaker' are missing\n",
    "test_data.drop(index=test_data[test_data.subject.isna()].index, inplace=True)\n",
    "test_data.drop(index=test_data[test_data.speaker.isna()].index, inplace=True)\n",
    "\n",
    "# drop rows where there are missing values in 'statement'\n",
    "test_data.drop(index=test_data[test_data.statement==' '].index, inplace=True)\n",
    "test_data.drop(index=test_data[test_data.statement=='  '].index, inplace=True)\n",
    "test_data.drop(index=test_data[test_data.statement=='\\n'].index, inplace=True)\n",
    "\n",
    "# drop context column \n",
    "test_data.drop(columns=['context'],inplace=True)\n",
    "print('test count')\n",
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "028f89fe-ea6d-4294-9826-a473f971ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real news count\n"
     ]
    },
    {
     "data": {
      "text/plain": "index            5752\nid               5752\nlabel            5752\nstatement        5752\nsubject          5752\nspeaker          5752\njob title        4264\nstate info       4663\nparty            5752\nbarely true      5752\nfalse            5752\nhalf-true        5752\nmostly-true      5752\npants-on-fire    5752\ndtype: int64"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('real news count')\n",
    "train_data[train_data['label']>0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eea504-c809-4707-8616-c658d394d8ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ['statement']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b67e73-4b4a-49f1-b9e4-7bd25eeb47f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a4a3ee4-275a-4a21-ab15-1ed6f2f08052",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "# val_data['pos_id'] = val_data['statement'].apply(get_pos)\n",
    "# test_data['pos_id'] = test_data['statement'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb30c910-33df-4be0-8a96-f4d9f63aa6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id  label  \\\n0      0   2635.json     -2   \n1      1  10540.json      1   \n2      2    324.json      2   \n3      3   1123.json     -2   \n4      4   9028.json      1   \n\n                                           statement  \\\n0  Says the Annies List political group supports ...   \n1  When did the decline of coal start? It started...   \n2  Hillary Clinton agrees with John McCain \"by vo...   \n3  Health care reform legislation is likely to ma...   \n4  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n  state info       party  barely true  false  half-true  mostly-true  \\\n0      Texas  republican          0.0    1.0        0.0          0.0   \n1   Virginia    democrat          0.0    0.0        1.0          1.0   \n2   Illinois    democrat         70.0   71.0      160.0        163.0   \n3        NaN        none          7.0   19.0        3.0          5.0   \n4    Florida    democrat         15.0    9.0       20.0         19.0   \n\n   pants-on-fire                                             pos_id  \n0            0.0      [1, 11, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]  \n1            0.0  [7, 1, 11, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...  \n2            9.0  [8, 8, 1, 4, 8, 8, 10, 4, 1, 11, 1, 8, 8, 11, ...  \n3           44.0         [0, 0, 0, 0, 11, 2, 11, 1, 2, 0, 0, 0, 10]  \n4            2.0               [11, 2, 0, 1, 4, 11, 0, 4, 5, 0, 10]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>pos_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[1, 11, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>[7, 1, 11, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 11, 1, 8, 8, 11, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>[0, 0, 0, 0, 11, 2, 11, 1, 2, 0, 0, 0, 10]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>[11, 2, 0, 1, 4, 11, 0, 4, 5, 0, 10]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e806da3-4a1a-4ad7-82b8-112d6e92cf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id  label  \\\n0      0  12134.json     -1   \n1      1    238.json     -3   \n2      2   7891.json     -2   \n3      3   8169.json      1   \n4      4    929.json      1   \n\n                                           statement  \\\n0  We have less Americans working now than in the...   \n1  When Obama was sworn into office, he DID NOT u...   \n2  Says Having organizations parading as being so...   \n3     Says nearly half of Oregons children are poor.   \n4  On attacks by Republicans that various program...   \n\n                            subject          speaker  \\\n0                      economy,jobs   vicky-hartzler   \n1  obama-birth-certificate,religion      chain-email   \n2   campaign-finance,congress,taxes  earl-blumenauer   \n3                           poverty  jim-francesconi   \n4                  economy,stimulus     barack-obama   \n\n                                       job title state info       party  \\\n0                            U.S. Representative   Missouri  republican   \n1                                            NaN        NaN        none   \n2                            U.S. representative     Oregon    democrat   \n3  Member of the State Board of Higher Education     Oregon        none   \n4                                      President   Illinois    democrat   \n\n   barely true  false  half-true  mostly-true  pants-on-fire  \\\n0            1      0          1            0              0   \n1           11     43          8            5            105   \n2            0      1          1            1              0   \n3            0      1          1            1              0   \n4           70     71        160          163              9   \n\n                                              pos_id  \n0        [17, 17, 17, 11, 16, 17, 17, 17, 17, 7, 12]  \n1  [17, 11, 17, 16, 17, 7, 12, 17, 17, 17, 16, 17...  \n2  [16, 16, 7, 16, 17, 17, 0, 7, 7, 17, 17, 17, 1...  \n3                   [16, 2, 7, 17, 11, 7, 17, 0, 12]  \n4  [17, 7, 17, 11, 17, 17, 7, 17, 17, 0, 7, 7, 17...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>pos_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>12134.json</td>\n      <td>-1</td>\n      <td>We have less Americans working now than in the...</td>\n      <td>economy,jobs</td>\n      <td>vicky-hartzler</td>\n      <td>U.S. Representative</td>\n      <td>Missouri</td>\n      <td>republican</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[17, 17, 17, 11, 16, 17, 17, 17, 17, 7, 12]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>238.json</td>\n      <td>-3</td>\n      <td>When Obama was sworn into office, he DID NOT u...</td>\n      <td>obama-birth-certificate,religion</td>\n      <td>chain-email</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>11</td>\n      <td>43</td>\n      <td>8</td>\n      <td>5</td>\n      <td>105</td>\n      <td>[17, 11, 17, 16, 17, 7, 12, 17, 17, 17, 16, 17...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>7891.json</td>\n      <td>-2</td>\n      <td>Says Having organizations parading as being so...</td>\n      <td>campaign-finance,congress,taxes</td>\n      <td>earl-blumenauer</td>\n      <td>U.S. representative</td>\n      <td>Oregon</td>\n      <td>democrat</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[16, 16, 7, 16, 17, 17, 0, 7, 7, 17, 17, 17, 1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8169.json</td>\n      <td>1</td>\n      <td>Says nearly half of Oregons children are poor.</td>\n      <td>poverty</td>\n      <td>jim-francesconi</td>\n      <td>Member of the State Board of Higher Education</td>\n      <td>Oregon</td>\n      <td>none</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[16, 2, 7, 17, 11, 7, 17, 0, 12]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>929.json</td>\n      <td>1</td>\n      <td>On attacks by Republicans that various program...</td>\n      <td>economy,stimulus</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70</td>\n      <td>71</td>\n      <td>160</td>\n      <td>163</td>\n      <td>9</td>\n      <td>[17, 7, 17, 11, 17, 17, 7, 17, 17, 0, 7, 7, 17...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ee13d-2069-422f-a763-9e3c725ca7d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### preprocess statements\n",
    "TODO 19 mar:\n",
    "- configure preprocessing/lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eab6f0d4-df00-486b-9b93-d398f6bafda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pred_statement'] = train_data['statement'].apply(preprocess_statement)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df206dac-9f21-4343-b875-18a27db83955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9660\n",
      "Created Vocabulary Dictionary...\n",
      "Saved Vocabulary Dictionary...\n"
     ]
    }
   ],
   "source": [
    "vocabulary_dict = load_statement_vocab_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f7cd063-5e56-4910-bc0b-6e376fede4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['word_id'] = train_data['pred_statement'].apply(lambda x: getWordId(x, vocabulary_dict))\n",
    "# train_data.drop('pred_statement', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1a34463-c0ba-41f1-b9a5-c421c0f9fd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id  label  \\\n0      0   2635.json     -2   \n1      1  10540.json      1   \n2      2    324.json      2   \n3      3   1123.json     -2   \n4      4   9028.json      1   \n\n                                           statement  \\\n0  Says the Annies List political group supports ...   \n1  When did the decline of coal start? It started...   \n2  Hillary Clinton agrees with John McCain \"by vo...   \n3  Health care reform legislation is likely to ma...   \n4  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n  state info       party  barely true  false  half-true  mostly-true  \\\n0      Texas  republican          0.0    1.0        0.0          0.0   \n1   Virginia    democrat          0.0    0.0        1.0          1.0   \n2   Illinois    democrat         70.0   71.0      160.0        163.0   \n3        NaN        none          7.0   19.0        3.0          5.0   \n4    Florida    democrat         15.0    9.0       20.0         19.0   \n\n   pants-on-fire                                             pos_id  \\\n0            0.0      [1, 11, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]   \n1            0.0  [7, 1, 11, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...   \n2            9.0  [8, 8, 1, 4, 8, 8, 10, 4, 1, 11, 1, 8, 8, 11, ...   \n3           44.0         [0, 0, 0, 0, 11, 2, 11, 1, 2, 0, 0, 0, 10]   \n4            2.0               [11, 2, 0, 1, 4, 11, 0, 4, 5, 0, 10]   \n\n                                      pred_statement  \\\n0  say annies list political group support third ...   \n1  when do decline of coal start it start when na...   \n2  hillary clinton agree with john mccain by vote...   \n3  health care reform legislation likely to manda...   \n4        economic turnaround start at end of my term   \n\n                                             word_id  \n0  [4, 5489, 759, 533, 436, 78, 311, 4094, 186, 8...  \n1  [57, 80, 849, 2, 905, 345, 18, 345, 57, 1031, ...  \n2  [129, 95, 776, 21, 192, 236, 17, 33, 3, 115, 3...  \n3  [34, 38, 246, 289, 632, 3, 446, 402, 481, 212,...  \n4             [318, 3380, 345, 37, 284, 2, 177, 285]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>pos_id</th>\n      <th>pred_statement</th>\n      <th>word_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>-2</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[1, 11, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n      <td>say annies list political group support third ...</td>\n      <td>[4, 5489, 759, 533, 436, 78, 311, 4094, 186, 8...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>[7, 1, 11, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n      <td>when do decline of coal start it start when na...</td>\n      <td>[57, 80, 849, 2, 905, 345, 18, 345, 57, 1031, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 11, 1, 8, 8, 11, ...</td>\n      <td>hillary clinton agree with john mccain by vote...</td>\n      <td>[129, 95, 776, 21, 192, 236, 17, 33, 3, 115, 3...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>-2</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>[0, 0, 0, 0, 11, 2, 11, 1, 2, 0, 0, 0, 10]</td>\n      <td>health care reform legislation likely to manda...</td>\n      <td>[34, 38, 246, 289, 632, 3, 446, 402, 481, 212,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>1</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>[11, 2, 0, 1, 4, 11, 0, 4, 5, 0, 10]</td>\n      <td>economic turnaround start at end of my term</td>\n      <td>[318, 3380, 345, 37, 284, 2, 177, 285]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0dbe55-900a-473b-9e8c-6c386db6ecae",
   "metadata": {},
   "source": [
    "### compare preprocessed statements with original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c29378b-73f0-4c83-a014-19bd34f8c073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Says the Annies List political group supports ...\n",
      "1        When did the decline of coal start? It started...\n",
      "2        Hillary Clinton agrees with John McCain \"by vo...\n",
      "3        Health care reform legislation is likely to ma...\n",
      "4        The economic turnaround started at the end of ...\n",
      "                               ...                        \n",
      "10233    There are a larger number of shark attacks in ...\n",
      "10234    Democrats have now become the party of the [At...\n",
      "10235    Says an alternative to Social Security that op...\n",
      "10236    On lifting the U.S. Cuban embargo and allowing...\n",
      "10237    The Department of Veterans Affairs has a manua...\n",
      "Name: statement, Length: 10238, dtype: object\n",
      "0        say annies list political group support trimes...\n",
      "1        decline coal start start natural gas take star...\n",
      "2        hillary clinton agree john mccain vote george ...\n",
      "3        health care reform legislation likely mandate ...\n",
      "4                       economic turnaround start end term\n",
      "                               ...                        \n",
      "10233    large number shark attack florida case voter f...\n",
      "10234             democrats party atlanta metro area black\n",
      "10235    say alternative social security operate galves...\n",
      "10236            lift u.s. cuban embargo allow travel cuba\n",
      "10237    department veterans affairs manual tell vetera...\n",
      "Name: pred_statement, Length: 10238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['statement']) \n",
    "print(train_data['pred_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e4dbc73-a1a1-4ac3-a015-ca9a14269f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I dont know who (Jonathan Gruber) is.\n",
      "not know jonathan gruber\n"
     ]
    }
   ],
   "source": [
    "print(train_data.loc[25,'statement'])\n",
    "print(train_data.loc[25,'pred_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def print_row_info(row_num, df):\n",
    "    print(f\"#### label #####\\n{df.loc[row_num, 'label']}\")\n",
    "    print(f\"#### original statement #####\\n{df.loc[row_num, 'statement']}\")\n",
    "    print(f\"#### pod_id #####\\n{df.loc[row_num, 'pos_id']}\")\n",
    "    print(f\"#### preprocessed statement #####\\n{df.loc[row_num, 'pred_statement']}\")\n",
    "    print(f\"#### word_id #####\\n{df.loc[row_num, 'word_id']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "The DREAM Act was written by members of both parties. When it came up for a vote a year and a half ago, Republicans in Congress blocked it. The bill hadnt changed. ... The only thing that had changed was politics.\n",
      "#### pod_id #####\n",
      "[11, 8, 8, 11, 1, 4, 0, 4, 11, 0, 10, 7, 5, 1, 4, 4, 11, 0, 11, 0, 11, 11, 0, 3, 10, 8, 4, 8, 1, 5, 10, 11, 0, 11, 11, 1, 10, 10, 11, 2, 0, 5, 11, 1, 11, 0, 10]\n",
      "#### preprocessed statement #####\n",
      "dream act write by member of party when it come up for vote year and half ago republicans in congress block it bill not change only thing that change politic\n",
      "#### word_id #####\n",
      "[1380, 204, 545, 17, 237, 2, 251, 57, 18, 120, 74, 6, 33, 11, 5, 231, 319, 218, 1, 145, 745, 18, 47, 9, 212, 61, 445, 7, 212, 1602]\n"
     ]
    }
   ],
   "source": [
    "# 21 mar 1:20 pm\n",
    "print_row_info(2000, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "-2\n",
      "#### original statement #####\n",
      "The Florida Department of Agricultures website FreshFromFlorida.com can be used to get a permit to carry a loaded hidden gun without ever leaving your house.\n",
      "#### preprocessed statement #####\n",
      "the florida department of agricultures website freshfromflorida.com can be use to get a permit to carry a load hide gun without ever leave your house\n",
      "#### pod_id #####\n",
      "[11, 8, 8, 4, 8, 0, 8, 11, 11, 1, 11, 1, 11, 0, 11, 1, 11, 1, 1, 0, 4, 3, 1, 5, 0, 10]\n",
      "#### word_id #####\n",
      "[1, 122, 269, 4, 5557, 1410, 5558, 4138, 98, 2, 114, 5, 61, 6, 989, 5, 595, 6, 2344, 1581, 146, 254, 302, 261, 193, 143]\n"
     ]
    }
   ],
   "source": [
    "# 21 mar 10:00 am\n",
    "print_row_info(100, train_data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "2\n",
      "#### original statement #####\n",
      "The DREAM Act was written by members of both parties. When it came up for a vote a year and a half ago, Republicans in Congress blocked it. The bill hadnt changed. ... The only thing that had changed was politics.\n",
      "#### pod_id #####\n",
      "[11, 8, 8, 11, 1, 4, 0, 4, 11, 0, 10, 7, 5, 1, 4, 4, 11, 0, 11, 0, 11, 11, 0, 3, 10, 8, 4, 8, 1, 5, 10, 11, 0, 11, 11, 1, 10, 10, 11, 2, 0, 5, 11, 1, 11, 0, 10]\n",
      "#### preprocessed statement #####\n",
      "dream act write by member of party when it come up for vote year and half ago republicans in congress block it bill not change only thing that change politic\n",
      "#### word_id #####\n",
      "[1378, 204, 544, 17, 237, 2, 251, 57, 18, 120, 74, 6, 33, 11, 5, 231, 318, 218, 1, 145, 744, 18, 47, 9, 212, 61, 444, 7, 212, 1600]\n"
     ]
    }
   ],
   "source": [
    "# removed det, sym, etc from pred_statement\n",
    "print_row_info(2000, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### label #####\n",
      "-2\n",
      "#### original statement #####\n",
      "The Florida Department of Agricultures website FreshFromFlorida.com can be used to get a permit to carry a loaded hidden gun without ever leaving your house.\n",
      "#### preprocessed statement #####\n",
      "florida department agricultures website freshfromflorida.com can be use to get permit to carry load hide gun ever leave house\n",
      "#### pod_id #####\n",
      "[17, 11, 11, 17, 11, 7, 11, 17, 17, 17, 17, 17, 17, 7, 17, 16, 17, 16, 16, 7, 17, 17, 16, 17, 7, 12]\n",
      "#### word_id #####\n",
      "[86, 219, 5489, 1345, 5490, 4067, 63, 1, 78, 3, 34, 930, 3, 545, 2277, 1516, 111, 252, 212, 108]\n"
     ]
    }
   ],
   "source": [
    "# stop words = 17\n",
    "print_row_info(100, train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f952127-0f98-4561-8632-74617de817c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original statements:\n",
      "The Florida Department of Agricultures website FreshFromFlorida.com can be used to get a permit to carry a loaded hidden gun without ever leaving your house.\n",
      "pos tag ids:\n",
      "[17, 11, 11, 17, 11, 7, 11, 17, 17, 17, 17, 17, 17, 7, 17, 16, 17, 16, 16, 7, 17, 17, 16, 17, 7, 12]\n",
      "preprocessed statements:\n",
      "florida department agricultures website freshfromflorida.com permit carry load hide gun leave house\n",
      "pred_statements vectorized:\n",
      "[59, 172, 5357, 1242, 5358, 3941, 835, 466, 2168, 1412, 79, 165, 76]\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "# print(train_data['pred_statement']) \n",
    "ROW = 101\n",
    "print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\") \n",
    "print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "print(train_data.loc[ROW, 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original statements:\n",
      "The Florida Department of Agricultures website FreshFromFlorida.com can be used to get a permit to carry a loaded hidden gun without ever leaving your house.\n",
      "pos tag ids:\n",
      "[17, 11, 11, 17, 11, 7, 11, 17, 17, 17, 17, 17, 17, 7, 17, 16, 17, 16, 16, 7, 17, 17, 16, 17, 7, 12]\n",
      "preprocessed statements:\n",
      "the florida department of agricultures website freshfromflorida.com can be use to get a permit to carry a load hide gun without ever leave your house\n",
      "pred_statements vectorized:\n",
      "[1, 122, 269, 4, 5557, 1410, 5558, 4138, 98, 2, 114, 5, 61, 6, 989, 5, 595, 6, 2344, 1581, 146, 254, 302, 261, 193, 143]\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "# if not token.is_punct and not token.is_space\n",
    "\n",
    "ROW = 100\n",
    "print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\")\n",
    "print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "print(train_data.loc[ROW, 'label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original statements:\n",
      "The economic turnaround started at the end of my term.\n",
      "pos tag ids:\n",
      "[17, 0, 7, 16, 17, 17, 7, 17, 17, 7, 12]\n",
      "preprocessed statements:\n",
      "economic turnaround start end term\n",
      "pred_statements vectorized:\n",
      "[289, 3333, 311, 250, 251]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# if not token.is_punct and not token.is_space and token.pos_ not in ['DET', 'ADP', 'CONJ', 'PRON']: # and not token.is_stop:\n",
    "\n",
    "ROW = 4\n",
    "print(f\"original statements:\\n{train_data.loc[ROW, 'statement']}\")\n",
    "print(f\"pos tag ids:\\n{train_data.loc[ROW, 'pos_id']}\")\n",
    "print(f\"preprocessed statements:\\n{train_data.loc[ROW, 'pred_statement']}\")\n",
    "print(f\"pred_statements vectorized:\\n{train_data.loc[ROW, 'word_id']}\")\n",
    "print(train_data.loc[ROW, 'label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49e29c-c619-4933-aa90-f3bd5c2cb6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "357abbbf-7da7-480a-bb1f-3a62f3301d66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# statement 8 mar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbabafb-6e54-4046-93c8-19917d81b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_dict = load_statement_vocab_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bea68-4922-4bd6-ac22-89f9ca746120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['word_id'] = train_data['statement'].apply(preprocess_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9aae06-3569-48e1-acf1-4ee5dfc91383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[['word_id', 'pos_id']] = train_data['statement'].apply(lambda x: pd.Series(preprocess_statement(x, vocabulary_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe01af-db79-4fce-8590-823b3ba5d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875d9e6-c891-4883-a99a-582577e830f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d0868-f3c3-4242-8b5b-e9f429ccc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# def load_statement_vocab_dict(train_data):\n",
    "#     vocabulary_dict = {}\n",
    "#     if not os.path.exists('vocabulary.p'):\n",
    "#         tokenizer = Tokenizer()\n",
    "#         tokenizer.fit_on_texts(train_data['statement'])\n",
    "#         vocabulary_dict = tokenizer.word_index\n",
    "#         print(len(vocabulary_dict))\n",
    "#         cp.dump(vocabulary_dict, open(\"vocabulary.p\", \"wb\"))\n",
    "#         print('Created Vocabulary Dictionary...')\n",
    "#         print('Saved Vocabulary Dictionary...')\n",
    "#     else:\n",
    "#         print('Loading Vocabulary Dictionary...')\n",
    "#         vocabulary_dict = cp.load(open(\"vocabulary.p\", \"rb\"))\n",
    "#     return vocabulary_dict\n",
    "\n",
    "\n",
    "\n",
    "### pre pos tag\n",
    "\n",
    "# def preprocess_statement(statement, vocabulary_dict):\n",
    "#     statement = statement.lower() # lowercasing\n",
    "#     statement = [w for w in statement.split(' ') if w not in stop_words] # stop word removal\n",
    "#     statement = [lemmatizer.lemmatize(w) for w in statement]  # lemmatization \n",
    "#     statement = ' '.join(statement)\n",
    "    \n",
    "# #   maps each word in the preprocessed statement to an integer index value in the vocabulary_dict, allowing us to represent each statement as a sequence of integers that can be used as input to a machine learning model.\n",
    "#     text = text_to_word_sequence(statement)\n",
    "#     val = [0] * 10\n",
    "#     val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "#     return val\n",
    "\n",
    "### doest work\n",
    "\n",
    "# def preprocess_statement(statement, vocabulary_dict):\n",
    "#     statement = statement.lower() # lowercasing\n",
    "#     statement = [lemmatizer.lemmatize(w) for w in statement.split(' ')]  # lemmatization \n",
    "#     pos_tags = get_pos(' '.join(statement))\n",
    "#     statement = [w for i, w in enumerate(statement) if pos_dict.get(pos_tags[i], 0) not in [2, 4] and w not in stop_words] # stop word removal after pos tagging\n",
    "#     statement = ' '.join(statement)\n",
    "    \n",
    "#     # maps each word in the preprocessed statement to an integer index value in the vocabulary_dict, allowing us to represent each statement as a sequence of integers that can be used as input to a machine learning model.\n",
    "#     text = text_to_word_sequence(statement)\n",
    "#     val = [0] * 10\n",
    "#     val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "#     return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c14700-773e-44a2-b13b-21d94481b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_statement(statement, vocabulary_dict):\n",
    "#     statement = statement.lower() # lowercasing\n",
    "#     doc = nlp(statement)\n",
    "#     taglist = []\n",
    "#     wordlist = []\n",
    "#     for token in doc:\n",
    "#         if not token.is_stop:\n",
    "#             wordlist.append(token.lemma_)\n",
    "#             taglist.append(pos_dict.get(token.pos_, max(pos_dict.values())))\n",
    "#     wordlist = ' '.join(wordlist)\n",
    "#     text = text_to_word_sequence(wordlist)\n",
    "#     val = [0] * 10\n",
    "#     val = [vocabulary_dict[t] for t in text if t in vocabulary_dict]\n",
    "#     return val, taglist\n",
    "\n",
    "# vocabulary_dict = load_statement_vocab_dict(train_data)\n",
    "\n",
    "# train_data[['word_id', 'pos_id']] = train_data['statement'].apply(lambda x: pd.Series(preprocess_statement(x, vocabulary_dict)))\n",
    "# valid_data[['word_id', 'pos_id']] = valid_data['statement'].apply(lambda x: pd.Series(preprocess_statement(x, vocabulary_dict)))\n",
    "# test_data[['word_id', 'pos_id']] = test_data['statement'].apply(lambda x: pd.Series(preprocess_statement(x, vocabulary_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea21d5-45a2-4450-a057-96504dc2d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tags = {'ADJ': 'adjective', 'ADP': 'adposition', 'ADV': 'adverb',\n",
    "#             'AUX': 'auxiliary verb', 'CONJ': 'coordinating conjunction',\n",
    "#             'DET': 'determiner', 'INTJ': 'interjection', 'NOUN': 'noun',\n",
    "#             'NUM': 'numeral', 'PART': 'particle', 'PRON': 'pronoun',\n",
    "#             'PROPN': 'proper noun', 'PUNCT': 'punctuation', 'X': 'other',\n",
    "#             'SCONJ': 'subord conjunction', 'SYM': 'symbol', 'VERB': 'verb'}\n",
    "#\n",
    "# pos_dict = {'NOUN' : 0, 'VERB' : 1, 'ADP' : 2, 'PROPN' : 3, 'PUNCT' : 4,\n",
    "#             'DET' : 5, 'ADJ' : 6, 'NUM' : 7, 'ADV' : 8, 'PRON' : 9, 'X' : 9,\n",
    "#             'PART' : 9, 'SYM' : 9, 'INTJ' : 9 }\n",
    "#\n",
    "# dep_dict = {'ACL' : 0, 'ACOMP' : 1, 'ADVCL' : 2, 'ADVMOD' : 3, 'AGENT' : 4,\n",
    "#             'AMOD' : 5, 'APPOS' : 6, 'ATTR' : 7, 'AUX' : 8, 'AUXPASS' : 9,\n",
    "#             'CASE' : 10, 'CC' : 11, 'CCOMP' : 12, 'COMPOUND' : 13, 'CONJ' : 14,\n",
    "#             'CSUBJ' : 15, 'CSUBJPASS' : 16, 'DATIVE' : 17, 'DEP' : 18,\n",
    "#             'DET' : 19, 'DOBJ' : 20, 'EXPL' : 21, 'INTJ' : 22, 'MARK' : 23,\n",
    "#             'META' : 24, 'NEG' : 25, 'NOUNMOD' : 26, 'NPMOD' : 27, 'NSUBJ' : 28,\n",
    "#             'NSUBJPASS' : 29, 'NUMMOD' : 30, 'OPRD' : 31, 'PARATAXIS' : 32,\n",
    "#             'PCOMP' : 33, 'POBJ' : 34, 'POSS' : 35, 'PRECONJ' : 36, 'PREDET' : 37,\n",
    "#             'PREP' : 38, 'PRT' : 39, 'PUNCT' : 40, 'QUANTMOD' : 41,\n",
    "#             'RELCL' : 42, 'ROOT' : 43, 'XCOMP' : 44}\n",
    "#\n",
    "# def get_pos(statement):\n",
    "#     doc = nlp(statement)\n",
    "#     taglist = []\n",
    "#     deplist = []\n",
    "#     for token in doc:\n",
    "#         taglist.append(pos_dict.get(token.pos_,max(pos_dict.values())))\n",
    "#         #deplist.append(token.dep_)\n",
    "#     return taglist\n",
    "#\n",
    "# train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "# val_data['pos_id'] = val_data['statement'].apply(get_pos)\n",
    "# test_data['pos_id'] = test_data['statement'].apply(get_pos)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf24e91-bb34-4df6-96b8-f2b11bc3f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_dict = load_statement_vocab_dict(train_data)\n",
    "#\n",
    "# # train_data['word_id'] = train_data['statement'].apply(lambda x: preprocess_statement(x, vocabulary_dict))\n",
    "#\n",
    "# valid_data['word_id'] = valid_data['statement'].apply(lambda x: preprocess_statement(x, vocabulary_dict))\n",
    "# test_data['word_id'] = test_data['statement'].apply(lambda x: preprocess_statement(x, vocabulary_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630cdda-62e5-45d2-a508-fabd5836fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_dict = {'NOUN' : 0, 'VERB' : 1, 'ADP' : 2, 'PROPN' : 3, 'PUNCT' : 4,\n",
    "#             'DET' : 5, 'ADJ' : 6, 'NUM' : 7, 'ADV' : 8, 'PRON' : 9, 'X' : 9,\n",
    "#             'PART' : 9, 'SYM' : 9, 'INTJ' : 9 }\n",
    "#\n",
    "# def get_pos(statement):\n",
    "#     doc = nlp(statement)\n",
    "#     taglist = []\n",
    "#     for token in doc:\n",
    "#         taglist.append(pos_dict.get(token.pos_, max(pos_dict.values())))\n",
    "#     return taglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924804d-a6c5-4ec3-8a3c-575669db333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "# val_data['pos_id'] = val_data['statement'].apply(get_pos)\n",
    "# test_data['pos_id'] = test_data['statement'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be963bb-a4ea-463d-a261-d468bf04ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad8114-8042-43c1-9bc6-ba8ed149814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_dict = load_statement_vocab_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345965a0-4ba4-4f80-b5d9-9acf3a24fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['pos_id'] = train_data['statement'].apply(get_pos)\n",
    "# # val_data['pos_id'] = val_data['statement'].apply(get_pos)\n",
    "# # test_data['pos_id'] = test_data['statement'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a84b3f-c05d-43cc-b30b-3eeef4e82e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add(a,b):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
