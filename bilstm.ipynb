{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import keras.utils\n",
    "import spacy\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense,Flatten,LSTM,Conv1D,GlobalMaxPool1D,Dropout,Bidirectional\n",
    "from keras.utils import pad_sequences\n",
    "from keras_preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('processed_train_data.tsv', sep='\\t', index_col=0)\n",
    "val_data = pd.read_csv('processed_val_data.tsv', sep='\\t', index_col=0)\n",
    "test_data = pd.read_csv('processed_test_data.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def format_string2np(string_numpy):\n",
    "    \"\"\"formatting : Conversion of String List to List\n",
    "\n",
    "    Args:\n",
    "        string_numpy (str)\n",
    "    Returns:\n",
    "        l (list): list of values\n",
    "    \"\"\"\n",
    "    list_values = string_numpy.strip('[]').split(', ')\n",
    "    return np.array(list_values).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "columns = ['word_id_custom', 'word_id_spacy', 'pos_id', 'pos_id_DEFAULT']\n",
    "\n",
    "for column in columns:\n",
    "    train_data[column] = train_data[column].apply(format_string2np)\n",
    "    val_data[column] = val_data[column].apply(format_string2np)\n",
    "    test_data[column] = test_data[column].apply(format_string2np)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrix: (9607, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_custom = np.load('embedding_matrix_custom.npy')\n",
    "embedding_matrix_spacy = np.load('embedding_matrix_spacy.npy')\n",
    "embedding_shape = embedding_matrix_custom.shape\n",
    "\n",
    "print(\"Shape of the embedding matrix:\", embedding_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the vocabulary dictionary: 9606\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "vocabulary_dict_custom = pickle.load(open('vocabulary_statement_custom.p', 'rb'))\n",
    "vocabulary_dict_spacy = pickle.load(open('vocabulary_statement_spacy.p', 'rb'))\n",
    "vocab_length = len(vocabulary_dict_custom)\n",
    "\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "             label                                          statement  \\\nindex                                                                   \n0            false  Says the Annies List political group supports ...   \n1        half-true  When did the decline of coal start? It started...   \n2      mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n3            false  Health care reform legislation is likely to ma...   \n4        half-true  The economic turnaround started at the end of ...   \n\n                                  subject         speaker  \\\nindex                                                       \n0                                abortion    dwayne-bohac   \n1      energy,history,job-accomplishments  scott-surovell   \n2                          foreign-policy    barack-obama   \n3                             health-care    blog-posting   \n4                            economy,jobs   charlie-crist   \n\n                  job title state info       party  barely true  false  \\\nindex                                                                    \n0      State representative      Texas  republican          0.0    1.0   \n1            State delegate   Virginia    democrat          0.0    0.0   \n2                 President   Illinois    democrat         70.0   71.0   \n3                       NaN        NaN        none          7.0   19.0   \n4                       NaN    Florida    democrat         15.0    9.0   \n\n       half-true  mostly-true  pants-on-fire  output  \\\nindex                                                  \n0            0.0          0.0            0.0      -2   \n1            1.0          1.0            0.0       1   \n2          160.0        163.0            9.0       2   \n3            3.0          5.0           44.0      -2   \n4           20.0         19.0            2.0       1   \n\n                                                  pos_id  \\\nindex                                                      \n0          [1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]   \n1      [7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...   \n2      [8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...   \n3             [0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]   \n4                   [14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]   \n\n                                          pos_id_DEFAULT  \\\nindex                                                      \n0       [16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]   \n1      [14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...   \n2      [11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...   \n3              [7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]   \n4                   [5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]   \n\n                                        statement_custom  \\\nindex                                                      \n0      say annies list political group support third ...   \n1      when do decline coal start start when natural ...   \n2      hillary clinton agree john mccain vote give ge...   \n3      health care reform legislation be likely manda...   \n4                     economic turnaround start end term   \n\n                                         statement_spacy  \\\nindex                                                      \n0      say annies list political group support trimes...   \n1      decline coal start start natural gas take star...   \n2      hillary clinton agree john mccain vote george ...   \n3      health care reform legislation likely mandate ...   \n4                     economic turnaround start end term   \n\n                                          word_id_custom  \\\nindex                                                      \n0      [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1      [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2      [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3      [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                             [282, 3331, 308, 247, 248]   \n\n                                           word_id_spacy  \nindex                                                     \n0           [1, 5315, 633, 423, 332, 37, 3919, 120, 936]  \n1      [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...  \n2      [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...  \n3      [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]  \n4                             [224, 3208, 249, 198, 199]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job title</th>\n      <th>state info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>false</th>\n      <th>half-true</th>\n      <th>mostly-true</th>\n      <th>pants-on-fire</th>\n      <th>output</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-2</td>\n      <td>[1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n      <td>[16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>[7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n      <td>[14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>2</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...</td>\n      <td>[11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>-2</td>\n      <td>[0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]</td>\n      <td>[7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>[14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]</td>\n      <td>[5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## to test the different preprocessing methods, the following experiments will be run:\n",
    "1. siddarth - baseline\n",
    "\n",
    "        - ogdict\n",
    "        - nltk stopword removal only\n",
    "\n",
    "****\n",
    "****\n",
    "\n",
    "## todo\n",
    "****\n",
    "### INITIALISE INPUT/OUTPUT\n",
    "1. [x] word_id custom AS X_train_custom\n",
    "  - [x] embedding_matrix_custom\n",
    "  - [x] vocabulary_dict_custom\n",
    "2. [x] word_id spacy AS X_train_spacy\n",
    "  - [x] embedding_matrix_spacy\n",
    "  - [x] vocabulary_dict_spacy\n",
    "  \n",
    "3. [x] pos_id custom AS X_train_pos_custom\n",
    "4. [x] pos_id spacy AS X_train_pos_spacy\n",
    "    \n",
    "#### Input variables to be processed: \n",
    "- [ ] meta\n",
    "- [ ] dep parse\n",
    "\n",
    "****\n",
    "### GENERAL\n",
    "- [x] change everything to python 3\n",
    "\n",
    "### variables, init, etc.\n",
    "- [ ] pass in vocabulary.p\n",
    "****\n",
    "### BILSTM MODEL\n",
    "- [ ] functions: train(), etc\n",
    "        (CODE CELLS COULD BE BETTER, INVESTIGATE)\n",
    "- [ ] black box everything to understand la\n",
    "- [ ]\n",
    "\n",
    "****\n",
    "*decide which word id to use*\n",
    "\n",
    "1. fathan - pos tag check [ ]\n",
    "    - custom pos tag dict\n",
    "    - spacy preprocess - spacy word id\n",
    "    - glove\n",
    " 2. fathan - preprocess [ ]\n",
    "    - custom pos tag dict\n",
    "    - custom preprocess - custom word id\n",
    "    - glove\n",
    "    * check best results with default pos tag [ ]\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "# HYPERPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBED_DIM = 100\n",
    "\n",
    "# vocab_length = len(vocabulary_dict.keys())\n",
    "custom_vocabLen = len(vocabulary_dict_custom.keys())\n",
    "spacy_vocabLen = len(vocabulary_dict_spacy.keys())\n",
    "hidden_size = EMBED_DIM #Has to be same as EMBED_DIM\n",
    "lstm_size = 100\n",
    "num_steps = 15\n",
    "num_epochs = 30\n",
    "batch_size = 40\n",
    "\n",
    "## TODO: preprocess metadata\n",
    "#Meta data related hyper params\n",
    "# num_party = len(train_data.party_id.unique())\n",
    "# num_state = len(train_data.state_id.unique())\n",
    "# num_venue = len(train_data.venue_id.unique())\n",
    "# num_job = len(train_data.job_id.unique())\n",
    "# num_sub = len(train_data.subject_id.unique())\n",
    "# num_speaker = len(train_data.speaker_id.unique())\n",
    "\n",
    "# print num_party\n",
    "# print num_state\n",
    "# print num_venue\n",
    "# print num_job\n",
    "# print num_sub\n",
    "# print num_speaker\n",
    "# print train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "0        [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...\n",
      "1        [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...\n",
      "2        [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...\n",
      "3        [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...\n",
      "4                               [282, 3331, 308, 247, 248]\n",
      "                               ...                        \n",
      "10235    [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...\n",
      "10236       [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]\n",
      "10237    [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...\n",
      "10238       [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]\n",
      "10239    [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...\n",
      "Name: word_id_custom, Length: 10240, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['word_id_custom'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   3 5440  717 ...    0    0    0]\n",
      " [  37    9  804 ...   16  262  517]\n",
      " [ 104   69  734 ...    0    0    0]\n",
      " ...\n",
      " [   3 2024  154 ...   24 1311 1173]\n",
      " [1604   28   13 ...    0    0    0]\n",
      " [ 216 1429 2087 ... 1195  430  184]]\n"
     ]
    }
   ],
   "source": [
    "# print(X_train_custom)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def input_pad_sequences(data):\n",
    "    padded_data = sequence.pad_sequences(data, maxlen=num_steps, padding='post', truncating='post')\n",
    "    return padded_data\n",
    "\n",
    "X_train_custom = input_pad_sequences(train_data['word_id_custom'])\n",
    "X_val_custom = input_pad_sequences(val_data['word_id_custom'])\n",
    "X_test_custom = input_pad_sequences(test_data['word_id_custom'])\n",
    "\n",
    "X_train_spacy = input_pad_sequences(train_data['word_id_spacy'])\n",
    "X_val_spacy = input_pad_sequences(val_data['word_id_spacy'])\n",
    "X_test_spacy = input_pad_sequences(test_data['word_id_spacy'])\n",
    "\n",
    "X_train_pos = input_pad_sequences(train_data['pos_id'])\n",
    "X_val_pos = input_pad_sequences(val_data['pos_id'])\n",
    "X_test_pos = input_pad_sequences(test_data['pos_id'])\n",
    "\n",
    "X_train_pos_DEFAULT = input_pad_sequences(train_data['pos_id_DEFAULT'])\n",
    "X_val_pos_DEFAULT = input_pad_sequences(val_data['pos_id_DEFAULT'])\n",
    "X_test_pos_DEFAULT = input_pad_sequences(test_data['pos_id_DEFAULT'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Initialise input/output\n",
    "\n",
    "## OUTPUT\n",
    "Y_train = train_data['output']\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=6)\n",
    "\n",
    "Y_val = val_data['output']\n",
    "Y_val = keras.utils.to_categorical(Y_val, num_classes=6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# # CUSTOM word_id PICKLE\n",
    "# ##\n",
    "# X_train_custom = pickle.load(open('train_word_id_custom.p', 'rb'))\n",
    "# X_val_custom = pickle.load(open('val_word_id_custom.p', 'rb'))\n",
    "# X_test_custom = pickle.load(open('test_word_id_custom.p', 'rb'))\n",
    "#\n",
    "# X_train_custom = sequence.pad_sequences(X_train_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "# X_train_custom = sequence.pad_sequences(X_train_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "# X_train_custom = sequence.pad_sequences(X_train_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "#\n",
    "# X_train_spacy = pickle.load(open('train_word_id_spacy.p', 'rb'))\n",
    "# # X_val_custom = sequence.pad_sequences(X_val_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "# # X_test_custom = sequence.pad_sequences(X_val_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "#\n",
    "#\n",
    "# # Y_train_custom = train_data['output']\n",
    "# # Y_train_custom = keras.utils.to_categorical(Y_train_custom, num_classes=6)\n",
    "#\n",
    "# # Y_val_custom = val_data['output']\n",
    "# # Y_val_custom = keras.utils.to_categorical(Y_val_custom, num_classes=6)\n",
    "#\n",
    "# # X_train_custom = sequence.pad_sequences(X_train_custom, maxlen=num_steps, padding='post',truncating='post')\n",
    "# # X_val_custom = sequence.pad_sequences(X_val_custom, maxlen=num_steps, padding='post',truncating='post')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 350  425   28 ...    0    0    0]\n",
      " [  64    1 1930 ...    0    0    0]\n",
      " [   3  160  201 ...    0    0    0]\n",
      " ...\n",
      " [ 472 1547  191 ...  142  524  372]\n",
      " [   3 1406  928 ...   78    0    0]\n",
      " [   3   93    1 ...  258   43  107]]\n",
      "[[ 291  358   19 ...    0    0    0]\n",
      " [  45 1829  234 ...    0    0    0]\n",
      " [   1  125  157 ...    0    0    0]\n",
      " ...\n",
      " [ 405 1448  153 ...  106  451  310]\n",
      " [   1 1306  836 ...    0    0    0]\n",
      " [   1   64   34 ... 1571   89   77]]\n",
      "[[ 1 14  0 ...  0  0  0]\n",
      " [ 8 11  4 ... 10  0  0]\n",
      " [ 1  8  8 ...  0  0  0]\n",
      " ...\n",
      " [ 4 14  2 ...  2  0  1]\n",
      " [ 1 14  8 ...  1  5  1]\n",
      " [ 1 14  0 ... 14  5 11]]\n",
      "[[16  5  7 ...  0  0  0]\n",
      " [11  3  1 ... 12  0  0]\n",
      " [16 11 11 ...  0  0  0]\n",
      " ...\n",
      " [ 1  5  0 ...  0  7 16]\n",
      " [16  5 11 ... 16 10 16]\n",
      " [16  5  7 ... 13 10  3]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_custom)\n",
    "print(X_test_spacy)\n",
    "print(X_test_pos)\n",
    "print(X_test_pos_DEFAULT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# CUSTOM word_id numpy\n",
    "##\n",
    "\n",
    "# X_train_custom = pd.DataFrame(train_data['word_id_custom'])\n",
    "# X_val_custom = val_data['word_id_custom']\n",
    "# X_test_custom = test_data['word_id_custom']\n",
    "\n",
    "\n",
    "# X_train_custom = pickle.load(open('train_word_id_custom.p', 'rb'))\n",
    "X_train_custom_np = np.load('train_word_id_custom.npy', allow_pickle=True)\n",
    "# X_val_custom = val_data['word_id_custom'].apply(lambda x: x.split()).tolist()\n",
    "# X_test_custom = test_data['word_id_custom'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "\n",
    "# X_train_custom = sequence.pad_sequences(X_train_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "X_train_custom_np = sequence.pad_sequences(X_train_custom_np, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "# X_val_custom = sequence.pad_sequences(X_val_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "# X_test_custom = sequence.pad_sequences(X_val_custom, maxlen=num_steps, dtype=object, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "Y_train_custom = train_data['output']\n",
    "Y_train_custom = keras.utils.to_categorical(Y_train_custom, num_classes=6)\n",
    "\n",
    "Y_val_custom = val_data['output']\n",
    "Y_val_custom = keras.utils.to_categorical(Y_val_custom, num_classes=6)\n",
    "\n",
    "# X_train_custom = sequence.pad_sequences(X_train_custom, maxlen=num_steps, padding='post',truncating='post')\n",
    "# X_val_custom = sequence.pad_sequences(X_val_custom, maxlen=num_steps, padding='post',truncating='post')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 5440 717 ... 0.0 0.0 0.0]\n",
      " [37 9 804 ... 16 262 517]\n",
      " [104 69 734 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [3 2024 154 ... 24 1311 1173]\n",
      " [1604 28 13 ... 0.0 0.0 0.0]\n",
      " [216 1429 2087 ... 1195 430 184]]\n",
      "[[3 5440 717 ... 0.0 0.0 0.0]\n",
      " [37 9 804 ... 16 262 517]\n",
      " [104 69 734 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [3 2024 154 ... 24 1311 1173]\n",
      " [1604 28 13 ... 0.0 0.0 0.0]\n",
      " [216 1429 2087 ... 1195 430 184]]\n"
     ]
    }
   ],
   "source": [
    "# print(X_train_custom_pd)\n",
    "print(X_train_custom_np)\n",
    "print(X_train_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SPACY word_id\n",
    "##\n",
    "X_train_spacy = train_data['word_id_spacy'].apply(lambda x: x.split()).tolist()\n",
    "X_val_spacy = val_data['word_id_spacy'].apply(lambda x: x.split()).tolist()\n",
    "X_test_spacy = test_data['word_id_spacy'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "X_train_spacy = keras.utils.pad_sequences(X_train_spacy, maxlen=num_steps, dtype=object, padding='post',truncating='post')\n",
    "X_val_spacy = keras.utils.pad_sequences(X_val_spacy, maxlen=num_steps, dtype=object, padding='post',truncating='post')\n",
    "\n",
    "Y_train_spacy = train_data['output']\n",
    "Y_train_spacy = keras.utils.to_categorical(Y_train_spacy, num_classes=6)\n",
    "\n",
    "Y_val_spacy = val_data['output']\n",
    "Y_val_spacy = keras.utils.to_categorical(Y_val_spacy, num_classes=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X_train_pos_custom \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_data\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpos_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      2\u001B[0m X_val_pos_custom \u001B[38;5;241m=\u001B[39m val_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpos_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m X_test_pos_custom \u001B[38;5;241m=\u001B[39m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpos_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# CUSTOM POS\n",
    "X_train_pos_custom = train_data['pos_id']\n",
    "X_val_pos_custom = val_data['pos_id']\n",
    "X_test_pos_custom = test_data['pos_id']\n",
    "\n",
    "X_train_pos_custom = keras.utils.pad_sequences(X_train_pos_custom, maxlen=num_steps, padding='post')\n",
    "X_val_pos_custom = keras.utils.pad_sequences(X_val_pos_custom, maxlen=num_steps, padding='post')\n",
    "X_test_pos_custom = keras.utils.pad_sequences(X_test_pos_custom, maxlen=num_steps, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SPACY POS\n",
    "X_train_pos_spacy = train_data['pos_id_spacy']\n",
    "X_val_pos_spacy = val_data['pos_id_spacy']\n",
    "X_test_pos_spacy = test_data['pos_id_spacy']\n",
    "\n",
    "X_train_pos_spacy = keras.utils.pad_sequences(X_train_pos_spacy, maxlen=num_steps, padding='post')\n",
    "X_val_pos_spacy = keras.utils.pad_sequences(X_val_pos_spacy, maxlen=num_steps, padding='post')\n",
    "X_test_pos_spacy = keras.utils.pad_sequences(X_test_pos_spacy, maxlen=num_steps, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. fathan - pos tag check [ ]\n",
    "    - custom pos tag dict\n",
    "    - spacy preprocess - spacy word id\n",
    "    - glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_custom.shape, X_val_custom.shape, X_test_custom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train(model, name, use_pos=False, use_meta=False, use_dep=False):\n",
    "    sgd = optimizers.SGD(lr=0.025, clipvalue=0.3, nesterov=True)\n",
    "    adam = optimizers.Adam(lr=0.000075, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    tb = TensorBoard()\n",
    "    csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "    filepath = name + \"_weights_best.hdf5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    if use_pos and use_meta:\n",
    "        if use_dep:\n",
    "            model.fit(\n",
    "                {'main_input': X_train, 'pos_input': X_train_pos, 'aux_input': X_train_meta, 'dep_input': X_train_dep},\n",
    "                {'main_output': Y_train},\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(\n",
    "                    {'main_input': X_val, 'pos_input': X_val_pos, 'aux_input': X_val_meta, 'dep_input': X_val_dep},\n",
    "                    {'main_output': Y_val}),\n",
    "                callbacks=[tb, csv_logger, checkpoint])\n",
    "        else:\n",
    "            model.fit(\n",
    "                {'main_input': X_train, 'pos_input': X_train_pos, 'aux_input': X_train_meta},\n",
    "                {'main_output': Y_train},\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(\n",
    "                    {'main_input': X_val, 'pos_input': X_val_pos, 'aux_input': X_val_meta},\n",
    "                    {'main_output': Y_val}),\n",
    "                callbacks=[tb, csv_logger, checkpoint])\n",
    "    elif use_meta:\n",
    "        if use_dep:\n",
    "            model.fit(\n",
    "                {'main_input': X_train, 'aux_input': X_train_meta, 'dep_input': X_train_dep},\n",
    "                {'main_output': Y_train},\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(\n",
    "                    {'main_input': X_val, 'aux_input': X_val_meta, 'dep_input': X_val_dep},\n",
    "                    {'main_output': Y_val}),\n",
    "                callbacks=[tb, csv_logger, checkpoint])\n",
    "        else:\n",
    "            model.fit(\n",
    "                {'main_input': X_train, 'aux_input': X_train_meta},\n",
    "                {'main_output': Y_train},\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(\n",
    "                    {'main_input': X_val, 'aux_input': X_val_meta},\n",
    "                    {'main_output': Y_val}),\n",
    "                callbacks=[tb, csv_logger, checkpoint])\n",
    "    elif use_pos:\n",
    "        if use_dep:\n",
    "            model.fit(\n",
    "                {'main_input': X_train, 'pos_input': X_train_pos, 'dep_input': X_train_dep},\n",
    "                {'main_output': Y_train},\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(\n",
    "                    {'main_input': X_val, 'pos_input': X_val_pos, 'dep_input': X_val_dep},\n",
    "                    {'main_output': Y_val}),\n",
    "                callbacks=[tb, csv_logger, checkpoint])\n",
    "        else:\n",
    "            model.fit(\n",
    "                {'main_input': X_train, 'pos_input': X_train_pos},\n",
    "                {'main_output': Y_train},\n",
    "                epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(\n",
    "                    {'main_input': X_val, 'pos_input': X_val_pos},\n",
    "                    {'main_output': Y_val}),\n",
    "                callbacks=[tb, csv_logger, checkpoint])\n",
    "    else:\n",
    "        if use_dep:\n",
    "            model.fit(\n",
    "            {'main_input': X_train,'dep_input':X_train_dep},\n",
    "            {'main_output': Y_train}, epochs = num_epochs, batch_size = batch_size,\n",
    "            validation_data = (\n",
    "                                {'main_input': X_val, 'dep_input':X_val_dep},\n",
    "                                {'main_output': Y_val}\n",
    "                                ), callbacks=[tb,csv_logger,checkpoint])\n",
    "    else:\n",
    "      model.fit(\n",
    "        {'main_input': X_train},\n",
    "        {'main_output': Y_train}, epochs = num_epochs, batch_size = batch_size,\n",
    "        validation_data = (\n",
    "            {'main_input': X_val},\n",
    "            {'main_output': Y_val}\n",
    "        ), callbacks=[tb,csv_logger,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "use_pos=False\n",
    "use_meta=True\n",
    "use_dep=True\n",
    "\n",
    "# LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocab_length+1, hidden_size, input_length=num_steps))\n",
    "model_lstm.add(Bidirectional(LSTM(hidden_size)))\n",
    "model_lstm.add(Dense(6, activation='softmax'))\n",
    "\n",
    "\n",
    "# statement embed LSTM\n",
    "statement_input = Input(shape=(num_steps,), dtype='int32', name='main_input')\n",
    "x = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=num_steps,trainable=False)(statement_input)\n",
    "lstm_in = LSTM(lstm_size,dropout=0.2)(x)\n",
    "\n",
    "\n",
    "\n",
    "# pos embed LSTM\n",
    "pos_input = Input(shape=(num_steps,), dtype='int32', name='pos_input')\n",
    "x2 = Embedding(max(pos_dict.values()), max(pos_dict.values()), weights=[pos_embeddings], input_length=num_steps, trainable=False)(pos_input)\n",
    "lstm_in2 = LSTM(lstm_size, dropout=0.2)(x2)\n",
    "\n",
    "\n",
    "# dep embed LSTM\n",
    "dep_input = Input(shape=(num_steps,), dtype='int32', name='dep_input')\n",
    "x3 = Embedding(max(dep_dict.values()), max(dep_dict.values()), weights=[dep_embeddings], input_length=num_steps, trainable=False)(dep_input)\n",
    "lstm_in3 = LSTM(lstm_size, dropout=0.2)(x3)\n",
    "\n",
    "\n",
    "# meta data Dense\n",
    "meta_input = Input(shape=(X_train_meta.shape[1],), name='aux_input')\n",
    "x_meta = Dense(64, activation='relu')(meta_input)\n",
    "\n",
    "\n",
    "if use_pos and use_meta:\n",
    "  if use_dep:\n",
    "    x = keras.layers.concatenate([lstm_in, lstm_in2, lstm_in3, x_meta])\n",
    "  else:\n",
    "    x = keras.layers.concatenate([lstm_in, lstm_in2, x_meta])\n",
    "elif use_meta:\n",
    "  if use_dep:\n",
    "    x = keras.layers.concatenate([lstm_in, lstm_in3, x_meta])\n",
    "  else:\n",
    "    x = keras.layers.concatenate([lstm_in, x_meta])\n",
    "elif use_pos:\n",
    "  if use_dep:\n",
    "    x = keras.layers.concatenate([lstm_in, lstm_in3, lstm_in2])\n",
    "  else:\n",
    "    x = keras.layers.concatenate([lstm_in, lstm_in2])\n",
    "else:\n",
    "  if use_dep:\n",
    "    x = keras.layers.concatenate([lstm_in, lstm_in3])\n",
    "  else:\n",
    "    x = lstm_in\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "\n",
    "if use_pos and use_meta:\n",
    "  if use_dep:\n",
    "    model_lstm = Model(inputs=[statement_input, pos_input, dep_input, meta_input], outputs=[main_output])\n",
    "  else:\n",
    "    model_lstm = Model(inputs=[statement_input, pos_input, meta_input], outputs=[main_output])\n",
    "elif use_meta:\n",
    "  if use_dep:\n",
    "    model_lstm = Model(inputs=[statement_input, dep_input, meta_input], outputs=[main_output])\n",
    "  else:\n",
    "    model_lstm = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "elif use_pos:\n",
    "  if use_dep:\n",
    "    model_lstm = Model(inputs=[statement_input, dep_input, pos_input], outputs=[main_output])\n",
    "  else:\n",
    "    model_lstm = Model(inputs=[statement_input, pos_input], outputs=[main_output])\n",
    "else:\n",
    "  if use_dep:\n",
    "    model_lstm = Model(inputs=[statement_input, dep_input], outputs=[main_output])\n",
    "  else:\n",
    "    model_lstm = Model(inputs=[statement_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
