{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "import keras.utils\n",
    "import spacy\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense,Flatten,LSTM,Conv1D,GlobalMaxPool1D,Dropout,Bidirectional\n",
    "from keras.utils import pad_sequences\n",
    "from keras_preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from csv to pandas dataframe\n",
    "# train_data = pd.read_csv('processed_train_data.tsv', sep='\\t', index_col=0)\n",
    "# val_data = pd.read_csv('processed_val_data.tsv', sep='\\t', index_col=0)\n",
    "# test_data = pd.read_csv('processed_test_data.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Alternative way to load data - pickle to pandas dataframe\n",
    "# train_data = pd.read_pickle('processed_train_data.p')\n",
    "# val_data = pd.read_pickle('processed_val_data.p')\n",
    "# test_data = pd.read_pickle('processed_test_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id        label  \\\n0      0   2635.json        false   \n1      1  10540.json    half-true   \n2      2    324.json  mostly-true   \n3      3   1123.json        false   \n4      4   9028.json    half-true   \n\n                                           statement  \\\n0  Says the Annies List political group supports ...   \n1  When did the decline of coal start? It started...   \n2  Hillary Clinton agrees with John McCain \"by vo...   \n3  Health care reform legislation is likely to ma...   \n4  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job_title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                         \n4                        economy,jobs   charlie-crist                         \n\n  state_info       party  barely true  ...  party_id  context_id  \\\n0      Texas  republican          0.0  ...         0           2   \n1   Virginia    democrat          0.0  ...         1           2   \n2   Illinois    democrat         70.0  ...         1           8   \n3                   none          7.0  ...         2           0   \n4    Florida    democrat         15.0  ...         1           1   \n\n                                              pos_id  \\\n0      [2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]   \n1  [8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...   \n2  [9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...   \n3         [1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]   \n4               [15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]   \n\n                                      pos_id_DEFAULT  \\\n0   [17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]   \n1  [15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...   \n2  [12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...   \n3         [8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]   \n4               [6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]   \n\n                                    statement_custom  \\\n0  say annies list political group support third ...   \n1  when do decline coal start start when natural ...   \n2  hillary clinton agree john mccain vote give ge...   \n3  health care reform legislation be likely manda...   \n4                 economic turnaround start end term   \n\n                                     statement_spacy  \\\n0  say annies list political group support trimes...   \n1  decline coal start start natural gas take star...   \n2  hillary clinton agree john mccain vote george ...   \n3  health care reform legislation likely mandate ...   \n4                 economic turnaround start end term   \n\n                                      word_id_custom  \\\n0  [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1  [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2  [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3  [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                         [282, 3331, 308, 247, 248]   \n\n                                       word_id_spacy  \\\n0       [1, 5315, 633, 423, 332, 37, 3919, 120, 936]   \n1  [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...   \n2  [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...   \n3  [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]   \n4                         [224, 3208, 249, 198, 199]   \n\n                                              dep_id  \\\n0      [6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]   \n1  [10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...   \n2  [3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...   \n3          [3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]   \n4                 [4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]   \n\n                                       dep_id_custom  \n0      [7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]  \n1  [11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...  \n2  [4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...  \n3         [4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]  \n4                 [5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>...</th>\n      <th>party_id</th>\n      <th>context_id</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n      <th>dep_id</th>\n      <th>dep_id_custom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]</td>\n      <td>[17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n      <td>[6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]</td>\n      <td>[7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...</td>\n      <td>[15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n      <td>[10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...</td>\n      <td>[11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>8</td>\n      <td>[9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...</td>\n      <td>[12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n      <td>[3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...</td>\n      <td>[4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td></td>\n      <td></td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]</td>\n      <td>[8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n      <td>[3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]</td>\n      <td>[4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]</td>\n      <td>[6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n      <td>[4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]</td>\n      <td>[5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the vocabulary dictionary: 9606\n",
      "Shape of the embedding matrixes: (9607, 100) (9496, 300)\n"
     ]
    }
   ],
   "source": [
    "## LOAD SAVED DATA\n",
    "# load data\n",
    "train_data = pd.read_pickle('processed_train_data.p')\n",
    "val_data = pd.read_pickle('processed_val_data.p')\n",
    "test_data = pd.read_pickle('processed_test_data.p')\n",
    "\n",
    "# load vocab dicts\n",
    "vocabulary_dict_custom = pickle.load(open('vocabulary_statement_custom.p', 'rb'))\n",
    "vocabulary_dict_spacy = pickle.load(open('vocabulary_statement_spacy.p', 'rb'))\n",
    "vocab_length = len(vocabulary_dict_custom)\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length)\n",
    "\n",
    "# load embeddings matrixes\n",
    "embedding_matrix_custom_100d = np.load('embedding_matrix_custom_100d.npy')\n",
    "embedding_matrix_spacy_100d = np.load('embedding_matrix_spacy_100d.npy')\n",
    "embedding_matrix_custom_300d = np.load('embedding_matrix_custom_300d.npy')\n",
    "embedding_matrix_spacy_300d = np.load('embedding_matrix_spacy_300d.npy')\n",
    "print(\"Shape of the embedding matrixes:\", embedding_matrix_custom_100d.shape, embedding_matrix_spacy_300d.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load DEP_dict\n",
    "with open('dep_dict.p', 'rb') as f:\n",
    "    dep_dict, dep_dict_custom = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load POS dictionaries\n",
    "with open('pos_dicts.pickle', 'rb') as f:\n",
    "    pos_dict_custom, pos_dict_default = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       index          id        label  \\\n0          0   2635.json        false   \n1          1  10540.json    half-true   \n2          2    324.json  mostly-true   \n3          3   1123.json        false   \n4          4   9028.json    half-true   \n...      ...         ...          ...   \n10235  10235   5473.json  mostly-true   \n10236  10236   3408.json  mostly-true   \n10237  10237   3959.json    half-true   \n10238  10238   2253.json        false   \n10239  10239   1155.json   pants-fire   \n\n                                               statement  \\\n0      Says the Annies List political group supports ...   \n1      When did the decline of coal start? It started...   \n2      Hillary Clinton agrees with John McCain \"by vo...   \n3      Health care reform legislation is likely to ma...   \n4      The economic turnaround started at the end of ...   \n...                                                  ...   \n10235  There are a larger number of shark attacks in ...   \n10236  Democrats have now become the party of the [At...   \n10237  Says an alternative to Social Security that op...   \n10238  On lifting the U.S. Cuban embargo and allowing...   \n10239  The Department of Veterans Affairs has a manua...   \n\n                                  subject         speaker  \\\n0                                abortion    dwayne-bohac   \n1      energy,history,job-accomplishments  scott-surovell   \n2                          foreign-policy    barack-obama   \n3                             health-care    blog-posting   \n4                            economy,jobs   charlie-crist   \n...                                   ...             ...   \n10235                   animals,elections    aclu-florida   \n10236                           elections     alan-powell   \n10237          retirement,social-security     herman-cain   \n10238              florida,foreign-policy     jeff-greene   \n10239                health-care,veterans  michael-steele   \n\n                                           job_title state_info       party  \\\n0                               State representative      Texas  republican   \n1                                     State delegate   Virginia    democrat   \n2                                          President   Illinois    democrat   \n3                                                                      none   \n4                                                       Florida    democrat   \n...                                              ...        ...         ...   \n10235                                                   Florida        none   \n10236                                                   Georgia  republican   \n10237                                                   Georgia  republican   \n10238                                                   Florida    democrat   \n10239  chairman of the Republican National Committee   Maryland  republican   \n\n       barely true  ...  party_id  context_id  \\\n0              0.0  ...         0           2   \n1              0.0  ...         1           2   \n2             70.0  ...         1           8   \n3              7.0  ...         2           0   \n4             15.0  ...         1           1   \n...            ...  ...       ...         ...   \n10235          0.0  ...         2           1   \n10236          0.0  ...         0           0   \n10237          4.0  ...         0           7   \n10238          3.0  ...         1           7   \n10239          0.0  ...         0           1   \n\n                                                  pos_id  \\\n0          [2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]   \n1      [8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...   \n2      [9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...   \n3             [1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]   \n4                   [15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]   \n...                                                  ...   \n10235  [6, 2, 15, 3, 1, 5, 1, 1, 5, 9, 8, 6, 2, 1, 5,...   \n10236  [9, 12, 4, 2, 15, 1, 5, 15, 15, 9, 11, 9, 1, 1...   \n10237  [2, 15, 1, 5, 9, 9, 6, 2, 5, 9, 9, 11, 9, 11, ...   \n10238            [5, 2, 15, 9, 3, 1, 15, 2, 1, 5, 9, 11]   \n10239  [15, 9, 5, 9, 9, 2, 15, 1, 4, 4, 2, 6, 1, 1, 5...   \n\n                                          pos_id_DEFAULT  \\\n0       [17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]   \n1      [15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...   \n2      [12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...   \n3             [8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]   \n4                   [6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]   \n...                                                  ...   \n10235  [11, 17, 6, 1, 8, 2, 8, 8, 2, 12, 15, 11, 17, ...   \n10236  [12, 4, 3, 17, 6, 8, 2, 6, 14, 12, 13, 12, 8, ...   \n10237  [17, 6, 8, 2, 12, 12, 11, 17, 2, 12, 12, 13, 1...   \n10238         [2, 17, 6, 12, 1, 8, 17, 17, 8, 2, 12, 13]   \n10239  [6, 12, 2, 12, 12, 17, 6, 8, 3, 3, 17, 11, 8, ...   \n\n                                        statement_custom  \\\n0      say annies list political group support third ...   \n1      when do decline coal start start when natural ...   \n2      hillary clinton agree john mccain vote give ge...   \n3      health care reform legislation be likely manda...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  be large number shark attack florida than be c...   \n10236  democrats have now become party atlanta metro ...   \n10237  say alternative social security operate galves...   \n10238      lift u.s. cuban embargo and allow travel cuba   \n10239  department veterans affairs have manual out th...   \n\n                                         statement_spacy  \\\n0      say annies list political group support trimes...   \n1      decline coal start start natural gas take star...   \n2      hillary clinton agree john mccain vote george ...   \n3      health care reform legislation likely mandate ...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  large number shark attack florida case voter f...   \n10236           democrats party atlanta metro area black   \n10237  say alternative social security operate galves...   \n10238          lift u.s. cuban embargo allow travel cuba   \n10239  department veterans affairs manual tell vetera...   \n\n                                          word_id_custom  \\\n0      [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1      [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2      [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3      [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                             [282, 3331, 308, 247, 248]   \n...                                                  ...   \n10235  [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...   \n10236     [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]   \n10237  [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...   \n10238     [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]   \n10239  [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...   \n\n                                           word_id_spacy  \\\n0           [1, 5315, 633, 423, 332, 37, 3919, 120, 936]   \n1      [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...   \n2      [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...   \n3      [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]   \n4                             [224, 3208, 249, 198, 199]   \n...                                                  ...   \n10235           [126, 100, 5078, 257, 59, 344, 168, 482]   \n10236                    [122, 169, 397, 1298, 574, 325]   \n10237  [1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...   \n10238         [1503, 19, 7, 2738, 2994, 118, 1290, 1374]   \n10239  [172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...   \n\n                                                  dep_id  \\\n0          [6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]   \n1      [10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...   \n2      [3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...   \n3              [3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]   \n4                     [4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]   \n...                                                  ...   \n10235  [10, 6, 4, 7, 10, 1, 3, 2, 1, 2, 10, 10, 10, 1...   \n10236  [5, 9, 10, 6, 4, 10, 1, 4, 10, 10, 0, 3, 2, 10...   \n10237  [6, 4, 5, 1, 3, 2, 5, 10, 1, 3, 2, 0, 10, 0, 9...   \n10238           [6, 10, 4, 10, 7, 8, 10, 10, 8, 1, 2, 0]   \n10239  [4, 5, 1, 3, 2, 6, 4, 8, 10, 10, 10, 10, 10, 8...   \n\n                                           dep_id_custom  \n0          [7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]  \n1      [11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...  \n2      [4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...  \n3             [4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]  \n4                     [5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]  \n...                                                  ...  \n10235  [11, 7, 5, 8, 11, 2, 4, 3, 2, 3, 11, 11, 11, 1...  \n10236  [6, 10, 11, 7, 5, 11, 2, 5, 11, 11, 1, 4, 3, 1...  \n10237  [7, 5, 6, 2, 4, 3, 6, 11, 2, 4, 3, 1, 11, 1, 1...  \n10238           [7, 11, 5, 11, 8, 9, 11, 11, 9, 2, 3, 1]  \n10239  [5, 6, 2, 4, 3, 7, 5, 9, 11, 11, 11, 11, 11, 9...  \n\n[10240 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>...</th>\n      <th>party_id</th>\n      <th>context_id</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n      <th>dep_id</th>\n      <th>dep_id_custom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]</td>\n      <td>[17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n      <td>[6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]</td>\n      <td>[7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...</td>\n      <td>[15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n      <td>[10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...</td>\n      <td>[11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>8</td>\n      <td>[9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...</td>\n      <td>[12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n      <td>[3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...</td>\n      <td>[4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td></td>\n      <td></td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]</td>\n      <td>[8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n      <td>[3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]</td>\n      <td>[4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]</td>\n      <td>[6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n      <td>[4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]</td>\n      <td>[5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10235</th>\n      <td>10235</td>\n      <td>5473.json</td>\n      <td>mostly-true</td>\n      <td>There are a larger number of shark attacks in ...</td>\n      <td>animals,elections</td>\n      <td>aclu-florida</td>\n      <td></td>\n      <td>Florida</td>\n      <td>none</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[6, 2, 15, 3, 1, 5, 1, 1, 5, 9, 8, 6, 2, 1, 5,...</td>\n      <td>[11, 17, 6, 1, 8, 2, 8, 8, 2, 12, 15, 11, 17, ...</td>\n      <td>be large number shark attack florida than be c...</td>\n      <td>large number shark attack florida case voter f...</td>\n      <td>[1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...</td>\n      <td>[126, 100, 5078, 257, 59, 344, 168, 482]</td>\n      <td>[10, 6, 4, 7, 10, 1, 3, 2, 1, 2, 10, 10, 10, 1...</td>\n      <td>[11, 7, 5, 8, 11, 2, 4, 3, 2, 3, 11, 11, 11, 1...</td>\n    </tr>\n    <tr>\n      <th>10236</th>\n      <td>10236</td>\n      <td>3408.json</td>\n      <td>mostly-true</td>\n      <td>Democrats have now become the party of the [At...</td>\n      <td>elections</td>\n      <td>alan-powell</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[9, 12, 4, 2, 15, 1, 5, 15, 15, 9, 11, 9, 1, 1...</td>\n      <td>[12, 4, 3, 17, 6, 8, 2, 6, 14, 12, 13, 12, 8, ...</td>\n      <td>democrats have now become party atlanta metro ...</td>\n      <td>democrats party atlanta metro area black</td>\n      <td>[157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]</td>\n      <td>[122, 169, 397, 1298, 574, 325]</td>\n      <td>[5, 9, 10, 6, 4, 10, 1, 4, 10, 10, 0, 3, 2, 10...</td>\n      <td>[6, 10, 11, 7, 5, 11, 2, 5, 11, 11, 1, 4, 3, 1...</td>\n    </tr>\n    <tr>\n      <th>10237</th>\n      <td>10237</td>\n      <td>3959.json</td>\n      <td>half-true</td>\n      <td>Says an alternative to Social Security that op...</td>\n      <td>retirement,social-security</td>\n      <td>herman-cain</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>[2, 15, 1, 5, 9, 9, 6, 2, 5, 9, 9, 11, 9, 11, ...</td>\n      <td>[17, 6, 8, 2, 12, 12, 11, 17, 2, 12, 12, 13, 1...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>[3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...</td>\n      <td>[1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...</td>\n      <td>[6, 4, 5, 1, 3, 2, 5, 10, 1, 3, 2, 0, 10, 0, 9...</td>\n      <td>[7, 5, 6, 2, 4, 3, 6, 11, 2, 4, 3, 1, 11, 1, 1...</td>\n    </tr>\n    <tr>\n      <th>10238</th>\n      <td>10238</td>\n      <td>2253.json</td>\n      <td>false</td>\n      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n      <td>florida,foreign-policy</td>\n      <td>jeff-greene</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>7</td>\n      <td>[5, 2, 15, 9, 3, 1, 15, 2, 1, 5, 9, 11]</td>\n      <td>[2, 17, 6, 12, 1, 8, 17, 17, 8, 2, 12, 13]</td>\n      <td>lift u.s. cuban embargo and allow travel cuba</td>\n      <td>lift u.s. cuban embargo allow travel cuba</td>\n      <td>[1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]</td>\n      <td>[1503, 19, 7, 2738, 2994, 118, 1290, 1374]</td>\n      <td>[6, 10, 4, 10, 7, 8, 10, 10, 8, 1, 2, 0]</td>\n      <td>[7, 11, 5, 11, 8, 9, 11, 11, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>10239</th>\n      <td>10239</td>\n      <td>1155.json</td>\n      <td>pants-fire</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>health-care,veterans</td>\n      <td>michael-steele</td>\n      <td>chairman of the Republican National Committee</td>\n      <td>Maryland</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[15, 9, 5, 9, 9, 2, 15, 1, 4, 4, 2, 6, 1, 1, 5...</td>\n      <td>[6, 12, 2, 12, 12, 17, 6, 8, 3, 3, 17, 11, 8, ...</td>\n      <td>department veterans affairs have manual out th...</td>\n      <td>department veterans affairs manual tell vetera...</td>\n      <td>[216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...</td>\n      <td>[172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...</td>\n      <td>[4, 5, 1, 3, 2, 6, 4, 8, 10, 10, 10, 10, 10, 8...</td>\n      <td>[5, 6, 2, 4, 3, 7, 5, 9, 11, 11, 11, 11, 11, 9...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10240 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## to test the different preprocessing methods, the following experiments will be run:\n",
    "1. siddarth - baseline\n",
    "\n",
    "        - ogdict\n",
    "        - nltk stopword removal only\n",
    "\n",
    "****\n",
    "****\n",
    "\n",
    "## todo\n",
    "****\n",
    "### INITIALISE INPUT/OUTPUT\n",
    "1. [x] word_id custom AS X_train_custom\n",
    "  - [x] embedding_matrix_custom\n",
    "  - [x] vocabulary_dict_custom\n",
    "2. [x] word_id spacy AS X_train_spacy\n",
    "  - [x] embedding_matrix_spacy\n",
    "  - [x] vocabulary_dict_spacy\n",
    "  \n",
    "3. [x] pos_id custom AS X_train_pos_custom\n",
    "4. [x] pos_id spacy AS X_train_pos_spacy\n",
    "    \n",
    "#### Input variables to be processed: \n",
    "- [x] meta\n",
    "- [ ] dep parse\n",
    "\n",
    "****\n",
    "### GENERAL\n",
    "- [x] change everything to python 3\n",
    "\n",
    "### variables, init, etc.\n",
    "- [x] pass in vocabulary.p\n",
    "****\n",
    "### BILSTM MODEL\n",
    "- [x] functions: train(), etc\n",
    "        (CODE CELLS COULD BE BETTER, INVESTIGATE)\n",
    "- [ ] verify varibales are correct\n",
    "\n",
    "****\n",
    "*decide which word id to use*\n",
    "- [x] jaccard similarity\n",
    "\n",
    "1. fathan - pos tag check [ ]\n",
    "    - custom pos tag dict\n",
    "    - spacy preprocess - spacy word id\n",
    "    - glove\n",
    " 2. fathan - preprocess [ ]\n",
    "    - custom pos tag dict\n",
    "    - custom preprocess - custom word id\n",
    "    - glove\n",
    "    * check best results with default pos tag [ ]\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "# HYPERPARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 1 with size 18",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m num_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(num_state)\n\u001B[1;32m----> 3\u001B[0m state_train \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstate_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_state\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\np_utils.py:73\u001B[0m, in \u001B[0;36mto_categorical\u001B[1;34m(y, num_classes, dtype)\u001B[0m\n\u001B[0;32m     71\u001B[0m n \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     72\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((n, num_classes), dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m---> 73\u001B[0m categorical[np\u001B[38;5;241m.\u001B[39marange(n), y] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     74\u001B[0m output_shape \u001B[38;5;241m=\u001B[39m input_shape \u001B[38;5;241m+\u001B[39m (num_classes,)\n\u001B[0;32m     75\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(categorical, output_shape)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 20 is out of bounds for axis 1 with size 18"
     ]
    }
   ],
   "source": [
    "# num_state = len(train_data['state_id'].unique())\n",
    "# print(num_state)\n",
    "# state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=num_state)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "18\n",
      "18\n",
      "19\n",
      "25\n",
      "26\n",
      "Index(['index', 'id', 'label', 'statement', 'subject', 'speaker', 'job_title',\n",
      "       'state_info', 'party', 'barely true', 'false', 'half-true',\n",
      "       'mostly-true', 'pants-on-fire', 'context', 'output', 'subject_id',\n",
      "       'speaker_id', 'job_id', 'state_id', 'party_id', 'context_id', 'pos_id',\n",
      "       'pos_id_DEFAULT', 'statement_custom', 'statement_spacy',\n",
      "       'word_id_custom', 'word_id_spacy', 'dep_id', 'dep_id_custom'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 100d GLOVE\n",
    "EMBED_DIM = 100\n",
    "\n",
    "# vocab_length = len(vocabulary_dict.keys())\n",
    "custom_vocabLen = len(vocabulary_dict_custom.keys())\n",
    "spacy_vocabLen = len(vocabulary_dict_spacy.keys())\n",
    "hidden_size = EMBED_DIM #Has to be same as EMBED_DIM\n",
    "lstm_size = 100\n",
    "num_steps = 30\n",
    "num_epochs = 30\n",
    "batch_size = 40\n",
    "\n",
    "# embedding_matrix = embedding_matrix_custom_100d\n",
    "\n",
    "#Meta data related hyper params\n",
    "num_party = len(train_data.party_id.unique())\n",
    "num_state = len(train_data['state_id'].unique())\n",
    "num_context = len(train_data['context_id'].unique())\n",
    "num_job = len(train_data['job_id'].unique())\n",
    "num_sub = len(train_data['subject_id'].unique())\n",
    "num_speaker = len(train_data['speaker_id'].unique())\n",
    "\n",
    "print(num_party)\n",
    "print(num_state)\n",
    "print(num_context)\n",
    "print(num_job)\n",
    "print(num_sub)\n",
    "print(num_speaker)\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...\n",
      "1        [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...\n",
      "2        [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...\n",
      "3        [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...\n",
      "4                               [282, 3331, 308, 247, 248]\n",
      "                               ...                        \n",
      "10235    [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...\n",
      "10236       [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]\n",
      "10237    [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...\n",
      "10238       [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]\n",
      "10239    [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...\n",
      "Name: word_id_custom, Length: 10240, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['word_id_custom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            [6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]\n",
      "1        [10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...\n",
      "2        [3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...\n",
      "3                [3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]\n",
      "4                       [4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]\n",
      "                               ...                        \n",
      "10235    [10, 6, 4, 7, 10, 1, 3, 2, 1, 2, 10, 10, 10, 1...\n",
      "10236    [5, 9, 10, 6, 4, 10, 1, 4, 10, 10, 0, 3, 2, 10...\n",
      "10237    [6, 4, 5, 1, 3, 2, 5, 10, 1, 3, 2, 0, 10, 0, 9...\n",
      "10238             [6, 10, 4, 10, 7, 8, 10, 10, 8, 1, 2, 0]\n",
      "10239    [4, 5, 1, 3, 2, 6, 4, 8, 10, 10, 10, 10, 10, 8...\n",
      "Name: dep_id, Length: 10240, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['dep_id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        1\n",
      "3        2\n",
      "4        1\n",
      "        ..\n",
      "10235    2\n",
      "10236    0\n",
      "10237    0\n",
      "10238    1\n",
      "10239    0\n",
      "Name: party_id, Length: 10240, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['party_id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input/Output Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# party_train = keras.utils.to_categorical(train_data['party_id'], num_classes=11)\n",
    "# state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=51)\n",
    "# context_train = keras.utils.to_categorical(train_data['context_id'], num_classes=21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# party_train = keras.utils.to_categorical(train_data['party_id'], num_classes=11)\n",
    "# state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=21)\n",
    "# context_train = keras.utils.to_categorical(train_data['context_id'], num_classes=21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apr 6 TODO:\n",
    "    - [ ] fix the input shape for the meta data, as num_party is 11, not 9.\n",
    "            - num_party = len(train_data.party_id.unique()) returns 9 instead of 11.\n",
    "            - or is it expecting 11 wrongly and party_id number of labels should be"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Meta data preparation\n",
    "party_train = keras.utils.to_categorical(train_data['party_id'], num_classes=num_party+2)\n",
    "state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=num_state+3)\n",
    "context_train = keras.utils.to_categorical(train_data['context_id'], num_classes=num_context+3)\n",
    "job_train = keras.utils.to_categorical(train_data['job_id'], num_classes=num_job+3)\n",
    "subject_train = keras.utils.to_categorical(train_data['subject_id'], num_classes=num_sub+3)\n",
    "speaker_train = keras.utils.to_categorical(train_data['speaker_id'], num_classes=num_speaker+2)\n",
    "\n",
    "\n",
    "party_val = keras.utils.to_categorical(val_data['party_id'], num_classes=num_party+2)\n",
    "state_val = keras.utils.to_categorical(val_data['state_id'], num_classes=num_state+3)\n",
    "context_val = keras.utils.to_categorical(val_data['context_id'], num_classes=num_context+3)\n",
    "job_val = keras.utils.to_categorical(val_data['job_id'], num_classes=num_job+3)\n",
    "subject_val = keras.utils.to_categorical(val_data['subject_id'], num_classes=num_sub+3)\n",
    "speaker_val = keras.utils.to_categorical(val_data['speaker_id'], num_classes=num_speaker+2)\n",
    "\n",
    "\n",
    "party_test = keras.utils.to_categorical(test_data['party_id'], num_classes=num_party+2)\n",
    "state_test = keras.utils.to_categorical(test_data['state_id'], num_classes=num_state+3)\n",
    "context_test = keras.utils.to_categorical(test_data['context_id'], num_classes=num_context+3)\n",
    "job_test = keras.utils.to_categorical(test_data['job_id'], num_classes=num_job+3)\n",
    "subject_test = keras.utils.to_categorical(test_data['subject_id'], num_classes=num_sub+3)\n",
    "speaker_test = keras.utils.to_categorical(test_data['speaker_id'], num_classes=num_speaker+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def input_pad_sequences(data):\n",
    "    padded_data = sequence.pad_sequences(data, maxlen=num_steps, padding='post', truncating='post')\n",
    "    return padded_data\n",
    "\n",
    "X_train_custom = input_pad_sequences(train_data['word_id_custom'])\n",
    "X_val_custom = input_pad_sequences(val_data['word_id_custom'])\n",
    "X_test_custom = input_pad_sequences(test_data['word_id_custom'])\n",
    "\n",
    "X_train_spacy = input_pad_sequences(train_data['word_id_spacy'])\n",
    "X_val_spacy = input_pad_sequences(val_data['word_id_spacy'])\n",
    "X_test_spacy = input_pad_sequences(test_data['word_id_spacy'])\n",
    "\n",
    "X_train_pos_custom = input_pad_sequences(train_data['pos_id'])\n",
    "X_val_pos_custom = input_pad_sequences(val_data['pos_id'])\n",
    "X_test_pos_custom = input_pad_sequences(test_data['pos_id'])\n",
    "\n",
    "X_train_pos_DEFAULT = input_pad_sequences(train_data['pos_id_DEFAULT'])\n",
    "X_val_pos_DEFAULT = input_pad_sequences(val_data['pos_id_DEFAULT'])\n",
    "X_test_pos_DEFAULT = input_pad_sequences(test_data['pos_id_DEFAULT'])\n",
    "\n",
    "X_train_meta = np.hstack((party_train,\n",
    "                          state_train,\n",
    "                          context_train,\n",
    "                          job_train,\n",
    "                          subject_train,\n",
    "                          speaker_train))\n",
    "\n",
    "X_val_meta = np.hstack((party_val,\n",
    "                        state_val,\n",
    "                        context_val,\n",
    "                        job_val,\n",
    "                        subject_val,\n",
    "                        speaker_val))\n",
    "\n",
    "X_test_meta = np.hstack((party_test,\n",
    "                         state_test,\n",
    "                         context_test,\n",
    "                         job_test,\n",
    "                         subject_test,\n",
    "                         speaker_test))\n",
    "\n",
    "X_train_dep = input_pad_sequences(train_data['dep_id_custom'])\n",
    "X_val_dep = input_pad_sequences(val_data['dep_id_custom'])\n",
    "X_test_dep = input_pad_sequences(test_data['dep_id_custom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   index          id        label  \\\n0      0   2635.json        false   \n1      1  10540.json    half-true   \n2      2    324.json  mostly-true   \n3      3   1123.json        false   \n4      4   9028.json    half-true   \n\n                                           statement  \\\n0  Says the Annies List political group supports ...   \n1  When did the decline of coal start? It started...   \n2  Hillary Clinton agrees with John McCain \"by vo...   \n3  Health care reform legislation is likely to ma...   \n4  The economic turnaround started at the end of ...   \n\n                              subject         speaker             job_title  \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                         \n4                        economy,jobs   charlie-crist                         \n\n  state_info       party  barely true  ...  party_id  context_id  \\\n0      Texas  republican          0.0  ...         0           2   \n1   Virginia    democrat          0.0  ...         1           2   \n2   Illinois    democrat         70.0  ...         1           8   \n3                   none          7.0  ...         2           0   \n4    Florida    democrat         15.0  ...         1           1   \n\n                                              pos_id  \\\n0      [2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]   \n1  [8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...   \n2  [9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...   \n3         [1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]   \n4               [15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]   \n\n                                      pos_id_DEFAULT  \\\n0   [17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]   \n1  [15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...   \n2  [12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...   \n3         [8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]   \n4               [6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]   \n\n                                    statement_custom  \\\n0  say annies list political group support third ...   \n1  when do decline coal start start when natural ...   \n2  hillary clinton agree john mccain vote give ge...   \n3  health care reform legislation be likely manda...   \n4                 economic turnaround start end term   \n\n                                     statement_spacy  \\\n0  say annies list political group support trimes...   \n1  decline coal start start natural gas take star...   \n2  hillary clinton agree john mccain vote george ...   \n3  health care reform legislation likely mandate ...   \n4                 economic turnaround start end term   \n\n                                      word_id_custom  \\\n0  [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1  [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2  [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3  [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                         [282, 3331, 308, 247, 248]   \n\n                                       word_id_spacy  \\\n0       [1, 5315, 633, 423, 332, 37, 3919, 120, 936]   \n1  [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...   \n2  [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...   \n3  [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]   \n4                         [224, 3208, 249, 198, 199]   \n\n                                              dep_id  \\\n0      [6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]   \n1  [10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...   \n2  [3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...   \n3          [3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]   \n4                 [4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]   \n\n                                       dep_id_custom  \n0      [7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]  \n1  [11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...  \n2  [4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...  \n3         [4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]  \n4                 [5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>...</th>\n      <th>party_id</th>\n      <th>context_id</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n      <th>dep_id</th>\n      <th>dep_id_custom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]</td>\n      <td>[17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n      <td>[6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]</td>\n      <td>[7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...</td>\n      <td>[15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n      <td>[10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...</td>\n      <td>[11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>8</td>\n      <td>[9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...</td>\n      <td>[12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n      <td>[3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...</td>\n      <td>[4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td></td>\n      <td></td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]</td>\n      <td>[8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n      <td>[3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]</td>\n      <td>[4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]</td>\n      <td>[6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n      <td>[4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]</td>\n      <td>[5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_dep.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 15  9 ...  0  0  0]\n",
      " [ 8  2 15 ... 11  0  0]\n",
      " [ 9  9  2 ...  0  0  0]\n",
      " ...\n",
      " [ 2 15  1 ...  5  9  9]\n",
      " [ 5  2 15 ...  0  0  0]\n",
      " [15  9  5 ...  6  2 11]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pos_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 131) (1284, 131) (1267, 131)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_meta.shape, X_val_meta.shape, X_test_meta.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialise input/output\n",
    "\n",
    "## OUTPUT\n",
    "Y_train = train_data['output']\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=6)\n",
    "\n",
    "Y_val = val_data['output']\n",
    "Y_val = keras.utils.to_categorical(Y_val, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 350  425   28 ...    0    0    0]\n",
      " [  64    1 1930 ...    0    0    0]\n",
      " [   3  160  201 ...    0    0    0]\n",
      " ...\n",
      " [ 472 1547  191 ...    0    0    0]\n",
      " [   3 1406  928 ...    0    0    0]\n",
      " [   3   93    1 ...    0    0    0]]\n",
      "[[ 291  358   19 ...    0    0    0]\n",
      " [  45 1829  234 ...    0    0    0]\n",
      " [   1  125  157 ...    0    0    0]\n",
      " ...\n",
      " [ 405 1448  153 ...    0    0    0]\n",
      " [   1 1306  836 ...    0    0    0]\n",
      " [   1   64   34 ...    0    0    0]]\n",
      "[[ 2 15  1 ...  0  0  0]\n",
      " [ 9 12  5 ...  0  0  0]\n",
      " [ 2  9  9 ...  0  0  0]\n",
      " ...\n",
      " [ 5 15  3 ...  0  0  0]\n",
      " [ 2 15  9 ...  0  0  0]\n",
      " [ 2 15  1 ...  3  1  1]]\n",
      "[[17  6  8 ...  0  0  0]\n",
      " [12  4  2 ...  0  0  0]\n",
      " [17 12 12 ...  0  0  0]\n",
      " ...\n",
      " [ 2  6  1 ...  0  0  0]\n",
      " [17  6 12 ...  0  0  0]\n",
      " [17  6  8 ...  1  8  8]]\n",
      "[[1. 0. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_custom)\n",
    "print(X_test_spacy)\n",
    "print(X_test_pos_custom)\n",
    "print(X_test_pos_DEFAULT)\n",
    "print(X_train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 30) (1284, 30) (1267, 30)\n",
      "(10240, 30) (1284, 30) (1267, 30)\n",
      "(10240, 30) (1284, 30) (1267, 30)\n",
      "(10240, 30) (1284, 30) (1267, 30)\n",
      "(10240, 6) (1284, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_custom.shape, X_val_custom.shape, X_test_custom.shape)\n",
    "print(X_train_spacy.shape, X_val_spacy.shape, X_test_spacy.shape)\n",
    "print(X_train_pos_custom.shape, X_val_pos_custom.shape, X_test_pos_custom.shape)\n",
    "print(X_train_pos_DEFAULT.shape, X_val_pos_DEFAULT.shape, X_test_pos_DEFAULT.shape)\n",
    "print(Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. fathan - pos tag check [ ]\n",
    "    - custom word id [ ]\n",
    "    - custom pos id [ ]\n",
    "    - glove [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in the input data: 15\n"
     ]
    }
   ],
   "source": [
    "max_value = max(np.max(X_train_pos_custom), np.max(X_val_pos_custom))\n",
    "print(\"Maximum value in the input data:\", max_value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def train(model, name, train_inputs, val_inputs, optimizer, output_name):\n",
    "    \"\"\"\n",
    "    Trains the given model with the provided input tensors.\n",
    "\n",
    "    :param model: {tf.keras.Model} model to be trained\n",
    "    :param name: {str} model name used for saving best weights\n",
    "    :param train_inputs: {dict} dictionary containing training input tensors\n",
    "    :param val_inputs: {dict} dictionary containing validation input tensors\n",
    "    :param optimizer: {keras.optimizers} optimizer to be used\n",
    "    :param output_name: {str} main output name used in the model\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    tb = TensorBoard()\n",
    "    csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = f\"{name}_weights_best_{timestamp}.hdf5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy',\n",
    "                                                  verbose=1, save_best_only=True, mode='max', save_freq='epoch')\n",
    "\n",
    "    model.fit(\n",
    "        train_inputs,\n",
    "        {output_name: Y_train},\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(val_inputs, {output_name: Y_val}),\n",
    "        callbacks=[tb, csv_logger, checkpoint]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def print_best_false_true_predicted(fw, tb):\n",
    "  sorted_false = sorted(fw.items(), key=operator.itemgetter(1), reverse=True)\n",
    "  sorted_true = sorted(tb.items(), key=operator.itemgetter(1), reverse=True)\n",
    "  print('*****************************************************************')\n",
    "  print('******************** False statements *************************')\n",
    "\n",
    "  for t in sorted_false[:5]:\n",
    "    print(t[1])\n",
    "    print(test_data.loc[t[0]])\n",
    "    print('=============')\n",
    "  print('*****************************************************************')\n",
    "  print('******************** True Statements *************************')\n",
    "  for t in sorted_true[:5]:\n",
    "    print(t[1])\n",
    "    print(test_data.loc[t[0]])\n",
    "    print('=============')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_accuracy(predictions, Y_test_gt):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the predictions\n",
    "\n",
    "    :param predictions: {np.array} predicted values\n",
    "    :param Y_test_gt: {np.array} ground truth values\n",
    "\n",
    "    :return: accuracy {float} accuracy of the predictions\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == Y_test_gt[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(predictions)\n",
    "    return accuracy\n",
    "\n",
    "def extract_fw_tb(preds):\n",
    "    \"\"\"\n",
    "    Extracts the worst false predictions and the best true predictions\n",
    "\n",
    "    :param preds: {np.array} array of predicted values\n",
    "\n",
    "    :return: false_worst: {dict} dictionary of worst false predictions\n",
    "    :return: true_best: {dict} dictionary of best true predictions\n",
    "    \"\"\"\n",
    "    false_worst = {}\n",
    "    true_best = {}\n",
    "\n",
    "    for p in range(len(preds)):\n",
    "        if np.argmax(preds[p])==0:\n",
    "            false_worst[p]=preds[p][0]\n",
    "        elif np.argmax(preds[p])==5:\n",
    "            true_best[p]=preds[p][5]\n",
    "\n",
    "    return false_worst, true_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def load_and_predict(model_filename, inputs):\n",
    "    \"\"\"\n",
    "    Load the model and predict with the provided inputs\n",
    "\n",
    "    :param name: {str} name of the model to load the model weights\n",
    "    :param inputs: {dict} dictionary of inputs to be passed to the model\n",
    "\n",
    "    :return: preds {np.array} array of predicted values/\n",
    "    \"\"\"\n",
    "    model = load_model(model_filename)\n",
    "    preds = model.predict(inputs,\n",
    "                          batch_size=batch_size,\n",
    "                          verbose=1)\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model_name, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluates the given model with provided input tensors\n",
    "\n",
    "    :param model_name: {str} used to load model weights\n",
    "    :param args: {list} of dictionaries of inputs\n",
    "    :param kwargs:\n",
    "\n",
    "    :return: false_worst: {dict} of the worst false predictions\n",
    "    :return: true_best: {dict} of the best true predictions\n",
    "    \"\"\"\n",
    "    inputs = {}\n",
    "    for arg in args:\n",
    "        inputs.update(arg)\n",
    "    inputs.update(kwargs)\n",
    "\n",
    "    preds = load_and_predict(model_name, inputs)\n",
    "\n",
    "    Y_test_groundtruth = list(test_data['output'])\n",
    "    predictions = np.array([np.argmax(pred) for pred in preds])\n",
    "\n",
    "    accuracy = calculate_accuracy(predictions, Y_test_groundtruth)\n",
    "    print(\"Correctly Predicted: \", np.sum(predictions == Y_test_groundtruth), \"/\", len(Y_test_groundtruth))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "    false_worst, true_best = extract_fw_tb(preds)\n",
    "\n",
    "    pickle.dump(predictions, open(model_name + \"_predictions.p\", \"wb\"))\n",
    "    return false_worst, true_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# model_name = \"bilstm\"\n",
    "#\n",
    "# for config in configurations:\n",
    "#     print(f\"Running {config['name']}...\")\n",
    "#     (fw, tb) = evaluate(model_name, *config[\"inputs\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "       index          id        label  \\\n0          0   2635.json        false   \n1          1  10540.json    half-true   \n2          2    324.json  mostly-true   \n3          3   1123.json        false   \n4          4   9028.json    half-true   \n...      ...         ...          ...   \n10235  10235   5473.json  mostly-true   \n10236  10236   3408.json  mostly-true   \n10237  10237   3959.json    half-true   \n10238  10238   2253.json        false   \n10239  10239   1155.json   pants-fire   \n\n                                               statement  \\\n0      Says the Annies List political group supports ...   \n1      When did the decline of coal start? It started...   \n2      Hillary Clinton agrees with John McCain \"by vo...   \n3      Health care reform legislation is likely to ma...   \n4      The economic turnaround started at the end of ...   \n...                                                  ...   \n10235  There are a larger number of shark attacks in ...   \n10236  Democrats have now become the party of the [At...   \n10237  Says an alternative to Social Security that op...   \n10238  On lifting the U.S. Cuban embargo and allowing...   \n10239  The Department of Veterans Affairs has a manua...   \n\n                                  subject         speaker  \\\n0                                abortion    dwayne-bohac   \n1      energy,history,job-accomplishments  scott-surovell   \n2                          foreign-policy    barack-obama   \n3                             health-care    blog-posting   \n4                            economy,jobs   charlie-crist   \n...                                   ...             ...   \n10235                   animals,elections    aclu-florida   \n10236                           elections     alan-powell   \n10237          retirement,social-security     herman-cain   \n10238              florida,foreign-policy     jeff-greene   \n10239                health-care,veterans  michael-steele   \n\n                                           job_title state_info       party  \\\n0                               State representative      Texas  republican   \n1                                     State delegate   Virginia    democrat   \n2                                          President   Illinois    democrat   \n3                                                                      none   \n4                                                       Florida    democrat   \n...                                              ...        ...         ...   \n10235                                                   Florida        none   \n10236                                                   Georgia  republican   \n10237                                                   Georgia  republican   \n10238                                                   Florida    democrat   \n10239  chairman of the Republican National Committee   Maryland  republican   \n\n       barely true  ...  party_id  context_id  \\\n0              0.0  ...         0           2   \n1              0.0  ...         1           2   \n2             70.0  ...         1           8   \n3              7.0  ...         2           0   \n4             15.0  ...         1           1   \n...            ...  ...       ...         ...   \n10235          0.0  ...         2           1   \n10236          0.0  ...         0           0   \n10237          4.0  ...         0           7   \n10238          3.0  ...         1           7   \n10239          0.0  ...         0           1   \n\n                                                  pos_id  \\\n0          [2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]   \n1      [8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...   \n2      [9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...   \n3             [1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]   \n4                   [15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]   \n...                                                  ...   \n10235  [6, 2, 15, 3, 1, 5, 1, 1, 5, 9, 8, 6, 2, 1, 5,...   \n10236  [9, 12, 4, 2, 15, 1, 5, 15, 15, 9, 11, 9, 1, 1...   \n10237  [2, 15, 1, 5, 9, 9, 6, 2, 5, 9, 9, 11, 9, 11, ...   \n10238            [5, 2, 15, 9, 3, 1, 15, 2, 1, 5, 9, 11]   \n10239  [15, 9, 5, 9, 9, 2, 15, 1, 4, 4, 2, 6, 1, 1, 5...   \n\n                                          pos_id_DEFAULT  \\\n0       [17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]   \n1      [15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...   \n2      [12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...   \n3             [8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]   \n4                   [6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]   \n...                                                  ...   \n10235  [11, 17, 6, 1, 8, 2, 8, 8, 2, 12, 15, 11, 17, ...   \n10236  [12, 4, 3, 17, 6, 8, 2, 6, 14, 12, 13, 12, 8, ...   \n10237  [17, 6, 8, 2, 12, 12, 11, 17, 2, 12, 12, 13, 1...   \n10238         [2, 17, 6, 12, 1, 8, 17, 17, 8, 2, 12, 13]   \n10239  [6, 12, 2, 12, 12, 17, 6, 8, 3, 3, 17, 11, 8, ...   \n\n                                        statement_custom  \\\n0      say annies list political group support third ...   \n1      when do decline coal start start when natural ...   \n2      hillary clinton agree john mccain vote give ge...   \n3      health care reform legislation be likely manda...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  be large number shark attack florida than be c...   \n10236  democrats have now become party atlanta metro ...   \n10237  say alternative social security operate galves...   \n10238      lift u.s. cuban embargo and allow travel cuba   \n10239  department veterans affairs have manual out th...   \n\n                                         statement_spacy  \\\n0      say annies list political group support trimes...   \n1      decline coal start start natural gas take star...   \n2      hillary clinton agree john mccain vote george ...   \n3      health care reform legislation likely mandate ...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  large number shark attack florida case voter f...   \n10236           democrats party atlanta metro area black   \n10237  say alternative social security operate galves...   \n10238          lift u.s. cuban embargo allow travel cuba   \n10239  department veterans affairs manual tell vetera...   \n\n                                          word_id_custom  \\\n0      [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1      [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2      [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3      [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                             [282, 3331, 308, 247, 248]   \n...                                                  ...   \n10235  [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...   \n10236     [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]   \n10237  [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...   \n10238     [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]   \n10239  [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...   \n\n                                           word_id_spacy  \\\n0           [1, 5315, 633, 423, 332, 37, 3919, 120, 936]   \n1      [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...   \n2      [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...   \n3      [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]   \n4                             [224, 3208, 249, 198, 199]   \n...                                                  ...   \n10235           [126, 100, 5078, 257, 59, 344, 168, 482]   \n10236                    [122, 169, 397, 1298, 574, 325]   \n10237  [1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...   \n10238         [1503, 19, 7, 2738, 2994, 118, 1290, 1374]   \n10239  [172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...   \n\n                                                  dep_id  \\\n0          [6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]   \n1      [10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...   \n2      [3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...   \n3              [3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]   \n4                     [4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]   \n...                                                  ...   \n10235  [10, 6, 4, 7, 10, 1, 3, 2, 1, 2, 10, 10, 10, 1...   \n10236  [5, 9, 10, 6, 4, 10, 1, 4, 10, 10, 0, 3, 2, 10...   \n10237  [6, 4, 5, 1, 3, 2, 5, 10, 1, 3, 2, 0, 10, 0, 9...   \n10238           [6, 10, 4, 10, 7, 8, 10, 10, 8, 1, 2, 0]   \n10239  [4, 5, 1, 3, 2, 6, 4, 8, 10, 10, 10, 10, 10, 8...   \n\n                                           dep_id_custom  \n0          [7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]  \n1      [11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...  \n2      [4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...  \n3             [4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]  \n4                     [5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]  \n...                                                  ...  \n10235  [11, 7, 5, 8, 11, 2, 4, 3, 2, 3, 11, 11, 11, 1...  \n10236  [6, 10, 11, 7, 5, 11, 2, 5, 11, 11, 1, 4, 3, 1...  \n10237  [7, 5, 6, 2, 4, 3, 6, 11, 2, 4, 3, 1, 11, 1, 1...  \n10238           [7, 11, 5, 11, 8, 9, 11, 11, 9, 2, 3, 1]  \n10239  [5, 6, 2, 4, 3, 7, 5, 9, 11, 11, 11, 11, 11, 9...  \n\n[10240 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>...</th>\n      <th>party_id</th>\n      <th>context_id</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n      <th>dep_id</th>\n      <th>dep_id_custom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]</td>\n      <td>[17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n      <td>[6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]</td>\n      <td>[7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...</td>\n      <td>[15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n      <td>[10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...</td>\n      <td>[11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>8</td>\n      <td>[9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...</td>\n      <td>[12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n      <td>[3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...</td>\n      <td>[4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td></td>\n      <td></td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]</td>\n      <td>[8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n      <td>[3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]</td>\n      <td>[4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]</td>\n      <td>[6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n      <td>[4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]</td>\n      <td>[5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10235</th>\n      <td>10235</td>\n      <td>5473.json</td>\n      <td>mostly-true</td>\n      <td>There are a larger number of shark attacks in ...</td>\n      <td>animals,elections</td>\n      <td>aclu-florida</td>\n      <td></td>\n      <td>Florida</td>\n      <td>none</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[6, 2, 15, 3, 1, 5, 1, 1, 5, 9, 8, 6, 2, 1, 5,...</td>\n      <td>[11, 17, 6, 1, 8, 2, 8, 8, 2, 12, 15, 11, 17, ...</td>\n      <td>be large number shark attack florida than be c...</td>\n      <td>large number shark attack florida case voter f...</td>\n      <td>[1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...</td>\n      <td>[126, 100, 5078, 257, 59, 344, 168, 482]</td>\n      <td>[10, 6, 4, 7, 10, 1, 3, 2, 1, 2, 10, 10, 10, 1...</td>\n      <td>[11, 7, 5, 8, 11, 2, 4, 3, 2, 3, 11, 11, 11, 1...</td>\n    </tr>\n    <tr>\n      <th>10236</th>\n      <td>10236</td>\n      <td>3408.json</td>\n      <td>mostly-true</td>\n      <td>Democrats have now become the party of the [At...</td>\n      <td>elections</td>\n      <td>alan-powell</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[9, 12, 4, 2, 15, 1, 5, 15, 15, 9, 11, 9, 1, 1...</td>\n      <td>[12, 4, 3, 17, 6, 8, 2, 6, 14, 12, 13, 12, 8, ...</td>\n      <td>democrats have now become party atlanta metro ...</td>\n      <td>democrats party atlanta metro area black</td>\n      <td>[157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]</td>\n      <td>[122, 169, 397, 1298, 574, 325]</td>\n      <td>[5, 9, 10, 6, 4, 10, 1, 4, 10, 10, 0, 3, 2, 10...</td>\n      <td>[6, 10, 11, 7, 5, 11, 2, 5, 11, 11, 1, 4, 3, 1...</td>\n    </tr>\n    <tr>\n      <th>10237</th>\n      <td>10237</td>\n      <td>3959.json</td>\n      <td>half-true</td>\n      <td>Says an alternative to Social Security that op...</td>\n      <td>retirement,social-security</td>\n      <td>herman-cain</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>[2, 15, 1, 5, 9, 9, 6, 2, 5, 9, 9, 11, 9, 11, ...</td>\n      <td>[17, 6, 8, 2, 12, 12, 11, 17, 2, 12, 12, 13, 1...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>[3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...</td>\n      <td>[1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...</td>\n      <td>[6, 4, 5, 1, 3, 2, 5, 10, 1, 3, 2, 0, 10, 0, 9...</td>\n      <td>[7, 5, 6, 2, 4, 3, 6, 11, 2, 4, 3, 1, 11, 1, 1...</td>\n    </tr>\n    <tr>\n      <th>10238</th>\n      <td>10238</td>\n      <td>2253.json</td>\n      <td>false</td>\n      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n      <td>florida,foreign-policy</td>\n      <td>jeff-greene</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>7</td>\n      <td>[5, 2, 15, 9, 3, 1, 15, 2, 1, 5, 9, 11]</td>\n      <td>[2, 17, 6, 12, 1, 8, 17, 17, 8, 2, 12, 13]</td>\n      <td>lift u.s. cuban embargo and allow travel cuba</td>\n      <td>lift u.s. cuban embargo allow travel cuba</td>\n      <td>[1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]</td>\n      <td>[1503, 19, 7, 2738, 2994, 118, 1290, 1374]</td>\n      <td>[6, 10, 4, 10, 7, 8, 10, 10, 8, 1, 2, 0]</td>\n      <td>[7, 11, 5, 11, 8, 9, 11, 11, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>10239</th>\n      <td>10239</td>\n      <td>1155.json</td>\n      <td>pants-fire</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>health-care,veterans</td>\n      <td>michael-steele</td>\n      <td>chairman of the Republican National Committee</td>\n      <td>Maryland</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[15, 9, 5, 9, 9, 2, 15, 1, 4, 4, 2, 6, 1, 1, 5...</td>\n      <td>[6, 12, 2, 12, 12, 17, 6, 8, 3, 3, 17, 11, 8, ...</td>\n      <td>department veterans affairs have manual out th...</td>\n      <td>department veterans affairs manual tell vetera...</td>\n      <td>[216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...</td>\n      <td>[172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...</td>\n      <td>[4, 5, 1, 3, 2, 6, 4, 8, 10, 10, 10, 10, 10, 8...</td>\n      <td>[5, 6, 2, 4, 3, 7, 5, 9, 11, 11, 11, 11, 11, 9...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10240 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9496\n"
     ]
    }
   ],
   "source": [
    "# print(len(embedding_matrix))\n",
    "print(len(embedding_matrix_spacy_100d))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_glove_wordcustom = embedding_matrix_custom_100d\n",
    "# embedding_matrix_glove_wordspacy = embedding_matrix_spacy_100d\n",
    "\n",
    "# statement embed bilstm\n",
    "vocab_length_custom = len(vocabulary_dict_custom.keys())\n",
    "statement_input_custom = Input(shape=num_steps, dtype='int32', name='main_input_custom')\n",
    "x = Embedding(vocab_length_custom+1,EMBED_DIM,weights=[embedding_matrix_custom_100d],input_length=num_steps,trainable=False)(statement_input_custom)\n",
    "bilstm_word_in_custom = LSTM(lstm_size, dropout=0.2, name='bilstm_word_in_custom')(x)\n",
    "\n",
    "vocab_length_spacy = len(vocabulary_dict_spacy.keys())\n",
    "statement_input_spacy = Input(shape=num_steps, dtype='int32', name='main_input_spacy')\n",
    "x_spacy = Embedding(vocab_length_spacy+1,EMBED_DIM,weights=[embedding_matrix_spacy_100d],input_length=num_steps,trainable=False)(statement_input_spacy)\n",
    "bilstm_word_in_spacy = LSTM(lstm_size, dropout=0.2, name='bilstm_word_in_spacy')(x_spacy)\n",
    "\n",
    "# SPECIFY POS_DICT USED FOR POS EMBEDDING\n",
    "pos_embeddings_custom = np.identity(max(pos_dict_custom.values())+1, dtype=int)\n",
    "pos_input_custom = Input(shape=num_steps, dtype='int32', name='pos_input_custom')\n",
    "xpos_custom = Embedding(max(pos_dict_custom.values())+1, max(pos_dict_custom.values())+1, weights=[pos_embeddings_custom], input_length=num_steps, trainable=False)(pos_input_custom)\n",
    "bilstm_pos_in_custom = LSTM(lstm_size, dropout=0.2, name='bilstm_pos_in_custom')(xpos_custom)\n",
    "\n",
    "pos_embeddings_default = np.identity(max(pos_dict_default.values())+1, dtype=int)\n",
    "pos_input_default = Input(shape=num_steps, dtype='int32', name='pos_input_default')\n",
    "xpos_default = Embedding(max(pos_dict_default.values())+1, max(pos_dict_default.values())+1, weights=[pos_embeddings_default], input_length=num_steps, trainable=False)(pos_input_default)\n",
    "bilstm_pos_in_default = LSTM(lstm_size, dropout=0.2, name='bilstm_pos_in_default')(xpos_default)\n",
    "\n",
    "# SPECIFY DEP_DICT USED FOR DEP EMBEDDING\n",
    "dep_embeddings_custom = np.identity(max(dep_dict_custom.values())+1, dtype=int)\n",
    "# dep embed LSTM X3\n",
    "dep_input = Input(shape=(num_steps,), dtype='int32', name='dep_input')\n",
    "xdep = Embedding(max(dep_dict_custom.values())+1, max(dep_dict_custom.values())+1, weights=[dep_embeddings_custom], input_length=num_steps, trainable=False)(dep_input)\n",
    "bilstm_dep_custom_in = LSTM(lstm_size, dropout=0.2)(xdep)\n",
    "\n",
    "# meta data Dense layer\n",
    "meta_input = Input(shape=(X_train_meta.shape[1],), name='aux_input')\n",
    "x_meta = Dense(64, activation='relu')(meta_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def concat_lstm_layers(bilstm_input, layers_to_concat):\n",
    "    layers = [bilstm_input] + layers_to_concat\n",
    "    x = keras.layers.concatenate(layers)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "layers_poscustom_depmeta = [bilstm_pos_in_custom, bilstm_dep_custom_in, x_meta]\n",
    "layers_posdefault_depmeta = [bilstm_pos_in_default, bilstm_dep_custom_in, x_meta]\n",
    "\n",
    "concat_customcustom = concat_lstm_layers(bilstm_word_in_custom, layers_poscustom_depmeta)\n",
    "main_output_customcustom = Dense(6, activation='softmax', name='main_output_customcustom')(concat_customcustom)\n",
    "experiment_customcustom_input = [statement_input_custom, pos_input_custom, dep_input, meta_input]\n",
    "\n",
    "concat_customdefault = concat_lstm_layers(bilstm_word_in_custom, layers_posdefault_depmeta)\n",
    "main_output_customdefault = Dense(6, activation='softmax', name='main_output_customdefault')(concat_customdefault)\n",
    "experiment_customdefault_input = [statement_input_custom, pos_input_default, dep_input, meta_input]\n",
    "\n",
    "concat_spacycustom = concat_lstm_layers(bilstm_word_in_spacy, layers_poscustom_depmeta)\n",
    "main_output_spacycustom = Dense(6, activation='softmax', name='main_output_spacycustom')(concat_spacycustom)\n",
    "experiment_spacycustom_input = [statement_input_spacy, pos_input_custom, dep_input, meta_input]\n",
    "\n",
    "concat_spacydefault = concat_lstm_layers(bilstm_word_in_spacy, layers_posdefault_depmeta)\n",
    "main_output_spacydefault = Dense(6, activation='softmax', name='main_output_spacydefault')(concat_spacydefault)\n",
    "experiment_spacydefault_input = [statement_input_spacy, pos_input_default, dep_input, meta_input]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# model_bilstm_customcustom = Sequential()\n",
    "# model_bilstm_customcustom.add(Embedding(vocab_length_custom+1, hidden_size, input_length=num_steps))\n",
    "# model_bilstm_customcustom.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_bilstm_customcustom.add(Dense(6, activation='softmax'))\n",
    "model_bilstm_customcustom = Model(inputs=experiment_customcustom_input, outputs=main_output_customcustom, name='model_bilstm_customcustom')\n",
    "\n",
    "# model_bilstm_customdefault = Sequential()\n",
    "# model_bilstm_customdefault.add(Embedding(vocab_length_custom+1, hidden_size, input_length=num_steps))\n",
    "# model_bilstm_customdefault.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_bilstm_customdefault.add(Dense(6, activation='softmax'))\n",
    "model_bilstm_customdefault = Model(inputs=experiment_customdefault_input, outputs=main_output_customdefault,name='model_bilstm_customdefault')\n",
    "\n",
    "# model_bilstm_spacycustom = Sequential()\n",
    "# model_bilstm_spacycustom.add(Embedding(vocab_length_spacy+1, hidden_size, input_length=num_steps))\n",
    "# model_bilstm_spacycustom.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_bilstm_spacycustom.add(Dense(6, activation='softmax'))\n",
    "model_bilstm_spacycustom = Model(inputs=experiment_spacycustom_input, outputs=main_output_spacycustom,name='model_bilstm_spacycustom')\n",
    "\n",
    "# model_bilstm_spacydefault = Sequential()\n",
    "# model_bilstm_spacydefault.add(Embedding(vocab_length_spacy+1, hidden_size, input_length=num_steps))\n",
    "# model_bilstm_spacydefault.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_bilstm_spacydefault.add(Dense(6, activation='softmax'))\n",
    "model_bilstm_spacydefault = Model(inputs=experiment_spacydefault_input, outputs=main_output_spacydefault,name='model_bilstm_spacydefault')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_bilstm_spacydefault\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input_spacy (InputLayer)  [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input_default (InputLayer)  [(None, 30)]        0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      949600      ['main_input_spacy[0][0]']       \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 30, 18)       324         ['pos_input_default[0][0]']      \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 30, 12)       144         ['dep_input[0][0]']              \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " bilstm_word_in_spacy (LSTM)    (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " bilstm_pos_in_default (LSTM)   (None, 100)          47600       ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 100)          45200       ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8448        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 364)          0           ['bilstm_word_in_spacy[0][0]',   \n",
      "                                                                  'bilstm_pos_in_default[0][0]',  \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " main_output_spacydefault (Dens  (None, 6)           2190        ['concatenate_3[0][0]']          \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,133,906\n",
      "Trainable params: 183,838\n",
      "Non-trainable params: 950,068\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_bilstm_spacycustom\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input_spacy (InputLayer)  [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input_custom (InputLayer)  [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      949600      ['main_input_spacy[0][0]']       \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 30, 16)       256         ['pos_input_custom[0][0]']       \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 30, 12)       144         ['dep_input[0][0]']              \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " bilstm_word_in_spacy (LSTM)    (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " bilstm_pos_in_custom (LSTM)    (None, 100)          46800       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 100)          45200       ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8448        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 364)          0           ['bilstm_word_in_spacy[0][0]',   \n",
      "                                                                  'bilstm_pos_in_custom[0][0]',   \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " main_output_spacycustom (Dense  (None, 6)           2190        ['concatenate_2[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,133,038\n",
      "Trainable params: 183,038\n",
      "Non-trainable params: 950,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_spacydefault.summary()\n",
    "model_bilstm_spacycustom.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_76 (Embedding)       (None, 30, 100)      949600      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_78 (Embedding)       (None, 30, 18)       324         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_79 (Embedding)       (None, 30, 12)       144         ['dep_input[0][0]']              \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_66 (LSTM)                 (None, 100)          80400       ['embedding_76[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_68 (LSTM)                 (None, 100)          47600       ['embedding_78[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_69 (LSTM)                 (None, 100)          45200       ['embedding_79[0][0]']           \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 64)           8448        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 364)          0           ['lstm_66[0][0]',                \n",
      "                                                                  'lstm_68[0][0]',                \n",
      "                                                                  'lstm_69[0][0]',                \n",
      "                                                                  'dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            2190        ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,133,906\n",
      "Trainable params: 183,838\n",
      "Non-trainable params: 950,068\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_76 (Embedding)       (None, 30, 100)      949600      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_77 (Embedding)       (None, 30, 16)       256         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_79 (Embedding)       (None, 30, 12)       144         ['dep_input[0][0]']              \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_66 (LSTM)                 (None, 100)          80400       ['embedding_76[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_67 (LSTM)                 (None, 100)          46800       ['embedding_77[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_69 (LSTM)                 (None, 100)          45200       ['embedding_79[0][0]']           \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 64)           8448        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 364)          0           ['lstm_66[0][0]',                \n",
      "                                                                  'lstm_67[0][0]',                \n",
      "                                                                  'lstm_69[0][0]',                \n",
      "                                                                  'dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            2190        ['concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,133,038\n",
      "Trainable params: 183,038\n",
      "Non-trainable params: 950,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_spacydefault.summary()\n",
    "model_bilstm_spacycustom.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_30 (Embedding)       (None, 30, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_32 (Embedding)       (None, 30, 16)       256         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_34 (Embedding)       (None, 30, 12)       144         ['dep_input[0][0]']              \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_20 (LSTM)                 (None, 100)          80400       ['embedding_30[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 (None, 100)          46800       ['embedding_32[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_24 (LSTM)                 (None, 100)          45200       ['embedding_34[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8448        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 364)          0           ['lstm_20[0][0]',                \n",
      "                                                                  'lstm_22[0][0]',                \n",
      "                                                                  'lstm_24[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            2190        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,144,138\n",
      "Trainable params: 183,038\n",
      "Non-trainable params: 961,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_customcustom.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# extra_layers_pos_custom = [bilstm_pos_in_custom]\n",
    "# extra_layer_pos_default = [bilstm_pos_in_default]\n",
    "# extra_layers_for_pos_meta = [bilstm_pos_in_custom, x_meta]\n",
    "# extra_layers_for_poscustom_dep_meta = [bilstm_pos_in_custom, bilstm_dep_custom_in, x_meta]\n",
    "#\n",
    "# concat_pos = concat_lstm_layers(bilstm_word_input, extra_layers_pos_custom)\n",
    "# main_output_pos = Dense(6, activation='softmax', name='main_output')(concat_pos)\n",
    "# experiment1input = [statement_input, pos_input_custom]\n",
    "#\n",
    "# concat_pos_meta = concat_lstm_layers(bilstm_word_input, extra_layers_for_pos_meta)\n",
    "# main_output_pos_meta = Dense(6, activation='softmax', name='main_output')(concat_pos_meta)\n",
    "# experiment2input = [statement_input, pos_input_custom, meta_input]\n",
    "#\n",
    "# concat_pos_dep_meta = concat_lstm_layers(bilstm_word_input, extra_layers_for_poscustom_dep_meta)\n",
    "# main_output_dep_meta = Dense(6, activation='softmax', name='main_output')(concat_pos_dep_meta)\n",
    "# experiment3input = [statement_input, pos_input_custom, dep_input, meta_input]\n",
    "#\n",
    "# model_bilstm_pos = Sequential()\n",
    "# model_bilstm_pos.add(Embedding(vocab_length+1, hidden_size, input_length=num_steps))\n",
    "# model_bilstm_pos.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_bilstm_pos.add(Dense(6, activation='softmax'))\n",
    "# model_bilstm_pos = Model(inputs=experiment1input, outputs=[main_output_pos])\n",
    "#\n",
    "# model_bilstm_meta = Sequential()\n",
    "# model_bilstm_meta.add(Embedding(vocab_length+1, hidden_size, input_length=num_steps))\n",
    "# model_bilstm_meta.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_bilstm_meta.add(Dense(6, activation='softmax'))\n",
    "# model_bilstm_meta = Model(inputs=experiment2input, outputs=[main_output_pos_meta])\n",
    "#\n",
    "# model_bilstm_dep_meta = Sequential()\n",
    "# model_bilstm_dep_meta.add(Embedding(vocab_length+1, hidden_size, input_length=num_steps))\n",
    "# model_bilstm_dep_meta.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_bilstm_dep_meta.add(Dense(6, activation='softmax'))\n",
    "# model_bilstm_dep_meta = Model(inputs=experiment3input, outputs=[main_output_dep_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 30, 18)       324         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 100)          47600       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 200)          0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,090,230\n",
      "Trainable params: 129,206\n",
      "Non-trainable params: 961,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_pos.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 30, 18)       324         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 30, 10)       100         ['dep_input[0][0]']              \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 100)          47600       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 100)          44400       ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8448        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 364)          0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]',                 \n",
      "                                                                  'lstm_3[0][0]',                 \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            2190        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,144,162\n",
      "Trainable params: 183,038\n",
      "Non-trainable params: 961,124\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MOst recent 342am\n",
    "model_bilstm_dep_meta.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 30, 18)       324         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 30, 10)       100         ['dep_input[0][0]']              \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 100)          47600       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 100)          44400       ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8448        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 364)          0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]',                 \n",
      "                                                                  'lstm_3[0][0]',                 \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            2190        ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,144,162\n",
      "Trainable params: 183,038\n",
      "Non-trainable params: 961,124\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_dep_meta.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 30, 18)       324         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 100)          47600       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 200)          0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " dep_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,090,230\n",
      "Trainable params: 129,206\n",
      "Non-trainable params: 961,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_dep_meta.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 30, 16)       256         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 100)          46800       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 200)          0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 131)]        0           []                               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,089,362\n",
      "Trainable params: 128,406\n",
      "Non-trainable params: 960,956\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_meta.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 30, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 30, 16)       256         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 100)          80400       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 100)          46800       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 200)          0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,089,362\n",
      "Trainable params: 128,406\n",
      "Non-trainable params: 960,956\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_36 (Embedding)       (None, 50, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_37 (Embedding)       (None, 50, 15)       225         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_32 (LSTM)                 (None, 100)          80400       ['embedding_36[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_33 (LSTM)                 (None, 100)          46400       ['embedding_37[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 200)          0           ['lstm_32[0][0]',                \n",
      "                                                                  'lstm_33[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,088,931\n",
      "Trainable params: 128,006\n",
      "Non-trainable params: 960,925\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_25 (Embedding)       (None, 50, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_26 (Embedding)       (None, 50, 14)       196         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 (None, 100)          80400       ['embedding_25[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)                 (None, 100)          46000       ['embedding_26[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 200)          0           ['lstm_22[0][0]',                \n",
      "                                                                  'lstm_23[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,088,502\n",
      "Trainable params: 127,606\n",
      "Non-trainable params: 960,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_22 (Embedding)       (None, 20, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_23 (Embedding)       (None, 20, 14)       196         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_19 (LSTM)                 (None, 100)          80400       ['embedding_22[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_20 (LSTM)                 (None, 100)          46000       ['embedding_23[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 200)          0           ['lstm_19[0][0]',                \n",
      "                                                                  'lstm_20[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,088,502\n",
      "Trainable params: 127,606\n",
      "Non-trainable params: 960,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vocab_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### APRIL 8th"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrixes: (9607, 100)\n",
      "Length of the vocabulary dictionary: 9606\n",
      "X_train_custom shape: (10240, 50)\n",
      "X_val_custom shape: (1284, 50)\n"
     ]
    }
   ],
   "source": [
    "# vocab_length = len(vocabulary_dict_custom)\n",
    "\n",
    "print(\"Shape of the embedding matrixes:\", embedding_matrix_custom_100d.shape)\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length)\n",
    "print(\"X_train_custom shape:\", X_train_custom.shape)\n",
    "print(\"X_val_custom shape:\", X_val_custom.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrixes: (9607, 100)\n",
      "Length of the vocabulary dictionary: 9606\n",
      "X_train_custom shape: (10240, 14)\n",
      "X_val_custom shape: (1284, 14)\n"
     ]
    }
   ],
   "source": [
    "# vocab_length = len(vocabulary_dict_custom)\n",
    "\n",
    "print(\"Shape of the embedding matrixes:\", embedding_matrix_custom_100d.shape)\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length)\n",
    "print(\"X_train_custom shape:\", X_train_custom.shape)\n",
    "print(\"X_val_custom shape:\", X_val_custom.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max index in X_train_custom: 9606\n",
      "Max index in X_val_custom: 9545\n"
     ]
    }
   ],
   "source": [
    "print(\"Max index in X_train_custom:\", np.max(X_train_custom))\n",
    "print(\"Max index in X_val_custom:\", np.max(X_val_custom))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "word_index = {word: i+1 for i, word in enumerate(vocabulary_dict_custom)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austin be burden fast grow tax increase major city nation     \n",
      "say have organization parade be social welfare organization and then be involve political combat back\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(sequence, index_to_word):\n",
    "    return \" \".join([index_to_word.get(idx, \"\") for idx in sequence])\n",
    "\n",
    "index_to_word = {i: word for word, i in word_index.items()}\n",
    "\n",
    "# Print a decoded sample from X_train_custom\n",
    "sample_idx = 89  # You can change this to any valid index\n",
    "print(decode_sequence(X_train_custom[sample_idx], index_to_word))\n",
    "\n",
    "# Print a decoded sample from X_val_custom\n",
    "sample_idx = 2  # You can change this to any valid index\n",
    "print(decode_sequence(X_val_custom[sample_idx], index_to_word))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_data\u001B[49m\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "configurations = [\n",
    "\n",
    "key:\n",
    "    .cu = custom\n",
    "    .de = default\n",
    "\n",
    "    s = statement\n",
    "    p = pos\n",
    "    d = dep\n",
    "    m = meta\n",
    "\n",
    "    g = glove\n",
    "    e = elmo\n",
    "\n",
    "\n",
    "\t{\n",
    "        \"name\": \"scu-pcu-g\",\n",
    "        \"inputs\": [X_test_custom, X_test_pos],\n",
    "    },\n",
    "\t{\n",
    "        \"name\": \"sde-pcu-g\",\n",
    "        \"inputs\": [X_test_spacy, X_test_pos],\n",
    "    },\n",
    "\n",
    "        \"name\": \"s\n",
    "    {\n",
    "        \"name\": \"sde-pcu-g\",\n",
    "        \"inputs\": [X_test_spacy, X_test_pos],\n",
    "    },\n",
    "\n",
    "\t{\n",
    "        \"name\": \"fathan_3\",\n",
    "        \"inputs\": [X_test_custom, X_test_pos_DEFAULT],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fathan_4\",\n",
    "        \"inputs\": [X_test_custom, X_test_pos_DEFAULT],\n",
    "    },\n",
    "\t# {\n",
    "    #     \"name\": \"fathan_5\",\n",
    "    #     \"inputs\": [X_test_best, X_test_pos_best, X_test_meta],\n",
    "    # },\n",
    "\t# {\n",
    "    #     \"name\": \"fathan_6\",\n",
    "    #     \"inputs\": [X_test_best, X_test_pos_best, X_test_meta, X_test_dep],\n",
    "    # },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "       index          id        label  \\\n0          0   2635.json        false   \n1          1  10540.json    half-true   \n2          2    324.json  mostly-true   \n3          3   1123.json        false   \n4          4   9028.json    half-true   \n...      ...         ...          ...   \n10235  10235   5473.json  mostly-true   \n10236  10236   3408.json  mostly-true   \n10237  10237   3959.json    half-true   \n10238  10238   2253.json        false   \n10239  10239   1155.json   pants-fire   \n\n                                               statement  \\\n0      Says the Annies List political group supports ...   \n1      When did the decline of coal start? It started...   \n2      Hillary Clinton agrees with John McCain \"by vo...   \n3      Health care reform legislation is likely to ma...   \n4      The economic turnaround started at the end of ...   \n...                                                  ...   \n10235  There are a larger number of shark attacks in ...   \n10236  Democrats have now become the party of the [At...   \n10237  Says an alternative to Social Security that op...   \n10238  On lifting the U.S. Cuban embargo and allowing...   \n10239  The Department of Veterans Affairs has a manua...   \n\n                                  subject         speaker  \\\n0                                abortion    dwayne-bohac   \n1      energy,history,job-accomplishments  scott-surovell   \n2                          foreign-policy    barack-obama   \n3                             health-care    blog-posting   \n4                            economy,jobs   charlie-crist   \n...                                   ...             ...   \n10235                   animals,elections    aclu-florida   \n10236                           elections     alan-powell   \n10237          retirement,social-security     herman-cain   \n10238              florida,foreign-policy     jeff-greene   \n10239                health-care,veterans  michael-steele   \n\n                                           job_title state_info       party  \\\n0                               State representative      Texas  republican   \n1                                     State delegate   Virginia    democrat   \n2                                          President   Illinois    democrat   \n3                                                                      none   \n4                                                       Florida    democrat   \n...                                              ...        ...         ...   \n10235                                                   Florida        none   \n10236                                                   Georgia  republican   \n10237                                                   Georgia  republican   \n10238                                                   Florida    democrat   \n10239  chairman of the Republican National Committee   Maryland  republican   \n\n       barely true  ...  party_id  context_id  \\\n0              0.0  ...         0           2   \n1              0.0  ...         1           2   \n2             70.0  ...         1           8   \n3              7.0  ...         2           0   \n4             15.0  ...         1           1   \n...            ...  ...       ...         ...   \n10235          0.0  ...         2           1   \n10236          0.0  ...         0           0   \n10237          4.0  ...         0           7   \n10238          3.0  ...         1           7   \n10239          0.0  ...         0           1   \n\n                                                  pos_id  \\\n0          [2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]   \n1      [8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...   \n2      [9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...   \n3             [1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]   \n4                   [15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]   \n...                                                  ...   \n10235  [6, 2, 15, 3, 1, 5, 1, 1, 5, 9, 8, 6, 2, 1, 5,...   \n10236  [9, 12, 4, 2, 15, 1, 5, 15, 15, 9, 11, 9, 1, 1...   \n10237  [2, 15, 1, 5, 9, 9, 6, 2, 5, 9, 9, 11, 9, 11, ...   \n10238            [5, 2, 15, 9, 3, 1, 15, 2, 1, 5, 9, 11]   \n10239  [15, 9, 5, 9, 9, 2, 15, 1, 4, 4, 2, 6, 1, 1, 5...   \n\n                                          pos_id_DEFAULT  \\\n0       [17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]   \n1      [15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...   \n2      [12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...   \n3             [8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]   \n4                   [6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]   \n...                                                  ...   \n10235  [11, 17, 6, 1, 8, 2, 8, 8, 2, 12, 15, 11, 17, ...   \n10236  [12, 4, 3, 17, 6, 8, 2, 6, 14, 12, 13, 12, 8, ...   \n10237  [17, 6, 8, 2, 12, 12, 11, 17, 2, 12, 12, 13, 1...   \n10238         [2, 17, 6, 12, 1, 8, 17, 17, 8, 2, 12, 13]   \n10239  [6, 12, 2, 12, 12, 17, 6, 8, 3, 3, 17, 11, 8, ...   \n\n                                        statement_custom  \\\n0      say annies list political group support third ...   \n1      when do decline coal start start when natural ...   \n2      hillary clinton agree john mccain vote give ge...   \n3      health care reform legislation be likely manda...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  be large number shark attack florida than be c...   \n10236  democrats have now become party atlanta metro ...   \n10237  say alternative social security operate galves...   \n10238      lift u.s. cuban embargo and allow travel cuba   \n10239  department veterans affairs have manual out th...   \n\n                                         statement_spacy  \\\n0      say annies list political group support trimes...   \n1      decline coal start start natural gas take star...   \n2      hillary clinton agree john mccain vote george ...   \n3      health care reform legislation likely mandate ...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  large number shark attack florida case voter f...   \n10236           democrats party atlanta metro area black   \n10237  say alternative social security operate galves...   \n10238          lift u.s. cuban embargo allow travel cuba   \n10239  department veterans affairs manual tell vetera...   \n\n                                          word_id_custom  \\\n0      [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1      [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2      [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3      [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                             [282, 3331, 308, 247, 248]   \n...                                                  ...   \n10235  [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...   \n10236     [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]   \n10237  [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...   \n10238     [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]   \n10239  [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...   \n\n                                           word_id_spacy  \\\n0           [1, 5315, 633, 423, 332, 37, 3919, 120, 936]   \n1      [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...   \n2      [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...   \n3      [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]   \n4                             [224, 3208, 249, 198, 199]   \n...                                                  ...   \n10235           [126, 100, 5078, 257, 59, 344, 168, 482]   \n10236                    [122, 169, 397, 1298, 574, 325]   \n10237  [1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...   \n10238         [1503, 19, 7, 2738, 2994, 118, 1290, 1374]   \n10239  [172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...   \n\n                                                  dep_id  \\\n0          [6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]   \n1      [10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...   \n2      [3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...   \n3              [3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]   \n4                     [4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]   \n...                                                  ...   \n10235  [10, 6, 4, 7, 10, 1, 3, 2, 1, 2, 10, 10, 10, 1...   \n10236  [5, 9, 10, 6, 4, 10, 1, 4, 10, 10, 0, 3, 2, 10...   \n10237  [6, 4, 5, 1, 3, 2, 5, 10, 1, 3, 2, 0, 10, 0, 9...   \n10238           [6, 10, 4, 10, 7, 8, 10, 10, 8, 1, 2, 0]   \n10239  [4, 5, 1, 3, 2, 6, 4, 8, 10, 10, 10, 10, 10, 8...   \n\n                                           dep_id_custom  \n0          [7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]  \n1      [11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...  \n2      [4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...  \n3             [4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]  \n4                     [5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]  \n...                                                  ...  \n10235  [11, 7, 5, 8, 11, 2, 4, 3, 2, 3, 11, 11, 11, 1...  \n10236  [6, 10, 11, 7, 5, 11, 2, 5, 11, 11, 1, 4, 3, 1...  \n10237  [7, 5, 6, 2, 4, 3, 6, 11, 2, 4, 3, 1, 11, 1, 1...  \n10238           [7, 11, 5, 11, 8, 9, 11, 11, 9, 2, 3, 1]  \n10239  [5, 6, 2, 4, 3, 7, 5, 9, 11, 11, 11, 11, 11, 9...  \n\n[10240 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>...</th>\n      <th>party_id</th>\n      <th>context_id</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n      <th>dep_id</th>\n      <th>dep_id_custom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[2, 15, 9, 9, 3, 1, 2, 3, 11, 1, 1, 5, 1, 11]</td>\n      <td>[17, 6, 12, 12, 1, 8, 17, 1, 13, 8, 8, 2, 8, 13]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n      <td>[6, 4, 10, 10, 7, 5, 10, 7, 0, 3, 8, 1, 2, 0]</td>\n      <td>[7, 5, 11, 11, 8, 6, 11, 8, 1, 4, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[8, 2, 15, 1, 5, 1, 1, 11, 6, 2, 8, 3, 1, 2, 5...</td>\n      <td>[15, 17, 6, 8, 2, 8, 8, 13, 11, 17, 15, 1, 8, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n      <td>[10, 6, 4, 5, 1, 3, 2, 0, 5, 6, 10, 7, 5, 10, ...</td>\n      <td>[11, 7, 5, 6, 2, 4, 3, 1, 6, 7, 11, 8, 6, 11, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>8</td>\n      <td>[9, 9, 2, 5, 9, 9, 11, 5, 2, 13, 2, 9, 9, 15, ...</td>\n      <td>[12, 12, 17, 2, 12, 12, 13, 2, 17, 10, 17, 12,...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n      <td>[3, 5, 6, 1, 3, 2, 0, 1, 10, 9, 10, 3, 10, 4, ...</td>\n      <td>[4, 6, 7, 2, 4, 3, 1, 2, 11, 10, 11, 4, 11, 5,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td></td>\n      <td></td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[1, 1, 1, 1, 12, 3, 13, 2, 3, 1, 1, 1, 11]</td>\n      <td>[8, 8, 8, 8, 4, 1, 10, 17, 1, 8, 8, 8, 13]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n      <td>[3, 3, 3, 5, 6, 10, 9, 10, 7, 3, 3, 8, 0]</td>\n      <td>[4, 4, 4, 6, 7, 11, 10, 11, 8, 4, 4, 9, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15, 3, 1, 2, 5, 15, 1, 5, 6, 1, 11]</td>\n      <td>[6, 1, 8, 17, 2, 6, 8, 2, 11, 8, 13]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n      <td>[4, 7, 5, 6, 1, 4, 2, 1, 10, 2, 0]</td>\n      <td>[5, 8, 6, 7, 2, 5, 3, 2, 11, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10235</th>\n      <td>10235</td>\n      <td>5473.json</td>\n      <td>mostly-true</td>\n      <td>There are a larger number of shark attacks in ...</td>\n      <td>animals,elections</td>\n      <td>aclu-florida</td>\n      <td></td>\n      <td>Florida</td>\n      <td>none</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[6, 2, 15, 3, 1, 5, 1, 1, 5, 9, 8, 6, 2, 1, 5,...</td>\n      <td>[11, 17, 6, 1, 8, 2, 8, 8, 2, 12, 15, 11, 17, ...</td>\n      <td>be large number shark attack florida than be c...</td>\n      <td>large number shark attack florida case voter f...</td>\n      <td>[1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...</td>\n      <td>[126, 100, 5078, 257, 59, 344, 168, 482]</td>\n      <td>[10, 6, 4, 7, 10, 1, 3, 2, 1, 2, 10, 10, 10, 1...</td>\n      <td>[11, 7, 5, 8, 11, 2, 4, 3, 2, 3, 11, 11, 11, 1...</td>\n    </tr>\n    <tr>\n      <th>10236</th>\n      <td>10236</td>\n      <td>3408.json</td>\n      <td>mostly-true</td>\n      <td>Democrats have now become the party of the [At...</td>\n      <td>elections</td>\n      <td>alan-powell</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[9, 12, 4, 2, 15, 1, 5, 15, 15, 9, 11, 9, 1, 1...</td>\n      <td>[12, 4, 3, 17, 6, 8, 2, 6, 14, 12, 13, 12, 8, ...</td>\n      <td>democrats have now become party atlanta metro ...</td>\n      <td>democrats party atlanta metro area black</td>\n      <td>[157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]</td>\n      <td>[122, 169, 397, 1298, 574, 325]</td>\n      <td>[5, 9, 10, 6, 4, 10, 1, 4, 10, 10, 0, 3, 2, 10...</td>\n      <td>[6, 10, 11, 7, 5, 11, 2, 5, 11, 11, 1, 4, 3, 1...</td>\n    </tr>\n    <tr>\n      <th>10237</th>\n      <td>10237</td>\n      <td>3959.json</td>\n      <td>half-true</td>\n      <td>Says an alternative to Social Security that op...</td>\n      <td>retirement,social-security</td>\n      <td>herman-cain</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>[2, 15, 1, 5, 9, 9, 6, 2, 5, 9, 9, 11, 9, 11, ...</td>\n      <td>[17, 6, 8, 2, 12, 12, 11, 17, 2, 12, 12, 13, 1...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>[3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...</td>\n      <td>[1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...</td>\n      <td>[6, 4, 5, 1, 3, 2, 5, 10, 1, 3, 2, 0, 10, 0, 9...</td>\n      <td>[7, 5, 6, 2, 4, 3, 6, 11, 2, 4, 3, 1, 11, 1, 1...</td>\n    </tr>\n    <tr>\n      <th>10238</th>\n      <td>10238</td>\n      <td>2253.json</td>\n      <td>false</td>\n      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n      <td>florida,foreign-policy</td>\n      <td>jeff-greene</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>7</td>\n      <td>[5, 2, 15, 9, 3, 1, 15, 2, 1, 5, 9, 11]</td>\n      <td>[2, 17, 6, 12, 1, 8, 17, 17, 8, 2, 12, 13]</td>\n      <td>lift u.s. cuban embargo and allow travel cuba</td>\n      <td>lift u.s. cuban embargo allow travel cuba</td>\n      <td>[1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]</td>\n      <td>[1503, 19, 7, 2738, 2994, 118, 1290, 1374]</td>\n      <td>[6, 10, 4, 10, 7, 8, 10, 10, 8, 1, 2, 0]</td>\n      <td>[7, 11, 5, 11, 8, 9, 11, 11, 9, 2, 3, 1]</td>\n    </tr>\n    <tr>\n      <th>10239</th>\n      <td>10239</td>\n      <td>1155.json</td>\n      <td>pants-fire</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>health-care,veterans</td>\n      <td>michael-steele</td>\n      <td>chairman of the Republican National Committee</td>\n      <td>Maryland</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[15, 9, 5, 9, 9, 2, 15, 1, 4, 4, 2, 6, 1, 1, 5...</td>\n      <td>[6, 12, 2, 12, 12, 17, 6, 8, 3, 3, 17, 11, 8, ...</td>\n      <td>department veterans affairs have manual out th...</td>\n      <td>department veterans affairs manual tell vetera...</td>\n      <td>[216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...</td>\n      <td>[172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...</td>\n      <td>[4, 5, 1, 3, 2, 6, 4, 8, 10, 10, 10, 10, 10, 8...</td>\n      <td>[5, 6, 2, 4, 3, 7, 5, 9, 11, 11, 11, 11, 11, 9...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10240 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(learning_rate=0.025, clipvalue=0.3, nesterov=True)\n",
    "adam = optimizers.Adam(learning_rate=0.000075, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### APRIL 13th"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6671 - categorical_accuracy: 0.2292\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.23832, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 15s 31ms/step - loss: 1.6671 - categorical_accuracy: 0.2292 - val_loss: 1.6109 - val_categorical_accuracy: 0.2383\n",
      "Epoch 2/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5966 - categorical_accuracy: 0.2521\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.23832\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5966 - categorical_accuracy: 0.2522 - val_loss: 1.6019 - val_categorical_accuracy: 0.2383\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5887 - categorical_accuracy: 0.2575\n",
      "Epoch 3: val_categorical_accuracy improved from 0.23832 to 0.23910, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5888 - categorical_accuracy: 0.2576 - val_loss: 1.5886 - val_categorical_accuracy: 0.2391\n",
      "Epoch 4/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5797 - categorical_accuracy: 0.2652\n",
      "Epoch 4: val_categorical_accuracy improved from 0.23910 to 0.25078, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5798 - categorical_accuracy: 0.2650 - val_loss: 1.5858 - val_categorical_accuracy: 0.2508\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5737 - categorical_accuracy: 0.2737\n",
      "Epoch 5: val_categorical_accuracy improved from 0.25078 to 0.25623, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5737 - categorical_accuracy: 0.2737 - val_loss: 1.5874 - val_categorical_accuracy: 0.2562\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5706 - categorical_accuracy: 0.2777\n",
      "Epoch 6: val_categorical_accuracy improved from 0.25623 to 0.26324, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5706 - categorical_accuracy: 0.2777 - val_loss: 1.5806 - val_categorical_accuracy: 0.2632\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5669 - categorical_accuracy: 0.2742\n",
      "Epoch 7: val_categorical_accuracy improved from 0.26324 to 0.26480, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5671 - categorical_accuracy: 0.2740 - val_loss: 1.5818 - val_categorical_accuracy: 0.2648\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5634 - categorical_accuracy: 0.2792\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.26480\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5637 - categorical_accuracy: 0.2788 - val_loss: 1.5779 - val_categorical_accuracy: 0.2484\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5608 - categorical_accuracy: 0.2814\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.26480\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5608 - categorical_accuracy: 0.2814 - val_loss: 1.5735 - val_categorical_accuracy: 0.2640\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5568 - categorical_accuracy: 0.2862\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.26480\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5568 - categorical_accuracy: 0.2862 - val_loss: 1.5790 - val_categorical_accuracy: 0.2640\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5545 - categorical_accuracy: 0.2881\n",
      "Epoch 11: val_categorical_accuracy improved from 0.26480 to 0.27259, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5542 - categorical_accuracy: 0.2886 - val_loss: 1.5679 - val_categorical_accuracy: 0.2726\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5512 - categorical_accuracy: 0.2943\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.27259\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5513 - categorical_accuracy: 0.2942 - val_loss: 1.5730 - val_categorical_accuracy: 0.2718\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5494 - categorical_accuracy: 0.2933\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.27259\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5494 - categorical_accuracy: 0.2933 - val_loss: 1.5695 - val_categorical_accuracy: 0.2718\n",
      "Epoch 14/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5453 - categorical_accuracy: 0.2952\n",
      "Epoch 14: val_categorical_accuracy improved from 0.27259 to 0.28271, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5452 - categorical_accuracy: 0.2955 - val_loss: 1.5694 - val_categorical_accuracy: 0.2827\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5440 - categorical_accuracy: 0.2985\n",
      "Epoch 15: val_categorical_accuracy improved from 0.28271 to 0.28427, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5441 - categorical_accuracy: 0.2979 - val_loss: 1.5670 - val_categorical_accuracy: 0.2843\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5414 - categorical_accuracy: 0.2984\n",
      "Epoch 16: val_categorical_accuracy improved from 0.28427 to 0.28816, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5414 - categorical_accuracy: 0.2983 - val_loss: 1.5700 - val_categorical_accuracy: 0.2882\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5377 - categorical_accuracy: 0.3055\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.28816\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5377 - categorical_accuracy: 0.3055 - val_loss: 1.5737 - val_categorical_accuracy: 0.2773\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5369 - categorical_accuracy: 0.3048\n",
      "Epoch 18: val_categorical_accuracy improved from 0.28816 to 0.29050, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5369 - categorical_accuracy: 0.3048 - val_loss: 1.5667 - val_categorical_accuracy: 0.2905\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5321 - categorical_accuracy: 0.3097\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.29050\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5321 - categorical_accuracy: 0.3097 - val_loss: 1.5650 - val_categorical_accuracy: 0.2835\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5303 - categorical_accuracy: 0.3120\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.29050\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5304 - categorical_accuracy: 0.3119 - val_loss: 1.5636 - val_categorical_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5301 - categorical_accuracy: 0.3082\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.29050\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5301 - categorical_accuracy: 0.3082 - val_loss: 1.5673 - val_categorical_accuracy: 0.2874\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5292 - categorical_accuracy: 0.3078\n",
      "Epoch 22: val_categorical_accuracy improved from 0.29050 to 0.29283, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5294 - categorical_accuracy: 0.3076 - val_loss: 1.5694 - val_categorical_accuracy: 0.2928\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5250 - categorical_accuracy: 0.3192\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.29283\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5250 - categorical_accuracy: 0.3192 - val_loss: 1.5641 - val_categorical_accuracy: 0.2819\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5215 - categorical_accuracy: 0.3203\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.29283\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5215 - categorical_accuracy: 0.3203 - val_loss: 1.5695 - val_categorical_accuracy: 0.2905\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5195 - categorical_accuracy: 0.3210\n",
      "Epoch 25: val_categorical_accuracy improved from 0.29283 to 0.29517, saving model to spacydefault-glove-adam_weights_best_20230413_005106.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5195 - categorical_accuracy: 0.3210 - val_loss: 1.5658 - val_categorical_accuracy: 0.2952\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5159 - categorical_accuracy: 0.3244\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.29517\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5158 - categorical_accuracy: 0.3246 - val_loss: 1.5656 - val_categorical_accuracy: 0.2835\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5137 - categorical_accuracy: 0.3237\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.29517\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5137 - categorical_accuracy: 0.3241 - val_loss: 1.5689 - val_categorical_accuracy: 0.2843\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5123 - categorical_accuracy: 0.3277\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.29517\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5123 - categorical_accuracy: 0.3277 - val_loss: 1.5691 - val_categorical_accuracy: 0.2827\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5114 - categorical_accuracy: 0.3281\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.29517\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5114 - categorical_accuracy: 0.3281 - val_loss: 1.5673 - val_categorical_accuracy: 0.2835\n",
      "Epoch 30/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5051 - categorical_accuracy: 0.3315\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.29517\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5050 - categorical_accuracy: 0.3315 - val_loss: 1.5752 - val_categorical_accuracy: 0.2882\n"
     ]
    }
   ],
   "source": [
    "# word_id_spacy + pos_id_default\n",
    "train(model_bilstm_spacydefault,\n",
    "      'spacydefault-glove-adam',\n",
    "      {'main_input_spacy': X_train_spacy, 'pos_input_default': X_train_pos_DEFAULT, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input_spacy': X_val_spacy, 'pos_input_default': X_val_pos_DEFAULT, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam,\n",
    "      output_name='main_output_spacydefault'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evalulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 11ms/step\n",
      "Correctly Predicted:  207 / 1267\n",
      "Accuracy:  0.1633780584056827\n",
      "*****************************************************************\n",
      "******************** False statements *************************\n",
      "*****************************************************************\n",
      "******************** True Statements *************************\n",
      "0.362695\n",
      "index                                                             602\n",
      "id                                                          4579.json\n",
      "label                                                           false\n",
      "statement           Says Bill Clinton opposes President Barack Oba...\n",
      "subject                                         message-machine,taxes\n",
      "speaker                                           american-crossroads\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                      republican\n",
      "barely true                                                         5\n",
      "false                                                               5\n",
      "half-true                                                           4\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context                             a television ad airing in Orlando\n",
      "output                                                             -2\n",
      "subject_id                                                          5\n",
      "speaker_id                                                          3\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            0\n",
      "context_id                                                          1\n",
      "pos_id                [2, 9, 9, 2, 9, 9, 9, 1, 13, 2, 1, 5, 3, 9, 11]\n",
      "pos_id_DEFAULT      [17, 12, 12, 17, 12, 12, 12, 8, 10, 17, 8, 2, ...\n",
      "statement_custom    say bill clinton oppose president barack obama...\n",
      "statement_spacy     say bill clinton oppose president barack obama...\n",
      "word_id_custom      [3, 29, 69, 276, 16, 49, 198, 55, 63, 42, 707,...\n",
      "word_id_spacy       [1, 20, 49, 220, 10, 35, 155, 38, 44, 28, 625,...\n",
      "dep_id                [6, 3, 5, 10, 3, 3, 3, 8, 9, 10, 8, 1, 7, 2, 0]\n",
      "dep_id_custom        [7, 4, 6, 11, 4, 4, 4, 9, 10, 11, 9, 2, 8, 3, 1]\n",
      "Name: 602, dtype: object\n",
      "=============\n",
      "0.36245105\n",
      "index                                                             285\n",
      "id                                                          6974.json\n",
      "label                                                           false\n",
      "statement           Says House Democrats voted to use your tax dol...\n",
      "subject                            abortion,health-care,public-health\n",
      "speaker                                    tennessee-republican-party\n",
      "job_title                                                            \n",
      "state_info                                                  Tennessee\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               2\n",
      "half-true                                                           0\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context               a mailer sent for a state legislative campaign.\n",
      "output                                                             -2\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          2\n",
      "job_id                                                              0\n",
      "state_id                                                            1\n",
      "party_id                                                            0\n",
      "context_id                                                          7\n",
      "pos_id              [2, 9, 9, 2, 13, 2, 6, 1, 1, 5, 1, 5, 2, 5, 1,...\n",
      "pos_id_DEFAULT      [17, 12, 12, 17, 10, 17, 11, 8, 8, 2, 8, 2, 17...\n",
      "statement_custom    say house democrats vote use tax dollar aborti...\n",
      "statement_spacy     say house democrats vote use tax dollar aborti...\n",
      "word_id_custom      [3, 106, 157, 18, 76, 14, 82, 155, 18, 29, 257...\n",
      "word_id_spacy       [1, 76, 122, 12, 173, 8, 58, 120, 12, 20, 2463...\n",
      "dep_id              [6, 3, 5, 10, 9, 10, 10, 3, 8, 1, 2, 1, 10, 1,...\n",
      "dep_id_custom       [7, 4, 6, 11, 10, 11, 11, 4, 9, 2, 3, 2, 11, 2...\n",
      "Name: 285, dtype: object\n",
      "=============\n",
      "0.3522581\n",
      "index                                                            1238\n",
      "id                                                          4250.json\n",
      "label                                                      pants-fire\n",
      "statement           Says state Rep. Sandy Pasch, her recall oppone...\n",
      "subject                                            health-care,unions\n",
      "speaker                                               alberta-darling\n",
      "job_title                                 State Senator, 8th District\n",
      "state_info                                                  Wisconsin\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               1\n",
      "half-true                                                           2\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       1\n",
      "context                                    a TV ad and campaign flier\n",
      "output                                                             -3\n",
      "subject_id                                                          0\n",
      "speaker_id                                                         24\n",
      "job_id                                                              1\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          6\n",
      "pos_id              [2, 1, 9, 9, 9, 11, 6, 1, 1, 11, 2, 13, 2, 3, ...\n",
      "pos_id_DEFAULT      [17, 8, 12, 12, 12, 13, 11, 8, 8, 13, 17, 10, ...\n",
      "statement_custom    say state rep. sandy pasch recall opponent vot...\n",
      "statement_spacy     say state rep. sandy pasch recall opponent vot...\n",
      "word_id_custom      [3, 7, 227, 1377, 4338, 885, 546, 18, 153, 85,...\n",
      "word_id_spacy       [1, 4, 180, 1276, 4214, 795, 469, 12, 118, 60,...\n",
      "dep_id              [6, 3, 3, 3, 5, 0, 10, 3, 10, 0, 10, 9, 10, 7,...\n",
      "dep_id_custom       [7, 4, 4, 4, 6, 1, 11, 4, 11, 1, 11, 10, 11, 8...\n",
      "Name: 1238, dtype: object\n",
      "=============\n",
      "0.33238977\n",
      "index                                                             751\n",
      "id                                                          6813.json\n",
      "label                                                     barely-true\n",
      "statement           Says President Barack Obama already passed all...\n",
      "subject                                             health-care,taxes\n",
      "speaker                                                     paul-ryan\n",
      "job_title                                         U.S. Representative\n",
      "state_info                                                  Wisconsin\n",
      "party                                                      republican\n",
      "barely true                                                        19\n",
      "false                                                               6\n",
      "half-true                                                          16\n",
      "mostly-true                                                        14\n",
      "pants-on-fire                                                       2\n",
      "context                             an interview on \"Fox News Sunday\"\n",
      "output                                                             -1\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          1\n",
      "job_id                                                              1\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          1\n",
      "pos_id              [2, 9, 9, 9, 4, 2, 15, 15, 1, 1, 11, 4, 15, 1,...\n",
      "pos_id_DEFAULT      [17, 12, 12, 12, 3, 17, 6, 6, 8, 8, 13, 3, 6, ...\n",
      "statement_custom    say president barack obama already pass obamac...\n",
      "statement_spacy     say president barack obama pass obamacare taxi...\n",
      "word_id_custom      [3, 16, 49, 11, 318, 130, 97, 42, 127, 1392, 1...\n",
      "word_id_spacy       [1, 10, 35, 5, 98, 67, 28, 1291, 1399, 205, 77...\n",
      "dep_id              [6, 3, 3, 5, 10, 10, 10, 4, 3, 8, 0, 10, 10, 5...\n",
      "dep_id_custom       [7, 4, 4, 6, 11, 11, 11, 5, 4, 9, 1, 11, 11, 6...\n",
      "Name: 751, dtype: object\n",
      "=============\n",
      "0.32666957\n",
      "index                                                             117\n",
      "id                                                         12456.json\n",
      "label                                                     barely-true\n",
      "statement           Its entirely possible that the Democratic nomi...\n",
      "subject                                                        income\n",
      "speaker                                                    pat-toomey\n",
      "job_title                                   Candidate for U.S. Senate\n",
      "state_info                                               Pennsylvania\n",
      "party                                                      republican\n",
      "barely true                                                         3\n",
      "false                                                               2\n",
      "half-true                                                           2\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       0\n",
      "context             an interview with Chris Stigall on Talk Radio ...\n",
      "output                                                             -1\n",
      "subject_id                                                          3\n",
      "speaker_id                                                          3\n",
      "job_id                                                              1\n",
      "state_id                                                           17\n",
      "party_id                                                            0\n",
      "context_id                                                          7\n",
      "pos_id              [6, 4, 3, 8, 15, 3, 1, 11, 11, 9, 9, 11, 11, 2...\n",
      "pos_id_DEFAULT      [11, 3, 1, 15, 6, 1, 8, 13, 13, 12, 12, 13, 13...\n",
      "statement_custom    entirely possible that democratic nominee hill...\n",
      "statement_spacy     entirely possible democratic nominee hillary c...\n",
      "word_id_custom      [2101, 1097, 10, 243, 609, 104, 69, 344, 8, 68...\n",
      "word_id_spacy       [1994, 1005, 194, 532, 74, 49, 285, 48, 127, 1...\n",
      "dep_id              [10, 10, 7, 10, 4, 7, 5, 0, 0, 3, 10, 0, 0, 6,...\n",
      "dep_id_custom       [11, 11, 8, 11, 5, 8, 6, 1, 1, 4, 11, 1, 1, 7,...\n",
      "Name: 117, dtype: object\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "model_file = 'spacydefault-glove-adam_weights_best_20230413_005106.hdf5'\n",
    "# word_id_spacy + pos_id_default\n",
    "(fw, tb) = evaluate(model_file,\n",
    "                    {'main_input_spacy': X_test_spacy,\n",
    "                     'pos_input_default': X_test_pos_DEFAULT,\n",
    "                     'dep_input': X_test_dep,\n",
    "                     'aux_input': X_test_meta}\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### word_id_custom + pos_id_default"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6191 - categorical_accuracy: 0.2329\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.22741, saving model to customdefault-glove-adam_weights_best_20230413_005815.hdf5\n",
      "256/256 [==============================] - 15s 32ms/step - loss: 1.6191 - categorical_accuracy: 0.2329 - val_loss: 1.6102 - val_categorical_accuracy: 0.2274\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5901 - categorical_accuracy: 0.2523\n",
      "Epoch 2: val_categorical_accuracy improved from 0.22741 to 0.25779, saving model to customdefault-glove-adam_weights_best_20230413_005815.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5901 - categorical_accuracy: 0.2523 - val_loss: 1.5970 - val_categorical_accuracy: 0.2578\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5802 - categorical_accuracy: 0.2613\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5802 - categorical_accuracy: 0.2612 - val_loss: 1.5904 - val_categorical_accuracy: 0.2368\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5731 - categorical_accuracy: 0.2657\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5727 - categorical_accuracy: 0.2659 - val_loss: 1.5865 - val_categorical_accuracy: 0.2484\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5671 - categorical_accuracy: 0.2772\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5671 - categorical_accuracy: 0.2772 - val_loss: 1.5825 - val_categorical_accuracy: 0.2399\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5619 - categorical_accuracy: 0.2792\n",
      "Epoch 6: val_categorical_accuracy improved from 0.25779 to 0.26636, saving model to customdefault-glove-adam_weights_best_20230413_005815.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5619 - categorical_accuracy: 0.2792 - val_loss: 1.5872 - val_categorical_accuracy: 0.2664\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5586 - categorical_accuracy: 0.2839\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5586 - categorical_accuracy: 0.2839 - val_loss: 1.5778 - val_categorical_accuracy: 0.2625\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5533 - categorical_accuracy: 0.2911\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5533 - categorical_accuracy: 0.2911 - val_loss: 1.5787 - val_categorical_accuracy: 0.2601\n",
      "Epoch 9/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5506 - categorical_accuracy: 0.2875\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5504 - categorical_accuracy: 0.2878 - val_loss: 1.5767 - val_categorical_accuracy: 0.2586\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5452 - categorical_accuracy: 0.2962\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5452 - categorical_accuracy: 0.2962 - val_loss: 1.5738 - val_categorical_accuracy: 0.2625\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5415 - categorical_accuracy: 0.2994\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5417 - categorical_accuracy: 0.2993 - val_loss: 1.5766 - val_categorical_accuracy: 0.2578\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5387 - categorical_accuracy: 0.3073\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5386 - categorical_accuracy: 0.3072 - val_loss: 1.5740 - val_categorical_accuracy: 0.2625\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5330 - categorical_accuracy: 0.3096\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5330 - categorical_accuracy: 0.3096 - val_loss: 1.5780 - val_categorical_accuracy: 0.2632\n",
      "Epoch 14/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5305 - categorical_accuracy: 0.3125\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.26636\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5305 - categorical_accuracy: 0.3127 - val_loss: 1.5739 - val_categorical_accuracy: 0.2664\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5282 - categorical_accuracy: 0.3180\n",
      "Epoch 15: val_categorical_accuracy improved from 0.26636 to 0.27336, saving model to customdefault-glove-adam_weights_best_20230413_005815.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5282 - categorical_accuracy: 0.3180 - val_loss: 1.5782 - val_categorical_accuracy: 0.2734\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5264 - categorical_accuracy: 0.3191\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.27336\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5266 - categorical_accuracy: 0.3190 - val_loss: 1.5819 - val_categorical_accuracy: 0.2671\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5223 - categorical_accuracy: 0.3158\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.27336\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5223 - categorical_accuracy: 0.3158 - val_loss: 1.5722 - val_categorical_accuracy: 0.2664\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5176 - categorical_accuracy: 0.3261\n",
      "Epoch 18: val_categorical_accuracy improved from 0.27336 to 0.28115, saving model to customdefault-glove-adam_weights_best_20230413_005815.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5176 - categorical_accuracy: 0.3261 - val_loss: 1.5828 - val_categorical_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5214 - categorical_accuracy: 0.3198\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5214 - categorical_accuracy: 0.3196 - val_loss: 1.5769 - val_categorical_accuracy: 0.2734\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5147 - categorical_accuracy: 0.3285\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5147 - categorical_accuracy: 0.3285 - val_loss: 1.5721 - val_categorical_accuracy: 0.2555\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5122 - categorical_accuracy: 0.3301\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5122 - categorical_accuracy: 0.3301 - val_loss: 1.5702 - val_categorical_accuracy: 0.2656\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5105 - categorical_accuracy: 0.3295\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5106 - categorical_accuracy: 0.3293 - val_loss: 1.5702 - val_categorical_accuracy: 0.2656\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5065 - categorical_accuracy: 0.3349\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5065 - categorical_accuracy: 0.3347 - val_loss: 1.5794 - val_categorical_accuracy: 0.2757\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5032 - categorical_accuracy: 0.3349\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5032 - categorical_accuracy: 0.3349 - val_loss: 1.5760 - val_categorical_accuracy: 0.2710\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5047 - categorical_accuracy: 0.3350\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5051 - categorical_accuracy: 0.3348 - val_loss: 1.5751 - val_categorical_accuracy: 0.2796\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4993 - categorical_accuracy: 0.3390\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4990 - categorical_accuracy: 0.3393 - val_loss: 1.5784 - val_categorical_accuracy: 0.2741\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4991 - categorical_accuracy: 0.3390\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4991 - categorical_accuracy: 0.3390 - val_loss: 1.5712 - val_categorical_accuracy: 0.2788\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4963 - categorical_accuracy: 0.3380\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4958 - categorical_accuracy: 0.3385 - val_loss: 1.5799 - val_categorical_accuracy: 0.2734\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4922 - categorical_accuracy: 0.3444\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4922 - categorical_accuracy: 0.3444 - val_loss: 1.5717 - val_categorical_accuracy: 0.2804\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4911 - categorical_accuracy: 0.3440\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4911 - categorical_accuracy: 0.3440 - val_loss: 1.5718 - val_categorical_accuracy: 0.2804\n"
     ]
    }
   ],
   "source": [
    "# word_id_custom + pos_id_default\n",
    "train(model_bilstm_customdefault,\n",
    "      'customdefault-glove-adam',\n",
    "      {'main_input_custom': X_train_custom, 'pos_input_default': X_train_pos_DEFAULT, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input_custom': X_val_custom, 'pos_input_default': X_val_pos_DEFAULT, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam,\n",
    "      output_name='main_output_customdefault'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evalulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "32/32 [==============================] - 2s 12ms/step\n",
      "Correctly Predicted:  195 / 1267\n",
      "Accuracy:  0.15390686661404893\n",
      "*****************************************************************\n",
      "******************** False statements *************************\n",
      "*****************************************************************\n",
      "******************** True Statements *************************\n",
      "0.4116359\n",
      "index                                                            1216\n",
      "id                                                          2533.json\n",
      "label                                                       half-true\n",
      "statement           Newspapers say Florida made bad investments, l...\n",
      "subject             financial-regulation,message-machine,retiremen...\n",
      "speaker                                      republican-party-florida\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                      republican\n",
      "barely true                                                        10\n",
      "false                                                               6\n",
      "half-true                                                           6\n",
      "mostly-true                                                         6\n",
      "pants-on-fire                                                       4\n",
      "context                                                 a campaign ad\n",
      "output                                                              1\n",
      "subject_id                                                          4\n",
      "speaker_id                                                          1\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            0\n",
      "context_id                                                          6\n",
      "pos_id              [1, 2, 9, 2, 3, 1, 11, 2, 1, 5, 1, 5, 1, 11, 1...\n",
      "pos_id_DEFAULT      [8, 17, 12, 17, 1, 8, 13, 17, 8, 2, 8, 2, 8, 1...\n",
      "statement_custom    newspaper say florida make bad investment lose...\n",
      "statement_spacy     newspaper florida bad investment lose hundred ...\n",
      "word_id_custom      [1784, 3, 84, 48, 307, 791, 112, 543, 17, 82, ...\n",
      "word_id_spacy       [1684, 59, 248, 709, 81, 537, 11, 58, 23, 407,...\n",
      "dep_id              [5, 6, 5, 10, 7, 8, 0, 10, 10, 10, 8, 1, 2, 0,...\n",
      "dep_id_custom       [6, 7, 6, 11, 8, 9, 1, 11, 11, 11, 9, 2, 3, 1,...\n",
      "Name: 1216, dtype: object\n",
      "=============\n",
      "0.36552367\n",
      "index                                                             664\n",
      "id                                                          2117.json\n",
      "label                                                       half-true\n",
      "statement           In New Mexico, Democratic gubernatorial candid...\n",
      "subject                                        ethics,message-machine\n",
      "speaker                                               susana-martinez\n",
      "job_title                        Candidate for governor of New Mexico\n",
      "state_info                                                 New Mexico\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               0\n",
      "half-true                                                           1\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context                                         a campaign commercial\n",
      "output                                                              1\n",
      "subject_id                                                          2\n",
      "speaker_id                                                          3\n",
      "job_id                                                              9\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          6\n",
      "pos_id              [5, 9, 9, 11, 3, 3, 1, 9, 9, 2, 3, 1, 1, 5, 1,...\n",
      "pos_id_DEFAULT      [2, 12, 12, 13, 1, 1, 8, 12, 12, 17, 1, 8, 8, ...\n",
      "statement_custom    new mexico democratic gubernatorial candidate ...\n",
      "statement_spacy     new mexico democratic gubernatorial candidate ...\n",
      "word_id_custom      [27, 383, 243, 1423, 149, 4249, 5755, 62, 47, ...\n",
      "word_id_spacy       [18, 319, 194, 1325, 113, 4125, 5630, 43, 33, ...\n",
      "dep_id              [1, 3, 2, 0, 7, 7, 3, 3, 5, 6, 7, 3, 8, 1, 7, ...\n",
      "dep_id_custom       [2, 4, 3, 1, 8, 8, 4, 4, 6, 7, 8, 4, 9, 2, 8, ...\n",
      "Name: 664, dtype: object\n",
      "=============\n",
      "0.35851914\n",
      "index                                                            1238\n",
      "id                                                          4250.json\n",
      "label                                                      pants-fire\n",
      "statement           Says state Rep. Sandy Pasch, her recall oppone...\n",
      "subject                                            health-care,unions\n",
      "speaker                                               alberta-darling\n",
      "job_title                                 State Senator, 8th District\n",
      "state_info                                                  Wisconsin\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               1\n",
      "half-true                                                           2\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       1\n",
      "context                                    a TV ad and campaign flier\n",
      "output                                                             -3\n",
      "subject_id                                                          0\n",
      "speaker_id                                                         24\n",
      "job_id                                                              1\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          6\n",
      "pos_id              [2, 1, 9, 9, 9, 11, 6, 1, 1, 11, 2, 13, 2, 3, ...\n",
      "pos_id_DEFAULT      [17, 8, 12, 12, 12, 13, 11, 8, 8, 13, 17, 10, ...\n",
      "statement_custom    say state rep. sandy pasch recall opponent vot...\n",
      "statement_spacy     say state rep. sandy pasch recall opponent vot...\n",
      "word_id_custom      [3, 7, 227, 1377, 4338, 885, 546, 18, 153, 85,...\n",
      "word_id_spacy       [1, 4, 180, 1276, 4214, 795, 469, 12, 118, 60,...\n",
      "dep_id              [6, 3, 3, 3, 5, 0, 10, 3, 10, 0, 10, 9, 10, 7,...\n",
      "dep_id_custom       [7, 4, 4, 4, 6, 1, 11, 4, 11, 1, 11, 10, 11, 8...\n",
      "Name: 1238, dtype: object\n",
      "=============\n",
      "0.35421345\n",
      "index                                                             971\n",
      "id                                                         11761.json\n",
      "label                                                            true\n",
      "statement           Says Marco Rubio knows full well I voted for h...\n",
      "subject                         federal-budget,military,voting-record\n",
      "speaker                                                      ted-cruz\n",
      "job_title                                                     Senator\n",
      "state_info                                                      Texas\n",
      "party                                                      republican\n",
      "barely true                                                        36\n",
      "false                                                              33\n",
      "half-true                                                          15\n",
      "mostly-true                                                        19\n",
      "pants-on-fire                                                       8\n",
      "context             a Republican presidential debate in North Char...\n",
      "output                                                              3\n",
      "subject_id                                                          4\n",
      "speaker_id                                                         10\n",
      "job_id                                                              1\n",
      "state_id                                                            1\n",
      "party_id                                                            0\n",
      "context_id                                                          7\n",
      "pos_id              [2, 9, 9, 2, 3, 14, 6, 2, 5, 6, 1, 13, 2, 3, 1...\n",
      "pos_id_DEFAULT      [17, 12, 12, 17, 1, 7, 11, 17, 2, 11, 8, 10, 1...\n",
      "statement_custom    say marco rubio know full well vote amendment ...\n",
      "statement_spacy     say marco rubio know vote amendment increase m...\n",
      "word_id_custom      [3, 511, 478, 184, 519, 280, 18, 305, 58, 251,...\n",
      "word_id_spacy           [1, 439, 410, 146, 12, 246, 40, 201, 104, 23]\n",
      "dep_id              [6, 3, 5, 10, 10, 10, 5, 6, 1, 10, 2, 9, 10, 7...\n",
      "dep_id_custom       [7, 4, 6, 11, 11, 11, 6, 7, 2, 11, 3, 10, 11, ...\n",
      "Name: 971, dtype: object\n",
      "=============\n",
      "0.33768606\n",
      "index                                                             262\n",
      "id                                                           688.json\n",
      "label                                                           false\n",
      "statement           He was offered medical care for his injuries i...\n",
      "subject                                          candidates-biography\n",
      "speaker                                                 fred-thompson\n",
      "job_title                                                       Actor\n",
      "state_info                                                  Tennessee\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               4\n",
      "half-true                                                           3\n",
      "mostly-true                                                         3\n",
      "pants-on-fire                                                       0\n",
      "context                a speech at the Republican National Convention\n",
      "output                                                             -2\n",
      "subject_id                                                          4\n",
      "speaker_id                                                          1\n",
      "job_id                                                              7\n",
      "state_id                                                            1\n",
      "party_id                                                            0\n",
      "context_id                                                          7\n",
      "pos_id              [6, 12, 2, 3, 1, 5, 6, 1, 8, 6, 12, 2, 5, 3, 1...\n",
      "pos_id_DEFAULT      [11, 4, 17, 1, 8, 2, 11, 8, 15, 11, 4, 17, 2, ...\n",
      "statement_custom    be offer medical care injury if would give mil...\n",
      "statement_spacy     offer medical care injury military information...\n",
      "word_id_custom      [1, 628, 482, 22, 1750, 51, 21, 89, 251, 1170,...\n",
      "word_id_spacy       [550, 414, 16, 1650, 201, 1076, 459, 125, 157, 1]\n",
      "dep_id              [10, 10, 6, 7, 8, 1, 10, 2, 10, 5, 9, 10, 10, ...\n",
      "dep_id_custom       [11, 11, 7, 8, 9, 2, 11, 3, 11, 6, 10, 11, 11,...\n",
      "Name: 262, dtype: object\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "model_file = 'customdefault-glove-adam_weights_best_20230413_005815.hdf5'\n",
    "# word_id_spacy + pos_id_default\n",
    "(fw, tb) = evaluate(model_file,\n",
    "                    {'main_input_custom': X_test_custom,\n",
    "                     'pos_input_default': X_test_pos_DEFAULT,\n",
    "                     'dep_input': X_test_dep,\n",
    "                     'aux_input': X_test_meta}\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### word_id_spacy + pos_id_custom"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5976 - categorical_accuracy: 0.2659\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.26090, saving model to spacycustom-glove-adam_weights_best_20230413_010320.hdf5\n",
      "256/256 [==============================] - 14s 31ms/step - loss: 1.5976 - categorical_accuracy: 0.2659 - val_loss: 1.5914 - val_categorical_accuracy: 0.2609\n",
      "Epoch 2/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5425 - categorical_accuracy: 0.2994\n",
      "Epoch 2: val_categorical_accuracy improved from 0.26090 to 0.27414, saving model to spacycustom-glove-adam_weights_best_20230413_010320.hdf5\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5424 - categorical_accuracy: 0.2993 - val_loss: 1.5807 - val_categorical_accuracy: 0.2741\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5335 - categorical_accuracy: 0.3114\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.27414\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5335 - categorical_accuracy: 0.3114 - val_loss: 1.5801 - val_categorical_accuracy: 0.2656\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5226 - categorical_accuracy: 0.3175\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.27414\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5224 - categorical_accuracy: 0.3175 - val_loss: 1.5807 - val_categorical_accuracy: 0.2695\n",
      "Epoch 5/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5178 - categorical_accuracy: 0.3228\n",
      "Epoch 5: val_categorical_accuracy improved from 0.27414 to 0.28115, saving model to spacycustom-glove-adam_weights_best_20230413_010320.hdf5\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5177 - categorical_accuracy: 0.3226 - val_loss: 1.5795 - val_categorical_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5115 - categorical_accuracy: 0.3261\n",
      "Epoch 6: val_categorical_accuracy improved from 0.28115 to 0.28349, saving model to spacycustom-glove-adam_weights_best_20230413_010320.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5112 - categorical_accuracy: 0.3262 - val_loss: 1.5827 - val_categorical_accuracy: 0.2835\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5073 - categorical_accuracy: 0.3295\n",
      "Epoch 7: val_categorical_accuracy improved from 0.28349 to 0.29206, saving model to spacycustom-glove-adam_weights_best_20230413_010320.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5071 - categorical_accuracy: 0.3296 - val_loss: 1.5824 - val_categorical_accuracy: 0.2921\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5053 - categorical_accuracy: 0.3310\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.29206\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5050 - categorical_accuracy: 0.3313 - val_loss: 1.5802 - val_categorical_accuracy: 0.2796\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4968 - categorical_accuracy: 0.3383\n",
      "Epoch 9: val_categorical_accuracy improved from 0.29206 to 0.30607, saving model to spacycustom-glove-adam_weights_best_20230413_010320.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4968 - categorical_accuracy: 0.3383 - val_loss: 1.5821 - val_categorical_accuracy: 0.3061\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4939 - categorical_accuracy: 0.3410\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4939 - categorical_accuracy: 0.3410 - val_loss: 1.5895 - val_categorical_accuracy: 0.2998\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4863 - categorical_accuracy: 0.3436\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4863 - categorical_accuracy: 0.3436 - val_loss: 1.5796 - val_categorical_accuracy: 0.2913\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4845 - categorical_accuracy: 0.3488\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4845 - categorical_accuracy: 0.3490 - val_loss: 1.5869 - val_categorical_accuracy: 0.2695\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4787 - categorical_accuracy: 0.3459\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4787 - categorical_accuracy: 0.3459 - val_loss: 1.5888 - val_categorical_accuracy: 0.2632\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4747 - categorical_accuracy: 0.3533\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4747 - categorical_accuracy: 0.3533 - val_loss: 1.5846 - val_categorical_accuracy: 0.2804\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4743 - categorical_accuracy: 0.3523\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4744 - categorical_accuracy: 0.3520 - val_loss: 1.5867 - val_categorical_accuracy: 0.2796\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4689 - categorical_accuracy: 0.3568\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4688 - categorical_accuracy: 0.3567 - val_loss: 1.5906 - val_categorical_accuracy: 0.2858\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4637 - categorical_accuracy: 0.3613\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4637 - categorical_accuracy: 0.3613 - val_loss: 1.5881 - val_categorical_accuracy: 0.2718\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4643 - categorical_accuracy: 0.3634\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4643 - categorical_accuracy: 0.3634 - val_loss: 1.5868 - val_categorical_accuracy: 0.2765\n",
      "Epoch 19/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4570 - categorical_accuracy: 0.3630\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4571 - categorical_accuracy: 0.3628 - val_loss: 1.5913 - val_categorical_accuracy: 0.2640\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4566 - categorical_accuracy: 0.3605\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4562 - categorical_accuracy: 0.3606 - val_loss: 1.5942 - val_categorical_accuracy: 0.2656\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4500 - categorical_accuracy: 0.3725\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4500 - categorical_accuracy: 0.3725 - val_loss: 1.5904 - val_categorical_accuracy: 0.2656\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4449 - categorical_accuracy: 0.3658\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4451 - categorical_accuracy: 0.3659 - val_loss: 1.5967 - val_categorical_accuracy: 0.2625\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4435 - categorical_accuracy: 0.3750\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4435 - categorical_accuracy: 0.3750 - val_loss: 1.5962 - val_categorical_accuracy: 0.2640\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4445 - categorical_accuracy: 0.3708\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4445 - categorical_accuracy: 0.3708 - val_loss: 1.5927 - val_categorical_accuracy: 0.2804\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4426 - categorical_accuracy: 0.3768\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4427 - categorical_accuracy: 0.3764 - val_loss: 1.5932 - val_categorical_accuracy: 0.2780\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4347 - categorical_accuracy: 0.3812\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4354 - categorical_accuracy: 0.3809 - val_loss: 1.6097 - val_categorical_accuracy: 0.2718\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4302 - categorical_accuracy: 0.3807\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4302 - categorical_accuracy: 0.3807 - val_loss: 1.6030 - val_categorical_accuracy: 0.2726\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4249 - categorical_accuracy: 0.3844\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4251 - categorical_accuracy: 0.3846 - val_loss: 1.6084 - val_categorical_accuracy: 0.2640\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4289 - categorical_accuracy: 0.3817\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4289 - categorical_accuracy: 0.3817 - val_loss: 1.6038 - val_categorical_accuracy: 0.2780\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4215 - categorical_accuracy: 0.3872\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.30607\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4215 - categorical_accuracy: 0.3872 - val_loss: 1.6114 - val_categorical_accuracy: 0.2773\n"
     ]
    }
   ],
   "source": [
    "# word_id_spacy + pos_id_custom\n",
    "train(model_bilstm_spacycustom,\n",
    "      'spacycustom-glove-adam',\n",
    "      {'main_input_spacy': X_train_spacy, 'pos_input_custom': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input_spacy': X_val_spacy, 'pos_input_custom': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam,\n",
    "      output_name='main_output_spacycustom'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evalulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model_file = 'spacycustom-glove-adam_weights_best_20230413_010320.hdf5'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "32/32 [==============================] - 2s 12ms/step\n",
      "Correctly Predicted:  216 / 1267\n",
      "Accuracy:  0.17048145224940806\n",
      "*****************************************************************\n",
      "******************** False statements *************************\n",
      "*****************************************************************\n",
      "******************** True Statements *************************\n",
      "0.3766848\n",
      "index                                                             274\n",
      "id                                                          3436.json\n",
      "label                                                           false\n",
      "statement           Says his bill, HB 97, would prevent the use of...\n",
      "subject                                          abortion,health-care\n",
      "speaker                                                    matt-gaetz\n",
      "job_title                                        State Representative\n",
      "state_info                                                    Florida\n",
      "party                                                      republican\n",
      "barely true                                                         0\n",
      "false                                                               1\n",
      "half-true                                                           1\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       0\n",
      "context                          comments before a House subcommittee\n",
      "output                                                             -2\n",
      "subject_id                                                          0\n",
      "speaker_id                                                         25\n",
      "job_id                                                              1\n",
      "state_id                                                            2\n",
      "party_id                                                            0\n",
      "context_id                                                         11\n",
      "pos_id              [2, 6, 1, 11, 9, 7, 11, 12, 2, 15, 1, 5, 1, 1,...\n",
      "pos_id_DEFAULT      [17, 11, 8, 13, 12, 9, 13, 4, 17, 6, 8, 2, 8, ...\n",
      "statement_custom    say bill hb 97 would prevent use taxpayer doll...\n",
      "statement_spacy     say bill hb 97 prevent use taxpayer dollar abo...\n",
      "word_id_custom         [3, 29, 6600, 1307, 21, 752, 76, 167, 82, 155]\n",
      "word_id_spacy             [1, 20, 6478, 1209, 667, 173, 131, 58, 120]\n",
      "dep_id              [6, 10, 5, 0, 10, 10, 0, 9, 10, 4, 8, 1, 3, 2,...\n",
      "dep_id_custom       [7, 11, 6, 1, 11, 11, 1, 10, 11, 5, 9, 2, 4, 3...\n",
      "Name: 274, dtype: object\n",
      "=============\n",
      "0.35484874\n",
      "index                                                             562\n",
      "id                                                         13329.json\n",
      "label                                                     barely-true\n",
      "statement           Says Hillary Clinton takes tens of millions of...\n",
      "subject                                      foreign-policy,terrorism\n",
      "speaker                                              kellyanne-conway\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               1\n",
      "half-true                                                           0\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context                                  comments on \"Meet the Press\"\n",
      "output                                                             -1\n",
      "subject_id                                                          3\n",
      "speaker_id                                                          4\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            0\n",
      "context_id                                                         13\n",
      "pos_id              [2, 9, 9, 2, 1, 5, 1, 5, 1, 5, 1, 6, 2, 1, 11,...\n",
      "pos_id_DEFAULT      [17, 12, 12, 17, 8, 2, 8, 2, 8, 2, 8, 11, 17, ...\n",
      "statement_custom    say hillary clinton take ten million dollar co...\n",
      "statement_spacy     say hillary clinton take ten million dollar co...\n",
      "word_id_custom      [3, 104, 69, 39, 728, 17, 82, 35, 1332, 102, 5...\n",
      "word_id_spacy       [1, 74, 49, 46, 1075, 11, 58, 24, 1234, 72, 49...\n",
      "dep_id              [6, 3, 5, 10, 10, 10, 8, 1, 2, 1, 2, 5, 10, 8,...\n",
      "dep_id_custom       [7, 4, 6, 11, 11, 11, 9, 2, 3, 2, 3, 6, 11, 9,...\n",
      "Name: 562, dtype: object\n",
      "=============\n",
      "0.34903884\n",
      "index                                                             751\n",
      "id                                                          6813.json\n",
      "label                                                     barely-true\n",
      "statement           Says President Barack Obama already passed all...\n",
      "subject                                             health-care,taxes\n",
      "speaker                                                     paul-ryan\n",
      "job_title                                         U.S. Representative\n",
      "state_info                                                  Wisconsin\n",
      "party                                                      republican\n",
      "barely true                                                        19\n",
      "false                                                               6\n",
      "half-true                                                          16\n",
      "mostly-true                                                        14\n",
      "pants-on-fire                                                       2\n",
      "context                             an interview on \"Fox News Sunday\"\n",
      "output                                                             -1\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          1\n",
      "job_id                                                              1\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          1\n",
      "pos_id              [2, 9, 9, 9, 4, 2, 15, 15, 1, 1, 11, 4, 15, 1,...\n",
      "pos_id_DEFAULT      [17, 12, 12, 12, 3, 17, 6, 6, 8, 8, 13, 3, 6, ...\n",
      "statement_custom    say president barack obama already pass obamac...\n",
      "statement_spacy     say president barack obama pass obamacare taxi...\n",
      "word_id_custom      [3, 16, 49, 11, 318, 130, 97, 42, 127, 1392, 1...\n",
      "word_id_spacy       [1, 10, 35, 5, 98, 67, 28, 1291, 1399, 205, 77...\n",
      "dep_id              [6, 3, 3, 5, 10, 10, 10, 4, 3, 8, 0, 10, 10, 5...\n",
      "dep_id_custom       [7, 4, 4, 6, 11, 11, 11, 5, 4, 9, 1, 11, 11, 6...\n",
      "Name: 751, dtype: object\n",
      "=============\n",
      "0.34599605\n",
      "index                                                             358\n",
      "id                                                         12648.json\n",
      "label                                                     barely-true\n",
      "statement           Many Nevadans relied on Uber for work, but aft...\n",
      "subject                                                transportation\n",
      "speaker                                  freedom-partners-action-fund\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                    organization\n",
      "barely true                                                         1\n",
      "false                                                               1\n",
      "half-true                                                           1\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context                                               a television ad\n",
      "output                                                             -1\n",
      "subject_id                                                          2\n",
      "speaker_id                                                          1\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            3\n",
      "context_id                                                          1\n",
      "pos_id              [3, 9, 2, 5, 9, 5, 1, 11, 15, 5, 2, 15, 7, 5, ...\n",
      "pos_id_DEFAULT      [1, 12, 17, 2, 12, 2, 8, 13, 17, 2, 17, 16, 9,...\n",
      "statement_custom    many nevadans rely uber work but accept 70,000...\n",
      "statement_spacy     nevadans rely uber work accept $ 70,000 taxi c...\n",
      "word_id_custom      [226, 6475, 1783, 4346, 72, 74, 613, 347, 12, ...\n",
      "word_id_spacy       [6353, 1683, 4222, 51, 535, 288, 6, 6671, 108,...\n",
      "dep_id              [7, 5, 6, 1, 2, 1, 2, 0, 10, 1, 10, 10, 8, 1, ...\n",
      "dep_id_custom       [8, 6, 7, 2, 3, 2, 3, 1, 11, 2, 11, 11, 9, 2, ...\n",
      "Name: 358, dtype: object\n",
      "=============\n",
      "0.34478608\n",
      "index                                                             184\n",
      "id                                                          6884.json\n",
      "label                                                       half-true\n",
      "statement           Bill Nelson leased land that he owned for six ...\n",
      "subject                                             agriculture,taxes\n",
      "speaker                                           american-crossroads\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                      republican\n",
      "barely true                                                         5\n",
      "false                                                               5\n",
      "half-true                                                           4\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context                                               a TV commercial\n",
      "output                                                              1\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          3\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            0\n",
      "context_id                                                          1\n",
      "pos_id              [9, 9, 2, 1, 6, 6, 2, 5, 7, 1, 11, 2, 1, 5, 15...\n",
      "pos_id_DEFAULT      [12, 12, 17, 8, 11, 11, 17, 2, 9, 8, 13, 17, 8...\n",
      "statement_custom    bill nelson lease land own six cow take advant...\n",
      "statement_spacy     bill nelson lease land own cow take advantage ...\n",
      "word_id_custom      [29, 1169, 2085, 560, 165, 281, 8188, 39, 1342...\n",
      "word_id_spacy       [20, 1074, 1978, 483, 683, 8066, 46, 1242, 388...\n",
      "dep_id              [3, 5, 6, 8, 8, 5, 10, 1, 10, 2, 0, 10, 8, 1, ...\n",
      "dep_id_custom       [4, 6, 7, 9, 9, 6, 11, 2, 11, 3, 1, 11, 9, 2, ...\n",
      "Name: 184, dtype: object\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# word_id_spacy + pos_id_default\n",
    "(fw, tb) = evaluate(model_file,\n",
    "                    {'main_input_spacy': X_test_spacy,\n",
    "                     'pos_input_custom': X_test_pos_custom,\n",
    "                     'dep_input': X_test_dep,\n",
    "                     'aux_input': X_test_meta}\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### word_id_custom + pos_id_custom"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5910 - categorical_accuracy: 0.2637\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.26168, saving model to customcustom-glove-adam_weights_best_20230413_010911.hdf5\n",
      "256/256 [==============================] - 16s 36ms/step - loss: 1.5906 - categorical_accuracy: 0.2646 - val_loss: 1.5866 - val_categorical_accuracy: 0.2617\n",
      "Epoch 2/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5373 - categorical_accuracy: 0.3139\n",
      "Epoch 2: val_categorical_accuracy improved from 0.26168 to 0.26869, saving model to customcustom-glove-adam_weights_best_20230413_010911.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5372 - categorical_accuracy: 0.3141 - val_loss: 1.5760 - val_categorical_accuracy: 0.2687\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5232 - categorical_accuracy: 0.3261\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.26869\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5232 - categorical_accuracy: 0.3261 - val_loss: 1.5792 - val_categorical_accuracy: 0.2640\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5137 - categorical_accuracy: 0.3338\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.26869\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5137 - categorical_accuracy: 0.3338 - val_loss: 1.5830 - val_categorical_accuracy: 0.2671\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5107 - categorical_accuracy: 0.3359\n",
      "Epoch 5: val_categorical_accuracy improved from 0.26869 to 0.26947, saving model to customcustom-glove-adam_weights_best_20230413_010911.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5107 - categorical_accuracy: 0.3359 - val_loss: 1.5784 - val_categorical_accuracy: 0.2695\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5052 - categorical_accuracy: 0.3377\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.26947\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5052 - categorical_accuracy: 0.3377 - val_loss: 1.5884 - val_categorical_accuracy: 0.2625\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5002 - categorical_accuracy: 0.3393\n",
      "Epoch 7: val_categorical_accuracy improved from 0.26947 to 0.27882, saving model to customcustom-glove-adam_weights_best_20230413_010911.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5004 - categorical_accuracy: 0.3388 - val_loss: 1.5719 - val_categorical_accuracy: 0.2788\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4938 - categorical_accuracy: 0.3449\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4939 - categorical_accuracy: 0.3451 - val_loss: 1.5724 - val_categorical_accuracy: 0.2718\n",
      "Epoch 9/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4905 - categorical_accuracy: 0.3455\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4907 - categorical_accuracy: 0.3452 - val_loss: 1.5751 - val_categorical_accuracy: 0.2687\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4870 - categorical_accuracy: 0.3474\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4870 - categorical_accuracy: 0.3474 - val_loss: 1.5782 - val_categorical_accuracy: 0.2780\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4838 - categorical_accuracy: 0.3553\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4838 - categorical_accuracy: 0.3553 - val_loss: 1.5818 - val_categorical_accuracy: 0.2773\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4783 - categorical_accuracy: 0.3548\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4777 - categorical_accuracy: 0.3550 - val_loss: 1.5947 - val_categorical_accuracy: 0.2679\n",
      "Epoch 13/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4774 - categorical_accuracy: 0.3534\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4773 - categorical_accuracy: 0.3534 - val_loss: 1.5873 - val_categorical_accuracy: 0.2671\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4731 - categorical_accuracy: 0.3565\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4731 - categorical_accuracy: 0.3565 - val_loss: 1.5939 - val_categorical_accuracy: 0.2734\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4696 - categorical_accuracy: 0.3591\n",
      "Epoch 15: val_categorical_accuracy improved from 0.27882 to 0.28193, saving model to customcustom-glove-adam_weights_best_20230413_010911.hdf5\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.4694 - categorical_accuracy: 0.3594 - val_loss: 1.5879 - val_categorical_accuracy: 0.2819\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4634 - categorical_accuracy: 0.3690\n",
      "Epoch 16: val_categorical_accuracy improved from 0.28193 to 0.28427, saving model to customcustom-glove-adam_weights_best_20230413_010911.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4634 - categorical_accuracy: 0.3690 - val_loss: 1.5940 - val_categorical_accuracy: 0.2843\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4656 - categorical_accuracy: 0.3589\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4656 - categorical_accuracy: 0.3589 - val_loss: 1.5949 - val_categorical_accuracy: 0.2726\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4616 - categorical_accuracy: 0.3648\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4615 - categorical_accuracy: 0.3649 - val_loss: 1.5888 - val_categorical_accuracy: 0.2687\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4559 - categorical_accuracy: 0.3721\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4559 - categorical_accuracy: 0.3721 - val_loss: 1.5907 - val_categorical_accuracy: 0.2843\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4514 - categorical_accuracy: 0.3730\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4514 - categorical_accuracy: 0.3730 - val_loss: 1.5916 - val_categorical_accuracy: 0.2773\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4483 - categorical_accuracy: 0.3727\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4483 - categorical_accuracy: 0.3727 - val_loss: 1.5975 - val_categorical_accuracy: 0.2679\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4423 - categorical_accuracy: 0.3802\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4423 - categorical_accuracy: 0.3802 - val_loss: 1.5972 - val_categorical_accuracy: 0.2835\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4411 - categorical_accuracy: 0.3769\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.4411 - categorical_accuracy: 0.3772 - val_loss: 1.5903 - val_categorical_accuracy: 0.2765\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4386 - categorical_accuracy: 0.3779\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.4386 - categorical_accuracy: 0.3779 - val_loss: 1.6055 - val_categorical_accuracy: 0.2843\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4387 - categorical_accuracy: 0.3782\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4387 - categorical_accuracy: 0.3782 - val_loss: 1.5965 - val_categorical_accuracy: 0.2757\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4288 - categorical_accuracy: 0.3866\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.4289 - categorical_accuracy: 0.3862 - val_loss: 1.6020 - val_categorical_accuracy: 0.2710\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4291 - categorical_accuracy: 0.3840\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4291 - categorical_accuracy: 0.3844 - val_loss: 1.6143 - val_categorical_accuracy: 0.2765\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4243 - categorical_accuracy: 0.3905\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4243 - categorical_accuracy: 0.3902 - val_loss: 1.5994 - val_categorical_accuracy: 0.2734\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4242 - categorical_accuracy: 0.3911\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4239 - categorical_accuracy: 0.3912 - val_loss: 1.6021 - val_categorical_accuracy: 0.2780\n",
      "Epoch 30/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4204 - categorical_accuracy: 0.3862\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28427\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4203 - categorical_accuracy: 0.3866 - val_loss: 1.6192 - val_categorical_accuracy: 0.2632\n"
     ]
    }
   ],
   "source": [
    "# word_id_custom + pos_id_custom\n",
    "train(model_bilstm_customcustom,\n",
    "      'customcustom-glove-adam',\n",
    "      {'main_input_custom': X_train_custom, 'pos_input_custom': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input_custom': X_val_custom, 'pos_input_custom': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam,\n",
    "      output_name='main_output_customcustom'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evalulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model_file = 'customcustom-glove-adam_weights_best_20230413_010911.hdf5'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "32/32 [==============================] - 2s 14ms/step\n",
      "Correctly Predicted:  222 / 1267\n",
      "Accuracy:  0.17521704814522493\n",
      "*****************************************************************\n",
      "******************** False statements *************************\n",
      "*****************************************************************\n",
      "******************** True Statements *************************\n",
      "0.44238472\n",
      "index                                                            1238\n",
      "id                                                          4250.json\n",
      "label                                                      pants-fire\n",
      "statement           Says state Rep. Sandy Pasch, her recall oppone...\n",
      "subject                                            health-care,unions\n",
      "speaker                                               alberta-darling\n",
      "job_title                                 State Senator, 8th District\n",
      "state_info                                                  Wisconsin\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               1\n",
      "half-true                                                           2\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       1\n",
      "context                                    a TV ad and campaign flier\n",
      "output                                                             -3\n",
      "subject_id                                                          0\n",
      "speaker_id                                                         24\n",
      "job_id                                                              1\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          6\n",
      "pos_id              [2, 1, 9, 9, 9, 11, 6, 1, 1, 11, 2, 13, 2, 3, ...\n",
      "pos_id_DEFAULT      [17, 8, 12, 12, 12, 13, 11, 8, 8, 13, 17, 10, ...\n",
      "statement_custom    say state rep. sandy pasch recall opponent vot...\n",
      "statement_spacy     say state rep. sandy pasch recall opponent vot...\n",
      "word_id_custom      [3, 7, 227, 1377, 4338, 885, 546, 18, 153, 85,...\n",
      "word_id_spacy       [1, 4, 180, 1276, 4214, 795, 469, 12, 118, 60,...\n",
      "dep_id              [6, 3, 3, 3, 5, 0, 10, 3, 10, 0, 10, 9, 10, 7,...\n",
      "dep_id_custom       [7, 4, 4, 4, 6, 1, 11, 4, 11, 1, 11, 10, 11, 8...\n",
      "Name: 1238, dtype: object\n",
      "=============\n",
      "0.41652068\n",
      "index                                                             156\n",
      "id                                                         11867.json\n",
      "label                                                           false\n",
      "statement           Says CNN reported Ben Carson was taking a brea...\n",
      "subject                                          candidates-biography\n",
      "speaker                                                      ted-cruz\n",
      "job_title                                                     Senator\n",
      "state_info                                                      Texas\n",
      "party                                                      republican\n",
      "barely true                                                        36\n",
      "false                                                              33\n",
      "half-true                                                          15\n",
      "mostly-true                                                        19\n",
      "pants-on-fire                                                       8\n",
      "context                                  the New Hampshire GOP debate\n",
      "output                                                             -2\n",
      "subject_id                                                          4\n",
      "speaker_id                                                         10\n",
      "job_id                                                              1\n",
      "state_id                                                            1\n",
      "party_id                                                            0\n",
      "context_id                                                          8\n",
      "pos_id              [2, 9, 2, 9, 9, 12, 2, 15, 1, 5, 2, 15, 15, 9,...\n",
      "pos_id_DEFAULT      [17, 12, 17, 12, 12, 4, 17, 6, 8, 2, 17, 17, 6...\n",
      "statement_custom    say cnn report ben carson be take break campai...\n",
      "statement_spacy     say cnn report ben carson take break campaign ...\n",
      "word_id_custom      [3, 2695, 304, 2512, 7060, 1, 39, 285, 126, 4,...\n",
      "word_id_spacy       [1, 2579, 245, 2400, 6939, 46, 226, 95, 646, 9...\n",
      "dep_id              [6, 5, 10, 3, 5, 9, 10, 4, 8, 1, 2, 10, 4, 3, ...\n",
      "dep_id_custom       [7, 6, 11, 4, 6, 10, 11, 5, 9, 2, 3, 11, 5, 4,...\n",
      "Name: 156, dtype: object\n",
      "=============\n",
      "0.40744132\n",
      "index                                                              90\n",
      "id                                                          1075.json\n",
      "label                                                     barely-true\n",
      "statement           Mitch McConnell opposed \"legislation to create...\n",
      "subject                                   economy,health-care,workers\n",
      "speaker                                 democratic-national-committee\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                            none\n",
      "barely true                                                         8\n",
      "false                                                               2\n",
      "half-true                                                          10\n",
      "mostly-true                                                         8\n",
      "pants-on-fire                                                       0\n",
      "context                                               a television ad\n",
      "output                                                             -1\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          1\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            2\n",
      "context_id                                                          1\n",
      "pos_id              [9, 9, 2, 11, 1, 13, 2, 15, 2, 9, 1, 11, 11, 1...\n",
      "pos_id_DEFAULT      [12, 12, 17, 13, 8, 10, 17, 17, 17, 12, 8, 13,...\n",
      "statement_custom    mitch mcconnell oppose legislation create and ...\n",
      "statement_spacy     mitch mcconnell oppose legislation create prot...\n",
      "word_id_custom      [1883, 1884, 276, 252, 92, 4, 544, 2752, 15, 1...\n",
      "word_id_spacy       [1782, 1783, 220, 202, 63, 467, 2635, 9, 149, ...\n",
      "dep_id              [3, 5, 6, 0, 8, 9, 10, 10, 10, 3, 8, 0, 0, 0, ...\n",
      "dep_id_custom       [4, 6, 7, 1, 9, 10, 11, 11, 11, 4, 9, 1, 1, 1,...\n",
      "Name: 90, dtype: object\n",
      "=============\n",
      "0.40474746\n",
      "index                                                            1165\n",
      "id                                                          8979.json\n",
      "label                                                     barely-true\n",
      "statement           Says Tom Cottons vote in Congress to change Me...\n",
      "subject                               health-care,medicare,retirement\n",
      "speaker                                                    mark-pryor\n",
      "job_title                                                U.S. Senator\n",
      "state_info                                                   Arkansas\n",
      "party                                                        democrat\n",
      "barely true                                                         2\n",
      "false                                                               0\n",
      "half-true                                                           0\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       0\n",
      "context                                                 a campaign ad\n",
      "output                                                             -1\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          0\n",
      "job_id                                                              1\n",
      "state_id                                                           19\n",
      "party_id                                                            1\n",
      "context_id                                                          6\n",
      "pos_id              [2, 9, 9, 1, 5, 9, 13, 2, 9, 12, 2, 5, 11, 5, ...\n",
      "pos_id_DEFAULT      [17, 12, 12, 8, 2, 12, 10, 17, 12, 4, 17, 2, 1...\n",
      "statement_custom    say tom cottons vote congress change medicare ...\n",
      "statement_spacy     say tom cottons vote congress change medicare ...\n",
      "word_id_custom      [3, 682, 18, 121, 176, 115, 24, 58, 1139, 1314...\n",
      "word_id_spacy       [1, 600, 12, 90, 140, 84, 40, 1045, 1215, 312,...\n",
      "dep_id              [6, 3, 3, 5, 1, 2, 9, 10, 8, 9, 10, 10, 0, 1, ...\n",
      "dep_id_custom       [7, 4, 4, 6, 2, 3, 10, 11, 9, 10, 11, 11, 1, 2...\n",
      "Name: 1165, dtype: object\n",
      "=============\n",
      "0.39309365\n",
      "index                                                             184\n",
      "id                                                          6884.json\n",
      "label                                                       half-true\n",
      "statement           Bill Nelson leased land that he owned for six ...\n",
      "subject                                             agriculture,taxes\n",
      "speaker                                           american-crossroads\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                      republican\n",
      "barely true                                                         5\n",
      "false                                                               5\n",
      "half-true                                                           4\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context                                               a TV commercial\n",
      "output                                                              1\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          3\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            0\n",
      "context_id                                                          1\n",
      "pos_id              [9, 9, 2, 1, 6, 6, 2, 5, 7, 1, 11, 2, 1, 5, 15...\n",
      "pos_id_DEFAULT      [12, 12, 17, 8, 11, 11, 17, 2, 9, 8, 13, 17, 8...\n",
      "statement_custom    bill nelson lease land own six cow take advant...\n",
      "statement_spacy     bill nelson lease land own cow take advantage ...\n",
      "word_id_custom      [29, 1169, 2085, 560, 165, 281, 8188, 39, 1342...\n",
      "word_id_spacy       [20, 1074, 1978, 483, 683, 8066, 46, 1242, 388...\n",
      "dep_id              [3, 5, 6, 8, 8, 5, 10, 1, 10, 2, 0, 10, 8, 1, ...\n",
      "dep_id_custom       [4, 6, 7, 9, 9, 6, 11, 2, 11, 3, 1, 11, 9, 2, ...\n",
      "Name: 184, dtype: object\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "(fw, tb) = evaluate(model_file,\n",
    "                    {'main_input_custom': X_test_custom,\n",
    "                     'pos_input_custom': X_test_pos_custom,\n",
    "                     'dep_input': X_test_dep,\n",
    "                     'aux_input': X_test_meta}\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## APRIL 13th Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 12ms/step\n",
      "Correctly Predicted:  207 / 1267\n",
      "Accuracy:  0.1633780584056827\n",
      "*****************************************************************\n",
      "******************** False statements *************************\n",
      "*****************************************************************\n",
      "******************** True Statements *************************\n",
      "0.362695\n",
      "index                                                             602\n",
      "id                                                          4579.json\n",
      "label                                                           false\n",
      "statement           Says Bill Clinton opposes President Barack Oba...\n",
      "subject                                         message-machine,taxes\n",
      "speaker                                           american-crossroads\n",
      "job_title                                                            \n",
      "state_info                                                           \n",
      "party                                                      republican\n",
      "barely true                                                         5\n",
      "false                                                               5\n",
      "half-true                                                           4\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context                             a television ad airing in Orlando\n",
      "output                                                             -2\n",
      "subject_id                                                          5\n",
      "speaker_id                                                          3\n",
      "job_id                                                              0\n",
      "state_id                                                            0\n",
      "party_id                                                            0\n",
      "context_id                                                          1\n",
      "pos_id                [2, 9, 9, 2, 9, 9, 9, 1, 13, 2, 1, 5, 3, 9, 11]\n",
      "pos_id_DEFAULT      [17, 12, 12, 17, 12, 12, 12, 8, 10, 17, 8, 2, ...\n",
      "statement_custom    say bill clinton oppose president barack obama...\n",
      "statement_spacy     say bill clinton oppose president barack obama...\n",
      "word_id_custom      [3, 29, 69, 276, 16, 49, 198, 55, 63, 42, 707,...\n",
      "word_id_spacy       [1, 20, 49, 220, 10, 35, 155, 38, 44, 28, 625,...\n",
      "dep_id                [6, 3, 5, 10, 3, 3, 3, 8, 9, 10, 8, 1, 7, 2, 0]\n",
      "dep_id_custom        [7, 4, 6, 11, 4, 4, 4, 9, 10, 11, 9, 2, 8, 3, 1]\n",
      "Name: 602, dtype: object\n",
      "=============\n",
      "0.36245105\n",
      "index                                                             285\n",
      "id                                                          6974.json\n",
      "label                                                           false\n",
      "statement           Says House Democrats voted to use your tax dol...\n",
      "subject                            abortion,health-care,public-health\n",
      "speaker                                    tennessee-republican-party\n",
      "job_title                                                            \n",
      "state_info                                                  Tennessee\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               2\n",
      "half-true                                                           0\n",
      "mostly-true                                                         0\n",
      "pants-on-fire                                                       0\n",
      "context               a mailer sent for a state legislative campaign.\n",
      "output                                                             -2\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          2\n",
      "job_id                                                              0\n",
      "state_id                                                            1\n",
      "party_id                                                            0\n",
      "context_id                                                          7\n",
      "pos_id              [2, 9, 9, 2, 13, 2, 6, 1, 1, 5, 1, 5, 2, 5, 1,...\n",
      "pos_id_DEFAULT      [17, 12, 12, 17, 10, 17, 11, 8, 8, 2, 8, 2, 17...\n",
      "statement_custom    say house democrats vote use tax dollar aborti...\n",
      "statement_spacy     say house democrats vote use tax dollar aborti...\n",
      "word_id_custom      [3, 106, 157, 18, 76, 14, 82, 155, 18, 29, 257...\n",
      "word_id_spacy       [1, 76, 122, 12, 173, 8, 58, 120, 12, 20, 2463...\n",
      "dep_id              [6, 3, 5, 10, 9, 10, 10, 3, 8, 1, 2, 1, 10, 1,...\n",
      "dep_id_custom       [7, 4, 6, 11, 10, 11, 11, 4, 9, 2, 3, 2, 11, 2...\n",
      "Name: 285, dtype: object\n",
      "=============\n",
      "0.3522581\n",
      "index                                                            1238\n",
      "id                                                          4250.json\n",
      "label                                                      pants-fire\n",
      "statement           Says state Rep. Sandy Pasch, her recall oppone...\n",
      "subject                                            health-care,unions\n",
      "speaker                                               alberta-darling\n",
      "job_title                                 State Senator, 8th District\n",
      "state_info                                                  Wisconsin\n",
      "party                                                      republican\n",
      "barely true                                                         1\n",
      "false                                                               1\n",
      "half-true                                                           2\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       1\n",
      "context                                    a TV ad and campaign flier\n",
      "output                                                             -3\n",
      "subject_id                                                          0\n",
      "speaker_id                                                         24\n",
      "job_id                                                              1\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          6\n",
      "pos_id              [2, 1, 9, 9, 9, 11, 6, 1, 1, 11, 2, 13, 2, 3, ...\n",
      "pos_id_DEFAULT      [17, 8, 12, 12, 12, 13, 11, 8, 8, 13, 17, 10, ...\n",
      "statement_custom    say state rep. sandy pasch recall opponent vot...\n",
      "statement_spacy     say state rep. sandy pasch recall opponent vot...\n",
      "word_id_custom      [3, 7, 227, 1377, 4338, 885, 546, 18, 153, 85,...\n",
      "word_id_spacy       [1, 4, 180, 1276, 4214, 795, 469, 12, 118, 60,...\n",
      "dep_id              [6, 3, 3, 3, 5, 0, 10, 3, 10, 0, 10, 9, 10, 7,...\n",
      "dep_id_custom       [7, 4, 4, 4, 6, 1, 11, 4, 11, 1, 11, 10, 11, 8...\n",
      "Name: 1238, dtype: object\n",
      "=============\n",
      "0.33238977\n",
      "index                                                             751\n",
      "id                                                          6813.json\n",
      "label                                                     barely-true\n",
      "statement           Says President Barack Obama already passed all...\n",
      "subject                                             health-care,taxes\n",
      "speaker                                                     paul-ryan\n",
      "job_title                                         U.S. Representative\n",
      "state_info                                                  Wisconsin\n",
      "party                                                      republican\n",
      "barely true                                                        19\n",
      "false                                                               6\n",
      "half-true                                                          16\n",
      "mostly-true                                                        14\n",
      "pants-on-fire                                                       2\n",
      "context                             an interview on \"Fox News Sunday\"\n",
      "output                                                             -1\n",
      "subject_id                                                          0\n",
      "speaker_id                                                          1\n",
      "job_id                                                              1\n",
      "state_id                                                            3\n",
      "party_id                                                            0\n",
      "context_id                                                          1\n",
      "pos_id              [2, 9, 9, 9, 4, 2, 15, 15, 1, 1, 11, 4, 15, 1,...\n",
      "pos_id_DEFAULT      [17, 12, 12, 12, 3, 17, 6, 6, 8, 8, 13, 3, 6, ...\n",
      "statement_custom    say president barack obama already pass obamac...\n",
      "statement_spacy     say president barack obama pass obamacare taxi...\n",
      "word_id_custom      [3, 16, 49, 11, 318, 130, 97, 42, 127, 1392, 1...\n",
      "word_id_spacy       [1, 10, 35, 5, 98, 67, 28, 1291, 1399, 205, 77...\n",
      "dep_id              [6, 3, 3, 5, 10, 10, 10, 4, 3, 8, 0, 10, 10, 5...\n",
      "dep_id_custom       [7, 4, 4, 6, 11, 11, 11, 5, 4, 9, 1, 11, 11, 6...\n",
      "Name: 751, dtype: object\n",
      "=============\n",
      "0.32666957\n",
      "index                                                             117\n",
      "id                                                         12456.json\n",
      "label                                                     barely-true\n",
      "statement           Its entirely possible that the Democratic nomi...\n",
      "subject                                                        income\n",
      "speaker                                                    pat-toomey\n",
      "job_title                                   Candidate for U.S. Senate\n",
      "state_info                                               Pennsylvania\n",
      "party                                                      republican\n",
      "barely true                                                         3\n",
      "false                                                               2\n",
      "half-true                                                           2\n",
      "mostly-true                                                         1\n",
      "pants-on-fire                                                       0\n",
      "context             an interview with Chris Stigall on Talk Radio ...\n",
      "output                                                             -1\n",
      "subject_id                                                          3\n",
      "speaker_id                                                          3\n",
      "job_id                                                              1\n",
      "state_id                                                           17\n",
      "party_id                                                            0\n",
      "context_id                                                          7\n",
      "pos_id              [6, 4, 3, 8, 15, 3, 1, 11, 11, 9, 9, 11, 11, 2...\n",
      "pos_id_DEFAULT      [11, 3, 1, 15, 6, 1, 8, 13, 13, 12, 12, 13, 13...\n",
      "statement_custom    entirely possible that democratic nominee hill...\n",
      "statement_spacy     entirely possible democratic nominee hillary c...\n",
      "word_id_custom      [2101, 1097, 10, 243, 609, 104, 69, 344, 8, 68...\n",
      "word_id_spacy       [1994, 1005, 194, 532, 74, 49, 285, 48, 127, 1...\n",
      "dep_id              [10, 10, 7, 10, 4, 7, 5, 0, 0, 3, 10, 0, 0, 6,...\n",
      "dep_id_custom       [11, 11, 8, 11, 5, 8, 6, 1, 1, 4, 11, 1, 1, 7,...\n",
      "Name: 117, dtype: object\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "model_file = 'spacydefault-glove-adam_weights_best_20230413_005106.hdf5'\n",
    "# word_id_spacy + pos_id_default\n",
    "(fw, tb) = evaluate(model_file,\n",
    "                    {'main_input_spacy': X_test_spacy,\n",
    "                     'pos_input_default': X_test_pos_DEFAULT,\n",
    "                     'dep_input': X_test_dep,\n",
    "                     'aux_input': X_test_meta}\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### APRIL 12th"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrixes: (9496, 100)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vocab_length_spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape of the embedding matrixes:\u001B[39m\u001B[38;5;124m\"\u001B[39m, embedding_matrix_spacy_100d\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of the vocabulary dictionary:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mvocab_length_spacy\u001B[49m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_train_custom shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, X_train_spacy\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_val_custom shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, X_val_spacy\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'vocab_length_spacy' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the embedding matrixes:\", embedding_matrix_spacy_100d.shape)\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length_spacy)\n",
    "print(\"X_train_custom shape:\", X_train_spacy.shape)\n",
    "print(\"X_val_custom shape:\", X_val_spacy.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5380 - categorical_accuracy: 0.3056\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.27492, saving model to wcustom-poscustom-dep-meta-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 14s 33ms/step - loss: 1.5380 - categorical_accuracy: 0.3056 - val_loss: 1.5799 - val_categorical_accuracy: 0.2749\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5370 - categorical_accuracy: 0.3067\n",
      "Epoch 2: val_categorical_accuracy improved from 0.27492 to 0.27570, saving model to wcustom-poscustom-dep-meta-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5370 - categorical_accuracy: 0.3067 - val_loss: 1.5826 - val_categorical_accuracy: 0.2757\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5351 - categorical_accuracy: 0.3088\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5352 - categorical_accuracy: 0.3086 - val_loss: 1.5808 - val_categorical_accuracy: 0.2617\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5332 - categorical_accuracy: 0.3079\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5329 - categorical_accuracy: 0.3083 - val_loss: 1.5803 - val_categorical_accuracy: 0.2671\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5317 - categorical_accuracy: 0.3105\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5317 - categorical_accuracy: 0.3105 - val_loss: 1.5777 - val_categorical_accuracy: 0.2710\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5295 - categorical_accuracy: 0.3111\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5295 - categorical_accuracy: 0.3111 - val_loss: 1.5760 - val_categorical_accuracy: 0.2726\n",
      "Epoch 7/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5258 - categorical_accuracy: 0.3195\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5262 - categorical_accuracy: 0.3190 - val_loss: 1.5779 - val_categorical_accuracy: 0.2718\n",
      "Epoch 8/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5244 - categorical_accuracy: 0.3179\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5246 - categorical_accuracy: 0.3181 - val_loss: 1.5806 - val_categorical_accuracy: 0.2656\n",
      "Epoch 9/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5220 - categorical_accuracy: 0.3157\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5221 - categorical_accuracy: 0.3160 - val_loss: 1.5722 - val_categorical_accuracy: 0.2749\n",
      "Epoch 10/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5206 - categorical_accuracy: 0.3161\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5210 - categorical_accuracy: 0.3156 - val_loss: 1.5750 - val_categorical_accuracy: 0.2757\n",
      "Epoch 11/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5186 - categorical_accuracy: 0.3202\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5195 - categorical_accuracy: 0.3197 - val_loss: 1.5730 - val_categorical_accuracy: 0.2726\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5164 - categorical_accuracy: 0.3214\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5164 - categorical_accuracy: 0.3214 - val_loss: 1.5752 - val_categorical_accuracy: 0.2671\n",
      "Epoch 13/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5140 - categorical_accuracy: 0.3231\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5146 - categorical_accuracy: 0.3228 - val_loss: 1.5764 - val_categorical_accuracy: 0.2702\n",
      "Epoch 14/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5112 - categorical_accuracy: 0.3279\n",
      "Epoch 14: val_categorical_accuracy improved from 0.27570 to 0.28115, saving model to wcustom-poscustom-dep-meta-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5114 - categorical_accuracy: 0.3278 - val_loss: 1.5731 - val_categorical_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5091 - categorical_accuracy: 0.3303\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5091 - categorical_accuracy: 0.3303 - val_loss: 1.5718 - val_categorical_accuracy: 0.2780\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5084 - categorical_accuracy: 0.3344\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5082 - categorical_accuracy: 0.3346 - val_loss: 1.5781 - val_categorical_accuracy: 0.2796\n",
      "Epoch 17/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5077 - categorical_accuracy: 0.3325\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5078 - categorical_accuracy: 0.3324 - val_loss: 1.5729 - val_categorical_accuracy: 0.2695\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5031 - categorical_accuracy: 0.3382\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5032 - categorical_accuracy: 0.3379 - val_loss: 1.5739 - val_categorical_accuracy: 0.2710\n",
      "Epoch 19/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5011 - categorical_accuracy: 0.3373\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5012 - categorical_accuracy: 0.3376 - val_loss: 1.5759 - val_categorical_accuracy: 0.2695\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4984 - categorical_accuracy: 0.3376\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.4984 - categorical_accuracy: 0.3376 - val_loss: 1.5734 - val_categorical_accuracy: 0.2679\n",
      "Epoch 21/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.4976 - categorical_accuracy: 0.3401\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4979 - categorical_accuracy: 0.3401 - val_loss: 1.5731 - val_categorical_accuracy: 0.2796\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4922 - categorical_accuracy: 0.3468\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4922 - categorical_accuracy: 0.3468 - val_loss: 1.5735 - val_categorical_accuracy: 0.2734\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4899 - categorical_accuracy: 0.3519\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.4899 - categorical_accuracy: 0.3519 - val_loss: 1.5814 - val_categorical_accuracy: 0.2702\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4889 - categorical_accuracy: 0.3481\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.4889 - categorical_accuracy: 0.3481 - val_loss: 1.5796 - val_categorical_accuracy: 0.2749\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4881 - categorical_accuracy: 0.3439\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.4882 - categorical_accuracy: 0.3439 - val_loss: 1.5795 - val_categorical_accuracy: 0.2734\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4852 - categorical_accuracy: 0.3501\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 8s 32ms/step - loss: 1.4852 - categorical_accuracy: 0.3501 - val_loss: 1.5795 - val_categorical_accuracy: 0.2718\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4824 - categorical_accuracy: 0.3534\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 8s 29ms/step - loss: 1.4824 - categorical_accuracy: 0.3534 - val_loss: 1.5809 - val_categorical_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4808 - categorical_accuracy: 0.3544\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.4806 - categorical_accuracy: 0.3547 - val_loss: 1.5805 - val_categorical_accuracy: 0.2765\n",
      "Epoch 29/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.4788 - categorical_accuracy: 0.3535\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 9s 34ms/step - loss: 1.4786 - categorical_accuracy: 0.3541 - val_loss: 1.5778 - val_categorical_accuracy: 0.2788\n",
      "Epoch 30/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.4757 - categorical_accuracy: 0.3531\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28115\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.4757 - categorical_accuracy: 0.3527 - val_loss: 1.5828 - val_categorical_accuracy: 0.2710\n"
     ]
    }
   ],
   "source": [
    "# Config 1a\n",
    "# word_id_custom, pos_custom, dep, meta ADAM optimizer\n",
    "train(model_bilstm_customcustom,\n",
    "      'wcustom-poscustom-dep-meta-glove100d-adam',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5345 - categorical_accuracy: 0.3092\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.26947, saving model to customcustom_weights_best_20230412_202519.hdf5\n",
      "256/256 [==============================] - 25s 69ms/step - loss: 1.5345 - categorical_accuracy: 0.3092 - val_loss: 1.5742 - val_categorical_accuracy: 0.2695\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5335 - categorical_accuracy: 0.3104\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.26947\n",
      "256/256 [==============================] - 16s 62ms/step - loss: 1.5335 - categorical_accuracy: 0.3104 - val_loss: 1.5766 - val_categorical_accuracy: 0.2687\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5316 - categorical_accuracy: 0.3102\n",
      "Epoch 3: val_categorical_accuracy improved from 0.26947 to 0.28349, saving model to customcustom_weights_best_20230412_202519.hdf5\n",
      "256/256 [==============================] - 16s 61ms/step - loss: 1.5316 - categorical_accuracy: 0.3102 - val_loss: 1.5715 - val_categorical_accuracy: 0.2835\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5311 - categorical_accuracy: 0.3122\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5311 - categorical_accuracy: 0.3122 - val_loss: 1.5727 - val_categorical_accuracy: 0.2796\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5289 - categorical_accuracy: 0.3172\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 61ms/step - loss: 1.5289 - categorical_accuracy: 0.3172 - val_loss: 1.5728 - val_categorical_accuracy: 0.2749\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5271 - categorical_accuracy: 0.3189\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 61ms/step - loss: 1.5271 - categorical_accuracy: 0.3189 - val_loss: 1.5761 - val_categorical_accuracy: 0.2804\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5277 - categorical_accuracy: 0.3172\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5277 - categorical_accuracy: 0.3172 - val_loss: 1.5752 - val_categorical_accuracy: 0.2687\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5257 - categorical_accuracy: 0.3128\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 61ms/step - loss: 1.5257 - categorical_accuracy: 0.3128 - val_loss: 1.5734 - val_categorical_accuracy: 0.2757\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5237 - categorical_accuracy: 0.3226\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 62ms/step - loss: 1.5237 - categorical_accuracy: 0.3226 - val_loss: 1.5734 - val_categorical_accuracy: 0.2773\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5210 - categorical_accuracy: 0.3247\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.5210 - categorical_accuracy: 0.3247 - val_loss: 1.5725 - val_categorical_accuracy: 0.2765\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5197 - categorical_accuracy: 0.3259\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 1.5197 - categorical_accuracy: 0.3259 - val_loss: 1.5742 - val_categorical_accuracy: 0.2679\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5178 - categorical_accuracy: 0.3235\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 1.5178 - categorical_accuracy: 0.3235 - val_loss: 1.5768 - val_categorical_accuracy: 0.2687\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5195 - categorical_accuracy: 0.3287\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 1.5195 - categorical_accuracy: 0.3287 - val_loss: 1.5721 - val_categorical_accuracy: 0.2757\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5167 - categorical_accuracy: 0.3255\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 1.5167 - categorical_accuracy: 0.3255 - val_loss: 1.5695 - val_categorical_accuracy: 0.2804\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5129 - categorical_accuracy: 0.3313\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 1.5129 - categorical_accuracy: 0.3313 - val_loss: 1.5753 - val_categorical_accuracy: 0.2741\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5124 - categorical_accuracy: 0.3314\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 17s 67ms/step - loss: 1.5124 - categorical_accuracy: 0.3314 - val_loss: 1.5745 - val_categorical_accuracy: 0.2656\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5115 - categorical_accuracy: 0.3291\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 18s 69ms/step - loss: 1.5115 - categorical_accuracy: 0.3291 - val_loss: 1.5795 - val_categorical_accuracy: 0.2765\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5102 - categorical_accuracy: 0.3344\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 1.5102 - categorical_accuracy: 0.3344 - val_loss: 1.5736 - val_categorical_accuracy: 0.2741\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5078 - categorical_accuracy: 0.3365\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 17s 67ms/step - loss: 1.5078 - categorical_accuracy: 0.3365 - val_loss: 1.5818 - val_categorical_accuracy: 0.2757\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5073 - categorical_accuracy: 0.3353\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.5073 - categorical_accuracy: 0.3353 - val_loss: 1.5784 - val_categorical_accuracy: 0.2741\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5051 - categorical_accuracy: 0.3408\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.5051 - categorical_accuracy: 0.3408 - val_loss: 1.5784 - val_categorical_accuracy: 0.2671\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5060 - categorical_accuracy: 0.3384\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.5060 - categorical_accuracy: 0.3384 - val_loss: 1.5896 - val_categorical_accuracy: 0.2625\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5033 - categorical_accuracy: 0.3351\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.5033 - categorical_accuracy: 0.3351 - val_loss: 1.5739 - val_categorical_accuracy: 0.2734\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5033 - categorical_accuracy: 0.3396\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.5033 - categorical_accuracy: 0.3396 - val_loss: 1.5790 - val_categorical_accuracy: 0.2718\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5011 - categorical_accuracy: 0.3385\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.5011 - categorical_accuracy: 0.3385 - val_loss: 1.5749 - val_categorical_accuracy: 0.2749\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4985 - categorical_accuracy: 0.3459\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.4985 - categorical_accuracy: 0.3459 - val_loss: 1.5766 - val_categorical_accuracy: 0.2734\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4965 - categorical_accuracy: 0.3420\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.4965 - categorical_accuracy: 0.3420 - val_loss: 1.5876 - val_categorical_accuracy: 0.2765\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4963 - categorical_accuracy: 0.3441\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.4963 - categorical_accuracy: 0.3441 - val_loss: 1.5756 - val_categorical_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4934 - categorical_accuracy: 0.3459\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.4934 - categorical_accuracy: 0.3459 - val_loss: 1.5797 - val_categorical_accuracy: 0.2679\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4912 - categorical_accuracy: 0.3482\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 1.4912 - categorical_accuracy: 0.3482 - val_loss: 1.5877 - val_categorical_accuracy: 0.2640\n"
     ]
    }
   ],
   "source": [
    "# Config 1b\n",
    "##### fixing name exists ######\n",
    "# word_id_custom, pos_custom, dep, meta SGD optimizer\n",
    "train(model_bilstm_customcustom,\n",
    "      'customcustom',\n",
    "      {'main_input_custom': X_train_custom, 'pos_input_custom': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input_custom': X_val_custom, 'pos_input_custom': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=sgd,\n",
    "      output_name='main_output_customcustom'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6215 - categorical_accuracy: 0.2438\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.22274, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 21s 58ms/step - loss: 1.6215 - categorical_accuracy: 0.2438 - val_loss: 1.6160 - val_categorical_accuracy: 0.2227\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5995 - categorical_accuracy: 0.2515\n",
      "Epoch 2: val_categorical_accuracy improved from 0.22274 to 0.24844, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 57ms/step - loss: 1.5995 - categorical_accuracy: 0.2515 - val_loss: 1.6060 - val_categorical_accuracy: 0.2484\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5949 - categorical_accuracy: 0.2536\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.24844\n",
      "256/256 [==============================] - 15s 58ms/step - loss: 1.5949 - categorical_accuracy: 0.2536 - val_loss: 1.6027 - val_categorical_accuracy: 0.2430\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5903 - categorical_accuracy: 0.2567\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.24844\n",
      "256/256 [==============================] - 15s 58ms/step - loss: 1.5905 - categorical_accuracy: 0.2563 - val_loss: 1.5996 - val_categorical_accuracy: 0.2375\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5878 - categorical_accuracy: 0.2593\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.24844\n",
      "256/256 [==============================] - 15s 58ms/step - loss: 1.5878 - categorical_accuracy: 0.2593 - val_loss: 1.5990 - val_categorical_accuracy: 0.2321\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5846 - categorical_accuracy: 0.2646\n",
      "Epoch 6: val_categorical_accuracy improved from 0.24844 to 0.25467, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5846 - categorical_accuracy: 0.2646 - val_loss: 1.5929 - val_categorical_accuracy: 0.2547\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5830 - categorical_accuracy: 0.2626\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.25467\n",
      "256/256 [==============================] - 15s 57ms/step - loss: 1.5830 - categorical_accuracy: 0.2626 - val_loss: 1.5904 - val_categorical_accuracy: 0.2547\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5805 - categorical_accuracy: 0.2636\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.25467\n",
      "256/256 [==============================] - 15s 58ms/step - loss: 1.5805 - categorical_accuracy: 0.2636 - val_loss: 1.5893 - val_categorical_accuracy: 0.2438\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5780 - categorical_accuracy: 0.2707\n",
      "Epoch 9: val_categorical_accuracy improved from 0.25467 to 0.25779, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5780 - categorical_accuracy: 0.2707 - val_loss: 1.5918 - val_categorical_accuracy: 0.2578\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5763 - categorical_accuracy: 0.2743\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 1.5763 - categorical_accuracy: 0.2743 - val_loss: 1.5895 - val_categorical_accuracy: 0.2422\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5735 - categorical_accuracy: 0.2752\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5735 - categorical_accuracy: 0.2752 - val_loss: 1.5896 - val_categorical_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5701 - categorical_accuracy: 0.2846\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5701 - categorical_accuracy: 0.2846 - val_loss: 1.5887 - val_categorical_accuracy: 0.2445\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5659 - categorical_accuracy: 0.2787\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5659 - categorical_accuracy: 0.2787 - val_loss: 1.5851 - val_categorical_accuracy: 0.2508\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5624 - categorical_accuracy: 0.2837\n",
      "Epoch 14: val_categorical_accuracy improved from 0.25779 to 0.25857, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5624 - categorical_accuracy: 0.2837 - val_loss: 1.5847 - val_categorical_accuracy: 0.2586\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5613 - categorical_accuracy: 0.2788\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.25857\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5613 - categorical_accuracy: 0.2788 - val_loss: 1.5856 - val_categorical_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5604 - categorical_accuracy: 0.2838\n",
      "Epoch 16: val_categorical_accuracy improved from 0.25857 to 0.27336, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5604 - categorical_accuracy: 0.2838 - val_loss: 1.5835 - val_categorical_accuracy: 0.2734\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5567 - categorical_accuracy: 0.2889\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.27336\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5567 - categorical_accuracy: 0.2889 - val_loss: 1.5850 - val_categorical_accuracy: 0.2516\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5556 - categorical_accuracy: 0.2901\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.27336\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5556 - categorical_accuracy: 0.2901 - val_loss: 1.5808 - val_categorical_accuracy: 0.2671\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5550 - categorical_accuracy: 0.2886\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.27336\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5550 - categorical_accuracy: 0.2886 - val_loss: 1.5831 - val_categorical_accuracy: 0.2640\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5520 - categorical_accuracy: 0.2918\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.27336\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5520 - categorical_accuracy: 0.2918 - val_loss: 1.5821 - val_categorical_accuracy: 0.2710\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5505 - categorical_accuracy: 0.2939\n",
      "Epoch 21: val_categorical_accuracy improved from 0.27336 to 0.27414, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5505 - categorical_accuracy: 0.2939 - val_loss: 1.5820 - val_categorical_accuracy: 0.2741\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5493 - categorical_accuracy: 0.2948\n",
      "Epoch 22: val_categorical_accuracy improved from 0.27414 to 0.27570, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5493 - categorical_accuracy: 0.2948 - val_loss: 1.5777 - val_categorical_accuracy: 0.2757\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5469 - categorical_accuracy: 0.2959\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5469 - categorical_accuracy: 0.2959 - val_loss: 1.5836 - val_categorical_accuracy: 0.2547\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5459 - categorical_accuracy: 0.3006\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5459 - categorical_accuracy: 0.3006 - val_loss: 1.5796 - val_categorical_accuracy: 0.2679\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5444 - categorical_accuracy: 0.2975\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5444 - categorical_accuracy: 0.2975 - val_loss: 1.5820 - val_categorical_accuracy: 0.2679\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5439 - categorical_accuracy: 0.2995\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5439 - categorical_accuracy: 0.2995 - val_loss: 1.5820 - val_categorical_accuracy: 0.2593\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5418 - categorical_accuracy: 0.3023\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 15s 59ms/step - loss: 1.5418 - categorical_accuracy: 0.3023 - val_loss: 1.5797 - val_categorical_accuracy: 0.2679\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5406 - categorical_accuracy: 0.2999\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5406 - categorical_accuracy: 0.2999 - val_loss: 1.5750 - val_categorical_accuracy: 0.2749\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5375 - categorical_accuracy: 0.3084\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.27570\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5375 - categorical_accuracy: 0.3084 - val_loss: 1.5780 - val_categorical_accuracy: 0.2726\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5365 - categorical_accuracy: 0.3105\n",
      "Epoch 30: val_categorical_accuracy improved from 0.27570 to 0.27882, saving model to customcustom_weights_best_20230412_191613.hdf5\n",
      "256/256 [==============================] - 15s 60ms/step - loss: 1.5365 - categorical_accuracy: 0.3105 - val_loss: 1.5753 - val_categorical_accuracy: 0.2788\n"
     ]
    }
   ],
   "source": [
    "# Config 1b AGAIANSDIBSAUI0FBISPA\n",
    "##### fixing name exists ######\n",
    "# word_id_custom, pos_custom, dep, meta SGD optimizer\n",
    "train(model_bilstm_customcustom,\n",
    "      'customcustom',\n",
    "      {'main_input_custom': X_train_custom, 'pos_input_custom': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input_custom': X_val_custom, 'pos_input_custom': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=sgd,\n",
    "      output_name='main_output_customcustom'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.6505 - categorical_accuracy: 0.2429\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.23832, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 14s 32ms/step - loss: 1.6503 - categorical_accuracy: 0.2430 - val_loss: 1.6206 - val_categorical_accuracy: 0.2383\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6055 - categorical_accuracy: 0.2504\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.23832\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.6055 - categorical_accuracy: 0.2504 - val_loss: 1.6075 - val_categorical_accuracy: 0.2321\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5969 - categorical_accuracy: 0.2546\n",
      "Epoch 3: val_categorical_accuracy improved from 0.23832 to 0.24533, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5969 - categorical_accuracy: 0.2546 - val_loss: 1.6025 - val_categorical_accuracy: 0.2453\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5913 - categorical_accuracy: 0.2597\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.24533\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 1.5913 - categorical_accuracy: 0.2602 - val_loss: 1.5974 - val_categorical_accuracy: 0.2399\n",
      "Epoch 5/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5888 - categorical_accuracy: 0.2573\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.24533\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5886 - categorical_accuracy: 0.2576 - val_loss: 1.5996 - val_categorical_accuracy: 0.2305\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5852 - categorical_accuracy: 0.2653\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.24533\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5851 - categorical_accuracy: 0.2654 - val_loss: 1.5907 - val_categorical_accuracy: 0.2414\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5830 - categorical_accuracy: 0.2627\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.24533\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5833 - categorical_accuracy: 0.2622 - val_loss: 1.5933 - val_categorical_accuracy: 0.2383\n",
      "Epoch 8/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5814 - categorical_accuracy: 0.2662\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.24533\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5816 - categorical_accuracy: 0.2661 - val_loss: 1.5905 - val_categorical_accuracy: 0.2399\n",
      "Epoch 9/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5797 - categorical_accuracy: 0.2666\n",
      "Epoch 9: val_categorical_accuracy improved from 0.24533 to 0.24611, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5796 - categorical_accuracy: 0.2672 - val_loss: 1.5916 - val_categorical_accuracy: 0.2461\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5780 - categorical_accuracy: 0.2680\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.24611\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5780 - categorical_accuracy: 0.2680 - val_loss: 1.5909 - val_categorical_accuracy: 0.2438\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5760 - categorical_accuracy: 0.2673\n",
      "Epoch 11: val_categorical_accuracy improved from 0.24611 to 0.24688, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5760 - categorical_accuracy: 0.2671 - val_loss: 1.5890 - val_categorical_accuracy: 0.2469\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5741 - categorical_accuracy: 0.2748\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.24688\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5741 - categorical_accuracy: 0.2748 - val_loss: 1.5876 - val_categorical_accuracy: 0.2430\n",
      "Epoch 13/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5727 - categorical_accuracy: 0.2746\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.24688\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5726 - categorical_accuracy: 0.2745 - val_loss: 1.5871 - val_categorical_accuracy: 0.2453\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5706 - categorical_accuracy: 0.2754\n",
      "Epoch 14: val_categorical_accuracy improved from 0.24688 to 0.25078, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5706 - categorical_accuracy: 0.2754 - val_loss: 1.5864 - val_categorical_accuracy: 0.2508\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5673 - categorical_accuracy: 0.2788\n",
      "Epoch 15: val_categorical_accuracy improved from 0.25078 to 0.25467, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5673 - categorical_accuracy: 0.2784 - val_loss: 1.5841 - val_categorical_accuracy: 0.2547\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5628 - categorical_accuracy: 0.2869\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.25467\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5628 - categorical_accuracy: 0.2869 - val_loss: 1.5817 - val_categorical_accuracy: 0.2547\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5606 - categorical_accuracy: 0.2845\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.25467\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5606 - categorical_accuracy: 0.2845 - val_loss: 1.5844 - val_categorical_accuracy: 0.2508\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5598 - categorical_accuracy: 0.2889\n",
      "Epoch 18: val_categorical_accuracy improved from 0.25467 to 0.26402, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 32ms/step - loss: 1.5598 - categorical_accuracy: 0.2890 - val_loss: 1.5798 - val_categorical_accuracy: 0.2640\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5565 - categorical_accuracy: 0.2854\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.26402\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5565 - categorical_accuracy: 0.2854 - val_loss: 1.5791 - val_categorical_accuracy: 0.2593\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5562 - categorical_accuracy: 0.2872\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.26402\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5560 - categorical_accuracy: 0.2872 - val_loss: 1.5806 - val_categorical_accuracy: 0.2578\n",
      "Epoch 21/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5537 - categorical_accuracy: 0.2883\n",
      "Epoch 21: val_categorical_accuracy improved from 0.26402 to 0.26713, saving model to wcustom-poscustom-dep-meta-glove100d_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5536 - categorical_accuracy: 0.2890 - val_loss: 1.5840 - val_categorical_accuracy: 0.2671\n",
      "Epoch 22/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5529 - categorical_accuracy: 0.2886\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 8s 29ms/step - loss: 1.5529 - categorical_accuracy: 0.2892 - val_loss: 1.5817 - val_categorical_accuracy: 0.2656\n",
      "Epoch 23/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5511 - categorical_accuracy: 0.2895\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5514 - categorical_accuracy: 0.2896 - val_loss: 1.5795 - val_categorical_accuracy: 0.2593\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5508 - categorical_accuracy: 0.2915\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5508 - categorical_accuracy: 0.2915 - val_loss: 1.5827 - val_categorical_accuracy: 0.2531\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5494 - categorical_accuracy: 0.2975\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5492 - categorical_accuracy: 0.2982 - val_loss: 1.5784 - val_categorical_accuracy: 0.2593\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5484 - categorical_accuracy: 0.2974\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5484 - categorical_accuracy: 0.2974 - val_loss: 1.5803 - val_categorical_accuracy: 0.2562\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5466 - categorical_accuracy: 0.2977\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 8s 32ms/step - loss: 1.5466 - categorical_accuracy: 0.2977 - val_loss: 1.5815 - val_categorical_accuracy: 0.2586\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5445 - categorical_accuracy: 0.2988\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5444 - categorical_accuracy: 0.2991 - val_loss: 1.5876 - val_categorical_accuracy: 0.2461\n",
      "Epoch 29/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5432 - categorical_accuracy: 0.3001\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5433 - categorical_accuracy: 0.3005 - val_loss: 1.5914 - val_categorical_accuracy: 0.2671\n",
      "Epoch 30/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5418 - categorical_accuracy: 0.2998\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.26713\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5425 - categorical_accuracy: 0.2996 - val_loss: 1.5810 - val_categorical_accuracy: 0.2593\n"
     ]
    }
   ],
   "source": [
    "# Config 1b\n",
    "# word_id_custom, pos_custom, dep, meta SGD optimizer\n",
    "train(model_bilstm_customcustom,\n",
    "      'wcustom-poscustom-dep-meta-glove100d',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=sgd\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6542 - categorical_accuracy: 0.2368\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.23832, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 16s 40ms/step - loss: 1.6539 - categorical_accuracy: 0.2374 - val_loss: 1.6054 - val_categorical_accuracy: 0.2383\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5962 - categorical_accuracy: 0.2520\n",
      "Epoch 2: val_categorical_accuracy improved from 0.23832 to 0.24455, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 1.5962 - categorical_accuracy: 0.2520 - val_loss: 1.6006 - val_categorical_accuracy: 0.2445\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5877 - categorical_accuracy: 0.2538\n",
      "Epoch 3: val_categorical_accuracy improved from 0.24455 to 0.24611, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 1.5876 - categorical_accuracy: 0.2539 - val_loss: 1.5920 - val_categorical_accuracy: 0.2461\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5810 - categorical_accuracy: 0.2618\n",
      "Epoch 4: val_categorical_accuracy improved from 0.24611 to 0.25234, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 1.5807 - categorical_accuracy: 0.2620 - val_loss: 1.5853 - val_categorical_accuracy: 0.2523\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5753 - categorical_accuracy: 0.2705\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.25234\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 1.5752 - categorical_accuracy: 0.2711 - val_loss: 1.5837 - val_categorical_accuracy: 0.2453\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5729 - categorical_accuracy: 0.2636\n",
      "Epoch 6: val_categorical_accuracy improved from 0.25234 to 0.25935, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 1.5726 - categorical_accuracy: 0.2642 - val_loss: 1.5817 - val_categorical_accuracy: 0.2593\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5666 - categorical_accuracy: 0.2834\n",
      "Epoch 7: val_categorical_accuracy improved from 0.25935 to 0.26324, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 1.5669 - categorical_accuracy: 0.2830 - val_loss: 1.5749 - val_categorical_accuracy: 0.2632\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5632 - categorical_accuracy: 0.2841\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.26324\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 1.5632 - categorical_accuracy: 0.2842 - val_loss: 1.5808 - val_categorical_accuracy: 0.2570\n",
      "Epoch 9/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5609 - categorical_accuracy: 0.2836\n",
      "Epoch 9: val_categorical_accuracy improved from 0.26324 to 0.26791, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 1.5608 - categorical_accuracy: 0.2838 - val_loss: 1.5739 - val_categorical_accuracy: 0.2679\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5573 - categorical_accuracy: 0.2879\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.26791\n",
      "256/256 [==============================] - 11s 43ms/step - loss: 1.5573 - categorical_accuracy: 0.2879 - val_loss: 1.5768 - val_categorical_accuracy: 0.2679\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5541 - categorical_accuracy: 0.2858\n",
      "Epoch 11: val_categorical_accuracy improved from 0.26791 to 0.27882, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 1.5541 - categorical_accuracy: 0.2858 - val_loss: 1.5698 - val_categorical_accuracy: 0.2788\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5511 - categorical_accuracy: 0.2921\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5515 - categorical_accuracy: 0.2914 - val_loss: 1.5700 - val_categorical_accuracy: 0.2687\n",
      "Epoch 13/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5505 - categorical_accuracy: 0.2968\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 10s 37ms/step - loss: 1.5501 - categorical_accuracy: 0.2971 - val_loss: 1.5786 - val_categorical_accuracy: 0.2702\n",
      "Epoch 14/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5464 - categorical_accuracy: 0.3006\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 1.5461 - categorical_accuracy: 0.3007 - val_loss: 1.5707 - val_categorical_accuracy: 0.2780\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5446 - categorical_accuracy: 0.2953\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.27882\n",
      "256/256 [==============================] - 11s 43ms/step - loss: 1.5446 - categorical_accuracy: 0.2953 - val_loss: 1.5732 - val_categorical_accuracy: 0.2749\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5415 - categorical_accuracy: 0.2979\n",
      "Epoch 16: val_categorical_accuracy improved from 0.27882 to 0.28349, saving model to wspacy-poscustom-glove100d-adam_weights_best.hdf5\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 1.5415 - categorical_accuracy: 0.2979 - val_loss: 1.5693 - val_categorical_accuracy: 0.2835\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5396 - categorical_accuracy: 0.3025\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 11s 41ms/step - loss: 1.5396 - categorical_accuracy: 0.3025 - val_loss: 1.5683 - val_categorical_accuracy: 0.2773\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5367 - categorical_accuracy: 0.3011\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 1.5367 - categorical_accuracy: 0.3011 - val_loss: 1.5700 - val_categorical_accuracy: 0.2734\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5363 - categorical_accuracy: 0.3036\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 1.5363 - categorical_accuracy: 0.3036 - val_loss: 1.5704 - val_categorical_accuracy: 0.2710\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5326 - categorical_accuracy: 0.3124\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5326 - categorical_accuracy: 0.3122 - val_loss: 1.5674 - val_categorical_accuracy: 0.2773\n",
      "Epoch 21/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5294 - categorical_accuracy: 0.3118\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5295 - categorical_accuracy: 0.3115 - val_loss: 1.5667 - val_categorical_accuracy: 0.2773\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5266 - categorical_accuracy: 0.3144\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5270 - categorical_accuracy: 0.3146 - val_loss: 1.5709 - val_categorical_accuracy: 0.2788\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5264 - categorical_accuracy: 0.3189\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5264 - categorical_accuracy: 0.3189 - val_loss: 1.5686 - val_categorical_accuracy: 0.2734\n",
      "Epoch 24/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5201 - categorical_accuracy: 0.3246\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5204 - categorical_accuracy: 0.3243 - val_loss: 1.5730 - val_categorical_accuracy: 0.2773\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5184 - categorical_accuracy: 0.3223\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5190 - categorical_accuracy: 0.3218 - val_loss: 1.5805 - val_categorical_accuracy: 0.2702\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5180 - categorical_accuracy: 0.3233\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5180 - categorical_accuracy: 0.3233 - val_loss: 1.5736 - val_categorical_accuracy: 0.2796\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5145 - categorical_accuracy: 0.3251\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5141 - categorical_accuracy: 0.3257 - val_loss: 1.5684 - val_categorical_accuracy: 0.2804\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5108 - categorical_accuracy: 0.3323\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 1.5108 - categorical_accuracy: 0.3323 - val_loss: 1.5755 - val_categorical_accuracy: 0.2640\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5098 - categorical_accuracy: 0.3311\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 1.5101 - categorical_accuracy: 0.3306 - val_loss: 1.5711 - val_categorical_accuracy: 0.2804\n",
      "Epoch 30/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5042 - categorical_accuracy: 0.3324\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28349\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.5040 - categorical_accuracy: 0.3323 - val_loss: 1.5728 - val_categorical_accuracy: 0.2687\n"
     ]
    }
   ],
   "source": [
    "# Config 2a\n",
    "# word_id_spacy, pos_custom, dep, meta, ADAM optimizer\n",
    "train(model_bilstm_spacycustom,\n",
    "      'wspacy-poscustom-glove100d-adam',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_spacy, 'pos_input': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5824 - categorical_accuracy: 0.2665\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.23520, saving model to please_weights_best_20230412_191224.hdf5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[133], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Config 3AGAIN\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m##### INCLUDES TIME IN HDF5 file #####\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# word_id_spacy, pos_custom, dep, meta, ADAM optimizer\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm_spacydefault\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mplease\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input_spacy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_spacy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input_default\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_pos_DEFAULT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdep_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_dep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maux_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_meta\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input_spacy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_spacy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input_default\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_pos_DEFAULT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdep_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_dep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maux_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_meta\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m      \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madam\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output_spacydefault\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[0;32m     11\u001B[0m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[131], line 22\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, train_inputs, val_inputs, optimizer, output_name)\u001B[0m\n\u001B[0;32m     18\u001B[0m filepath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_weights_best_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtimestamp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.hdf5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     19\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(filepath, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_categorical_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     20\u001B[0m                                               verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m, save_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 22\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[43moutput_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43moutput_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcsv_logger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\h5py\\_hl\\group.py:161\u001B[0m, in \u001B[0;36mGroup.create_dataset\u001B[1;34m(self, name, shape, dtype, data, **kwds)\u001B[0m\n\u001B[0;32m    158\u001B[0m         parent_path, name \u001B[38;5;241m=\u001B[39m name\u001B[38;5;241m.\u001B[39mrsplit(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    159\u001B[0m         group \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequire_group(parent_path)\n\u001B[1;32m--> 161\u001B[0m dsid \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mmake_new_dset(group, shape, dtype, data, name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    162\u001B[0m dset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mDataset(dsid)\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dset\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\h5py\\_hl\\dataset.py:156\u001B[0m, in \u001B[0;36mmake_new_dset\u001B[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter)\u001B[0m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    153\u001B[0m     sid \u001B[38;5;241m=\u001B[39m h5s\u001B[38;5;241m.\u001B[39mcreate_simple(shape, maxshape)\n\u001B[1;32m--> 156\u001B[0m dset_id \u001B[38;5;241m=\u001B[39m \u001B[43mh5d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdcpl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdcpl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdapl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdapl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, Empty)):\n\u001B[0;32m    159\u001B[0m     dset_id\u001B[38;5;241m.\u001B[39mwrite(h5s\u001B[38;5;241m.\u001B[39mALL, h5s\u001B[38;5;241m.\u001B[39mALL, data)\n",
      "File \u001B[1;32mh5py\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\h5d.pyx:87\u001B[0m, in \u001B[0;36mh5py.h5d.create\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "# Config 3AGAIN\n",
    "##### INCLUDES TIME IN HDF5 file #####\n",
    "# word_id_spacy, pos_custom, dep, meta, ADAM optimizer\n",
    "\n",
    "train(model_bilstm_spacydefault,\n",
    "      'please',\n",
    "      {'main_input_spacy': X_train_spacy, 'pos_input_default': X_train_pos_DEFAULT, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input_spacy': X_val_spacy, 'pos_input_default': X_val_pos_DEFAULT, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam,\n",
    "      output_name='main_output_spacydefault'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/256 [..............................] - ETA: 8s - loss: 1.5008 - categorical_accuracy: 0.3350WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0346s vs `on_train_batch_end` time: 0.2596s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0346s vs `on_train_batch_end` time: 0.2596s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - ETA: 0s - loss: 1.5300 - categorical_accuracy: 0.3173\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.26791277527809143. Saving model to wspacyy_posdefault_glove100d_adam_weights_best.hdf5.\n",
      "256/256 [==============================] - 19s 46ms/step - loss: 1.5300 - categorical_accuracy: 0.3173 - val_loss: 1.5861 - val_categorical_accuracy: 0.2679\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5271 - categorical_accuracy: 0.3146\n",
      "Epoch 2: val_categorical_accuracy improved from 0.26791277527809143 to 0.28582555055618286. Saving model to wspacyy_posdefault_glove100d_adam_weights_best.hdf5.\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 1.5271 - categorical_accuracy: 0.3146 - val_loss: 1.5731 - val_categorical_accuracy: 0.2858\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5203 - categorical_accuracy: 0.3181\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.28582555055618286.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.5203 - categorical_accuracy: 0.3181 - val_loss: 1.5824 - val_categorical_accuracy: 0.2664\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5157 - categorical_accuracy: 0.3284\n",
      "Epoch 4: val_categorical_accuracy improved from 0.28582555055618286 to 0.28738316893577576. Saving model to wspacyy_posdefault_glove100d_adam_weights_best.hdf5.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.5157 - categorical_accuracy: 0.3284 - val_loss: 1.5767 - val_categorical_accuracy: 0.2874\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5105 - categorical_accuracy: 0.3289\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 1.5102 - categorical_accuracy: 0.3290 - val_loss: 1.5824 - val_categorical_accuracy: 0.2687\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5084 - categorical_accuracy: 0.3299\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 1.5084 - categorical_accuracy: 0.3299 - val_loss: 1.5847 - val_categorical_accuracy: 0.2726\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5037 - categorical_accuracy: 0.3350\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 1.5039 - categorical_accuracy: 0.3349 - val_loss: 1.5786 - val_categorical_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5005 - categorical_accuracy: 0.3366\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 1.5005 - categorical_accuracy: 0.3366 - val_loss: 1.5778 - val_categorical_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4930 - categorical_accuracy: 0.3413\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 1.4932 - categorical_accuracy: 0.3410 - val_loss: 1.5912 - val_categorical_accuracy: 0.2562\n",
      "Epoch 10/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4925 - categorical_accuracy: 0.3363\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.4921 - categorical_accuracy: 0.3364 - val_loss: 1.5878 - val_categorical_accuracy: 0.2773\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4875 - categorical_accuracy: 0.3488\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 49ms/step - loss: 1.4875 - categorical_accuracy: 0.3487 - val_loss: 1.5819 - val_categorical_accuracy: 0.2796\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4841 - categorical_accuracy: 0.3528\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.4843 - categorical_accuracy: 0.3528 - val_loss: 1.5868 - val_categorical_accuracy: 0.2788\n",
      "Epoch 13/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4803 - categorical_accuracy: 0.3507\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.4801 - categorical_accuracy: 0.3507 - val_loss: 1.5920 - val_categorical_accuracy: 0.2648\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4780 - categorical_accuracy: 0.3508\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 13s 49ms/step - loss: 1.4780 - categorical_accuracy: 0.3508 - val_loss: 1.5928 - val_categorical_accuracy: 0.2664\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4758 - categorical_accuracy: 0.3561\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 1.4758 - categorical_accuracy: 0.3561 - val_loss: 1.5974 - val_categorical_accuracy: 0.2656\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4714 - categorical_accuracy: 0.3602\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 1.4714 - categorical_accuracy: 0.3602 - val_loss: 1.5963 - val_categorical_accuracy: 0.2664\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4688 - categorical_accuracy: 0.3594\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 1.4688 - categorical_accuracy: 0.3594 - val_loss: 1.5899 - val_categorical_accuracy: 0.2664\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4669 - categorical_accuracy: 0.3584\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.4669 - categorical_accuracy: 0.3584 - val_loss: 1.6021 - val_categorical_accuracy: 0.2749\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4605 - categorical_accuracy: 0.3608\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.4605 - categorical_accuracy: 0.3608 - val_loss: 1.5993 - val_categorical_accuracy: 0.2702\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4578 - categorical_accuracy: 0.3631\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.4578 - categorical_accuracy: 0.3631 - val_loss: 1.5963 - val_categorical_accuracy: 0.2679\n",
      "Epoch 21/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4545 - categorical_accuracy: 0.3706\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 1.4544 - categorical_accuracy: 0.3706 - val_loss: 1.6059 - val_categorical_accuracy: 0.2609\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4587 - categorical_accuracy: 0.3686\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 1.4587 - categorical_accuracy: 0.3686 - val_loss: 1.6009 - val_categorical_accuracy: 0.2648\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4499 - categorical_accuracy: 0.3714\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 1.4499 - categorical_accuracy: 0.3714 - val_loss: 1.6048 - val_categorical_accuracy: 0.2632\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4395 - categorical_accuracy: 0.3748\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 14s 55ms/step - loss: 1.4395 - categorical_accuracy: 0.3748 - val_loss: 1.6062 - val_categorical_accuracy: 0.2671\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4443 - categorical_accuracy: 0.3715\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 13s 52ms/step - loss: 1.4443 - categorical_accuracy: 0.3715 - val_loss: 1.6069 - val_categorical_accuracy: 0.2609\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.4382 - categorical_accuracy: 0.3770\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 1.4382 - categorical_accuracy: 0.3770 - val_loss: 1.6069 - val_categorical_accuracy: 0.2562\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4398 - categorical_accuracy: 0.3733\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 12s 49ms/step - loss: 1.4397 - categorical_accuracy: 0.3733 - val_loss: 1.6005 - val_categorical_accuracy: 0.2656\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4356 - categorical_accuracy: 0.3792\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 1.4356 - categorical_accuracy: 0.3790 - val_loss: 1.6082 - val_categorical_accuracy: 0.2726\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4349 - categorical_accuracy: 0.3776\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 13s 52ms/step - loss: 1.4344 - categorical_accuracy: 0.3778 - val_loss: 1.6227 - val_categorical_accuracy: 0.2679\n",
      "Epoch 30/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.4299 - categorical_accuracy: 0.3831\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28738316893577576.\n",
      "256/256 [==============================] - 13s 52ms/step - loss: 1.4303 - categorical_accuracy: 0.3830 - val_loss: 1.6127 - val_categorical_accuracy: 0.2695\n"
     ]
    }
   ],
   "source": [
    "# Config 3\n",
    "##### FIXED BY USING CUSTOM CALLBACK CLASS #####\n",
    "# word_id_spacy, pos_custom, dep, meta, ADAM optimizer\n",
    "\n",
    "train(model_bilstm_spacydefault,\n",
    "      'wspacyy_posdefault_glove100d_adam',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_DEFAULT, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_spacy, 'pos_input': X_val_pos_DEFAULT, 'dep_input': X_val_dep, 'aux_input': X_val_meta},\n",
    "      optimizer=adam\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### APRIL 11th"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(model_bilstm_dep_meta,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.6529 - categorical_accuracy: 0.2455\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.23364, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 10s 23ms/step - loss: 1.6528 - categorical_accuracy: 0.2451 - val_loss: 1.6216 - val_categorical_accuracy: 0.2336\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6086 - categorical_accuracy: 0.2486\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.6086 - categorical_accuracy: 0.2486 - val_loss: 1.6134 - val_categorical_accuracy: 0.2329\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6029 - categorical_accuracy: 0.2462\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.6029 - categorical_accuracy: 0.2462 - val_loss: 1.6059 - val_categorical_accuracy: 0.2336\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6006 - categorical_accuracy: 0.2491\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.6006 - categorical_accuracy: 0.2491 - val_loss: 1.6069 - val_categorical_accuracy: 0.2305\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6002 - categorical_accuracy: 0.2456\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.6002 - categorical_accuracy: 0.2455 - val_loss: 1.6071 - val_categorical_accuracy: 0.2313\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5996 - categorical_accuracy: 0.2468\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5996 - categorical_accuracy: 0.2470 - val_loss: 1.6058 - val_categorical_accuracy: 0.2336\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5993 - categorical_accuracy: 0.2472\n",
      "Epoch 7: val_categorical_accuracy improved from 0.23364 to 0.23520, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5993 - categorical_accuracy: 0.2472 - val_loss: 1.6033 - val_categorical_accuracy: 0.2352\n",
      "Epoch 8/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5986 - categorical_accuracy: 0.2455\n",
      "Epoch 8: val_categorical_accuracy improved from 0.23520 to 0.23598, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.5985 - categorical_accuracy: 0.2457 - val_loss: 1.6068 - val_categorical_accuracy: 0.2360\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5978 - categorical_accuracy: 0.2500\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.23598\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5978 - categorical_accuracy: 0.2500 - val_loss: 1.6096 - val_categorical_accuracy: 0.2344\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5975 - categorical_accuracy: 0.2504\n",
      "Epoch 10: val_categorical_accuracy improved from 0.23598 to 0.23676, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5975 - categorical_accuracy: 0.2504 - val_loss: 1.6016 - val_categorical_accuracy: 0.2368\n",
      "Epoch 11/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5963 - categorical_accuracy: 0.2476\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.23676\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.5965 - categorical_accuracy: 0.2479 - val_loss: 1.5996 - val_categorical_accuracy: 0.2344\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5938 - categorical_accuracy: 0.2525\n",
      "Epoch 12: val_categorical_accuracy improved from 0.23676 to 0.23910, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5938 - categorical_accuracy: 0.2525 - val_loss: 1.5991 - val_categorical_accuracy: 0.2391\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5907 - categorical_accuracy: 0.2500\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.23910\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5907 - categorical_accuracy: 0.2500 - val_loss: 1.6002 - val_categorical_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5890 - categorical_accuracy: 0.2475\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.23910\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5890 - categorical_accuracy: 0.2475 - val_loss: 1.5936 - val_categorical_accuracy: 0.2391\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5863 - categorical_accuracy: 0.2488\n",
      "Epoch 15: val_categorical_accuracy improved from 0.23910 to 0.24844, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5863 - categorical_accuracy: 0.2488 - val_loss: 1.5932 - val_categorical_accuracy: 0.2484\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5850 - categorical_accuracy: 0.2485\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.24844\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.5850 - categorical_accuracy: 0.2485 - val_loss: 1.5943 - val_categorical_accuracy: 0.2461\n",
      "Epoch 17/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5850 - categorical_accuracy: 0.2551\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.24844\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 1.5849 - categorical_accuracy: 0.2552 - val_loss: 1.5894 - val_categorical_accuracy: 0.2469\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5822 - categorical_accuracy: 0.2563\n",
      "Epoch 18: val_categorical_accuracy improved from 0.24844 to 0.24922, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5822 - categorical_accuracy: 0.2563 - val_loss: 1.5935 - val_categorical_accuracy: 0.2492\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5821 - categorical_accuracy: 0.2598\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.24922\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5821 - categorical_accuracy: 0.2598 - val_loss: 1.5896 - val_categorical_accuracy: 0.2407\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5815 - categorical_accuracy: 0.2602\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.24922\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5815 - categorical_accuracy: 0.2604 - val_loss: 1.5919 - val_categorical_accuracy: 0.2414\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5806 - categorical_accuracy: 0.2538\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.24922\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5806 - categorical_accuracy: 0.2538 - val_loss: 1.5907 - val_categorical_accuracy: 0.2438\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5800 - categorical_accuracy: 0.2586\n",
      "Epoch 22: val_categorical_accuracy improved from 0.24922 to 0.26012, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5800 - categorical_accuracy: 0.2586 - val_loss: 1.5920 - val_categorical_accuracy: 0.2601\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5799 - categorical_accuracy: 0.2579\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.26012\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5798 - categorical_accuracy: 0.2582 - val_loss: 1.5951 - val_categorical_accuracy: 0.2368\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5794 - categorical_accuracy: 0.2587\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.26012\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5794 - categorical_accuracy: 0.2587 - val_loss: 1.5897 - val_categorical_accuracy: 0.2593\n",
      "Epoch 25/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5782 - categorical_accuracy: 0.2623\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.26012\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5783 - categorical_accuracy: 0.2623 - val_loss: 1.5948 - val_categorical_accuracy: 0.2422\n",
      "Epoch 26/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5781 - categorical_accuracy: 0.2562\n",
      "Epoch 26: val_categorical_accuracy improved from 0.26012 to 0.26480, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.5783 - categorical_accuracy: 0.2562 - val_loss: 1.5881 - val_categorical_accuracy: 0.2648\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5768 - categorical_accuracy: 0.2637\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.26480\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5768 - categorical_accuracy: 0.2639 - val_loss: 1.5876 - val_categorical_accuracy: 0.2531\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5767 - categorical_accuracy: 0.2595\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.26480\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5767 - categorical_accuracy: 0.2595 - val_loss: 1.5880 - val_categorical_accuracy: 0.2555\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5762 - categorical_accuracy: 0.2555\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.26480\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5763 - categorical_accuracy: 0.2557 - val_loss: 1.5944 - val_categorical_accuracy: 0.2453\n",
      "Epoch 30/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5756 - categorical_accuracy: 0.2616\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.26480\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5758 - categorical_accuracy: 0.2615 - val_loss: 1.5931 - val_categorical_accuracy: 0.2422\n"
     ]
    }
   ],
   "source": [
    "# Train experiment 3 with dep input and meta input\n",
    "train(model_bilstm_dep_meta,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta}\n",
    "     )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5777 - categorical_accuracy: 0.2690\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.23988, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 15s 36ms/step - loss: 1.5777 - categorical_accuracy: 0.2690 - val_loss: 1.5952 - val_categorical_accuracy: 0.2399\n",
      "Epoch 2/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5764 - categorical_accuracy: 0.2694\n",
      "Epoch 2: val_categorical_accuracy improved from 0.23988 to 0.25078, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5765 - categorical_accuracy: 0.2694 - val_loss: 1.5887 - val_categorical_accuracy: 0.2508\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5751 - categorical_accuracy: 0.2731\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.25078\n",
      "256/256 [==============================] - 8s 29ms/step - loss: 1.5752 - categorical_accuracy: 0.2731 - val_loss: 1.5896 - val_categorical_accuracy: 0.2508\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5728 - categorical_accuracy: 0.2777\n",
      "Epoch 4: val_categorical_accuracy improved from 0.25078 to 0.25312, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5729 - categorical_accuracy: 0.2777 - val_loss: 1.5909 - val_categorical_accuracy: 0.2531\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5714 - categorical_accuracy: 0.2751\n",
      "Epoch 5: val_categorical_accuracy improved from 0.25312 to 0.25779, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5716 - categorical_accuracy: 0.2753 - val_loss: 1.5873 - val_categorical_accuracy: 0.2578\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5700 - categorical_accuracy: 0.2741\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5703 - categorical_accuracy: 0.2739 - val_loss: 1.5890 - val_categorical_accuracy: 0.2508\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5685 - categorical_accuracy: 0.2825\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5684 - categorical_accuracy: 0.2823 - val_loss: 1.5911 - val_categorical_accuracy: 0.2516\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5654 - categorical_accuracy: 0.2791\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5653 - categorical_accuracy: 0.2791 - val_loss: 1.5832 - val_categorical_accuracy: 0.2539\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5618 - categorical_accuracy: 0.2842\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.25779\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5618 - categorical_accuracy: 0.2842 - val_loss: 1.5796 - val_categorical_accuracy: 0.2539\n",
      "Epoch 10/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5593 - categorical_accuracy: 0.2835\n",
      "Epoch 10: val_categorical_accuracy improved from 0.25779 to 0.25857, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5592 - categorical_accuracy: 0.2832 - val_loss: 1.5837 - val_categorical_accuracy: 0.2586\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5578 - categorical_accuracy: 0.2844\n",
      "Epoch 11: val_categorical_accuracy improved from 0.25857 to 0.26090, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5579 - categorical_accuracy: 0.2846 - val_loss: 1.5793 - val_categorical_accuracy: 0.2609\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5556 - categorical_accuracy: 0.2862\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.26090\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5554 - categorical_accuracy: 0.2864 - val_loss: 1.5861 - val_categorical_accuracy: 0.2578\n",
      "Epoch 13/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5540 - categorical_accuracy: 0.2912\n",
      "Epoch 13: val_categorical_accuracy improved from 0.26090 to 0.27181, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5541 - categorical_accuracy: 0.2907 - val_loss: 1.5804 - val_categorical_accuracy: 0.2718\n",
      "Epoch 14/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5519 - categorical_accuracy: 0.2899\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5520 - categorical_accuracy: 0.2898 - val_loss: 1.5894 - val_categorical_accuracy: 0.2578\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5511 - categorical_accuracy: 0.2969\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5512 - categorical_accuracy: 0.2969 - val_loss: 1.5840 - val_categorical_accuracy: 0.2648\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5498 - categorical_accuracy: 0.2970\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5497 - categorical_accuracy: 0.2973 - val_loss: 1.5818 - val_categorical_accuracy: 0.2632\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5485 - categorical_accuracy: 0.2950\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5485 - categorical_accuracy: 0.2950 - val_loss: 1.5798 - val_categorical_accuracy: 0.2671\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5469 - categorical_accuracy: 0.2967\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5465 - categorical_accuracy: 0.2972 - val_loss: 1.5980 - val_categorical_accuracy: 0.2679\n",
      "Epoch 19/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5451 - categorical_accuracy: 0.2976\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 32ms/step - loss: 1.5451 - categorical_accuracy: 0.2972 - val_loss: 1.5761 - val_categorical_accuracy: 0.2664\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5435 - categorical_accuracy: 0.2993\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5433 - categorical_accuracy: 0.2993 - val_loss: 1.5820 - val_categorical_accuracy: 0.2640\n",
      "Epoch 21/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5421 - categorical_accuracy: 0.2979\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5420 - categorical_accuracy: 0.2980 - val_loss: 1.5769 - val_categorical_accuracy: 0.2586\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5400 - categorical_accuracy: 0.3038\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5401 - categorical_accuracy: 0.3039 - val_loss: 1.5782 - val_categorical_accuracy: 0.2695\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5385 - categorical_accuracy: 0.3070\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.27181\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5383 - categorical_accuracy: 0.3069 - val_loss: 1.5778 - val_categorical_accuracy: 0.2656\n",
      "Epoch 24/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5380 - categorical_accuracy: 0.3016\n",
      "Epoch 24: val_categorical_accuracy improved from 0.27181 to 0.27259, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5383 - categorical_accuracy: 0.3011 - val_loss: 1.5747 - val_categorical_accuracy: 0.2726\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5352 - categorical_accuracy: 0.3063\n",
      "Epoch 25: val_categorical_accuracy improved from 0.27259 to 0.27570, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5358 - categorical_accuracy: 0.3060 - val_loss: 1.5779 - val_categorical_accuracy: 0.2757\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5320 - categorical_accuracy: 0.3067\n",
      "Epoch 26: val_categorical_accuracy improved from 0.27570 to 0.28193, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5324 - categorical_accuracy: 0.3067 - val_loss: 1.5765 - val_categorical_accuracy: 0.2819\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5330 - categorical_accuracy: 0.3116\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.28193\n",
      "256/256 [==============================] - 8s 32ms/step - loss: 1.5329 - categorical_accuracy: 0.3117 - val_loss: 1.5835 - val_categorical_accuracy: 0.2617\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5308 - categorical_accuracy: 0.3121\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.28193\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5312 - categorical_accuracy: 0.3117 - val_loss: 1.5789 - val_categorical_accuracy: 0.2726\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5295 - categorical_accuracy: 0.3125\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.28193\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.5292 - categorical_accuracy: 0.3126 - val_loss: 1.5799 - val_categorical_accuracy: 0.2734\n",
      "Epoch 30/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5285 - categorical_accuracy: 0.3144\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28193\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5286 - categorical_accuracy: 0.3143 - val_loss: 1.5756 - val_categorical_accuracy: 0.2757\n"
     ]
    }
   ],
   "source": [
    "# dep_dict + 1\n",
    "train(model_bilstm_dep_meta,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6552 - categorical_accuracy: 0.2353\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.23832, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 14s 32ms/step - loss: 1.6551 - categorical_accuracy: 0.2353 - val_loss: 1.6208 - val_categorical_accuracy: 0.2383\n",
      "Epoch 2/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6060 - categorical_accuracy: 0.2513\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.23832\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.6059 - categorical_accuracy: 0.2517 - val_loss: 1.6102 - val_categorical_accuracy: 0.2313\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5967 - categorical_accuracy: 0.2555\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.23832\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5968 - categorical_accuracy: 0.2557 - val_loss: 1.6009 - val_categorical_accuracy: 0.2383\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5919 - categorical_accuracy: 0.2583\n",
      "Epoch 4: val_categorical_accuracy improved from 0.23832 to 0.23988, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5919 - categorical_accuracy: 0.2583 - val_loss: 1.5953 - val_categorical_accuracy: 0.2399\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5886 - categorical_accuracy: 0.2610\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.23988\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5884 - categorical_accuracy: 0.2611 - val_loss: 1.5999 - val_categorical_accuracy: 0.2298\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5862 - categorical_accuracy: 0.2582\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.23988\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5862 - categorical_accuracy: 0.2582 - val_loss: 1.5949 - val_categorical_accuracy: 0.2383\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5836 - categorical_accuracy: 0.2632\n",
      "Epoch 7: val_categorical_accuracy improved from 0.23988 to 0.25623, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5836 - categorical_accuracy: 0.2632 - val_loss: 1.5899 - val_categorical_accuracy: 0.2562\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5809 - categorical_accuracy: 0.2650\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.25623\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5811 - categorical_accuracy: 0.2648 - val_loss: 1.5918 - val_categorical_accuracy: 0.2383\n",
      "Epoch 9/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5797 - categorical_accuracy: 0.2690\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.25623\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5796 - categorical_accuracy: 0.2688 - val_loss: 1.5911 - val_categorical_accuracy: 0.2344\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5779 - categorical_accuracy: 0.2634\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.25623\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5779 - categorical_accuracy: 0.2634 - val_loss: 1.5919 - val_categorical_accuracy: 0.2492\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5762 - categorical_accuracy: 0.2693\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.25623\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5765 - categorical_accuracy: 0.2691 - val_loss: 1.5874 - val_categorical_accuracy: 0.2407\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5736 - categorical_accuracy: 0.2758\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.25623\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5736 - categorical_accuracy: 0.2758 - val_loss: 1.5882 - val_categorical_accuracy: 0.2547\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5716 - categorical_accuracy: 0.2774\n",
      "Epoch 13: val_categorical_accuracy improved from 0.25623 to 0.26012, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5716 - categorical_accuracy: 0.2774 - val_loss: 1.5834 - val_categorical_accuracy: 0.2601\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5679 - categorical_accuracy: 0.2761\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.26012\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5679 - categorical_accuracy: 0.2761 - val_loss: 1.5779 - val_categorical_accuracy: 0.2562\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5657 - categorical_accuracy: 0.2799\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.26012\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5655 - categorical_accuracy: 0.2799 - val_loss: 1.5811 - val_categorical_accuracy: 0.2586\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5623 - categorical_accuracy: 0.2832\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.26012\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5622 - categorical_accuracy: 0.2836 - val_loss: 1.5809 - val_categorical_accuracy: 0.2562\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5605 - categorical_accuracy: 0.2899\n",
      "Epoch 17: val_categorical_accuracy improved from 0.26012 to 0.26791, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5605 - categorical_accuracy: 0.2899 - val_loss: 1.5765 - val_categorical_accuracy: 0.2679\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5589 - categorical_accuracy: 0.2852\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.26791\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5588 - categorical_accuracy: 0.2854 - val_loss: 1.5778 - val_categorical_accuracy: 0.2679\n",
      "Epoch 19/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5564 - categorical_accuracy: 0.2914\n",
      "Epoch 19: val_categorical_accuracy improved from 0.26791 to 0.27804, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5564 - categorical_accuracy: 0.2912 - val_loss: 1.5796 - val_categorical_accuracy: 0.2780\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5548 - categorical_accuracy: 0.2938\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5547 - categorical_accuracy: 0.2940 - val_loss: 1.5832 - val_categorical_accuracy: 0.2640\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5533 - categorical_accuracy: 0.2893\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.5533 - categorical_accuracy: 0.2893 - val_loss: 1.5784 - val_categorical_accuracy: 0.2648\n",
      "Epoch 22/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5501 - categorical_accuracy: 0.2949\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 1.5500 - categorical_accuracy: 0.2947 - val_loss: 1.5794 - val_categorical_accuracy: 0.2718\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5501 - categorical_accuracy: 0.2942\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5499 - categorical_accuracy: 0.2943 - val_loss: 1.5829 - val_categorical_accuracy: 0.2671\n",
      "Epoch 24/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5484 - categorical_accuracy: 0.2963\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5485 - categorical_accuracy: 0.2964 - val_loss: 1.5871 - val_categorical_accuracy: 0.2617\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5460 - categorical_accuracy: 0.2963\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5459 - categorical_accuracy: 0.2968 - val_loss: 1.5763 - val_categorical_accuracy: 0.2656\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5448 - categorical_accuracy: 0.3002\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5448 - categorical_accuracy: 0.3005 - val_loss: 1.5796 - val_categorical_accuracy: 0.2617\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5426 - categorical_accuracy: 0.3020\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5427 - categorical_accuracy: 0.3019 - val_loss: 1.5835 - val_categorical_accuracy: 0.2780\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5404 - categorical_accuracy: 0.3027\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.27804\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5405 - categorical_accuracy: 0.3029 - val_loss: 1.5738 - val_categorical_accuracy: 0.2734\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5386 - categorical_accuracy: 0.3075\n",
      "Epoch 29: val_categorical_accuracy improved from 0.27804 to 0.28972, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 1.5387 - categorical_accuracy: 0.3072 - val_loss: 1.5741 - val_categorical_accuracy: 0.2897\n",
      "Epoch 30/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5378 - categorical_accuracy: 0.3046\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.28972\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.5382 - categorical_accuracy: 0.3043 - val_loss: 1.5710 - val_categorical_accuracy: 0.2850\n"
     ]
    }
   ],
   "source": [
    "# Updated shape of model 3:42am\n",
    "train(model_bilstm_dep_meta,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom, 'dep_input': X_train_dep, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom, 'dep_input': X_val_dep, 'aux_input': X_val_meta}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### APRIL 9th\n",
    "\n",
    "num_steps set to 30\n",
    "pos dict + 1\n",
    "meta processed by hardcoding missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6540 - categorical_accuracy: 0.2468\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.22430, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 14s 25ms/step - loss: 1.6539 - categorical_accuracy: 0.2471 - val_loss: 1.6265 - val_categorical_accuracy: 0.2243\n",
      "Epoch 2/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.6086 - categorical_accuracy: 0.2495\n",
      "Epoch 2: val_categorical_accuracy improved from 0.22430 to 0.23364, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.6088 - categorical_accuracy: 0.2488 - val_loss: 1.6140 - val_categorical_accuracy: 0.2336\n",
      "Epoch 3/30\n",
      "253/256 [============================>.] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.2481\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.6028 - categorical_accuracy: 0.2482 - val_loss: 1.6084 - val_categorical_accuracy: 0.2274\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6011 - categorical_accuracy: 0.2477\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.6011 - categorical_accuracy: 0.2475 - val_loss: 1.6059 - val_categorical_accuracy: 0.2290\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6005 - categorical_accuracy: 0.2491\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.6005 - categorical_accuracy: 0.2491 - val_loss: 1.6098 - val_categorical_accuracy: 0.2274\n",
      "Epoch 6/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.6001 - categorical_accuracy: 0.2482\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.6001 - categorical_accuracy: 0.2485 - val_loss: 1.6070 - val_categorical_accuracy: 0.2321\n",
      "Epoch 7/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5990 - categorical_accuracy: 0.2476\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.5990 - categorical_accuracy: 0.2476 - val_loss: 1.6071 - val_categorical_accuracy: 0.2274\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5983 - categorical_accuracy: 0.2498\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.5983 - categorical_accuracy: 0.2498 - val_loss: 1.6102 - val_categorical_accuracy: 0.2290\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5973 - categorical_accuracy: 0.2512\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5973 - categorical_accuracy: 0.2512 - val_loss: 1.6095 - val_categorical_accuracy: 0.2266\n",
      "Epoch 10/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5967 - categorical_accuracy: 0.2522\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5966 - categorical_accuracy: 0.2521 - val_loss: 1.6035 - val_categorical_accuracy: 0.2305\n",
      "Epoch 11/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5954 - categorical_accuracy: 0.2517\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5954 - categorical_accuracy: 0.2516 - val_loss: 1.5987 - val_categorical_accuracy: 0.2290\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5935 - categorical_accuracy: 0.2500\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5935 - categorical_accuracy: 0.2500 - val_loss: 1.5956 - val_categorical_accuracy: 0.2305\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5909 - categorical_accuracy: 0.2541\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5909 - categorical_accuracy: 0.2541 - val_loss: 1.5965 - val_categorical_accuracy: 0.2298\n",
      "Epoch 14/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5879 - categorical_accuracy: 0.2588\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.23364\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.5883 - categorical_accuracy: 0.2580 - val_loss: 1.6039 - val_categorical_accuracy: 0.2329\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5857 - categorical_accuracy: 0.2545\n",
      "Epoch 15: val_categorical_accuracy improved from 0.23364 to 0.24065, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.5857 - categorical_accuracy: 0.2545 - val_loss: 1.5918 - val_categorical_accuracy: 0.2407\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5863 - categorical_accuracy: 0.2544\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.24065\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5863 - categorical_accuracy: 0.2544 - val_loss: 1.5955 - val_categorical_accuracy: 0.2352\n",
      "Epoch 17/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5842 - categorical_accuracy: 0.2578\n",
      "Epoch 17: val_categorical_accuracy improved from 0.24065 to 0.24221, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5842 - categorical_accuracy: 0.2579 - val_loss: 1.5996 - val_categorical_accuracy: 0.2422\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5827 - categorical_accuracy: 0.2573\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.24221\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5827 - categorical_accuracy: 0.2573 - val_loss: 1.5911 - val_categorical_accuracy: 0.2399\n",
      "Epoch 19/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5811 - categorical_accuracy: 0.2596\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.24221\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5815 - categorical_accuracy: 0.2591 - val_loss: 1.5957 - val_categorical_accuracy: 0.2360\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5819 - categorical_accuracy: 0.2570\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.24221\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5819 - categorical_accuracy: 0.2570 - val_loss: 1.5975 - val_categorical_accuracy: 0.2336\n",
      "Epoch 21/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5801 - categorical_accuracy: 0.2590\n",
      "Epoch 21: val_categorical_accuracy improved from 0.24221 to 0.25312, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5799 - categorical_accuracy: 0.2590 - val_loss: 1.5889 - val_categorical_accuracy: 0.2531\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5805 - categorical_accuracy: 0.2583\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.25312\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 1.5803 - categorical_accuracy: 0.2586 - val_loss: 1.5939 - val_categorical_accuracy: 0.2407\n",
      "Epoch 23/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5791 - categorical_accuracy: 0.2614\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.25312\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5789 - categorical_accuracy: 0.2617 - val_loss: 1.5935 - val_categorical_accuracy: 0.2375\n",
      "Epoch 24/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5784 - categorical_accuracy: 0.2640\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.25312\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5783 - categorical_accuracy: 0.2640 - val_loss: 1.5954 - val_categorical_accuracy: 0.2407\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5753 - categorical_accuracy: 0.2621\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.25312\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5753 - categorical_accuracy: 0.2621 - val_loss: 1.5993 - val_categorical_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5760 - categorical_accuracy: 0.2638\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.25312\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5757 - categorical_accuracy: 0.2640 - val_loss: 1.6045 - val_categorical_accuracy: 0.2422\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5751 - categorical_accuracy: 0.2626\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.25312\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5751 - categorical_accuracy: 0.2628 - val_loss: 1.5869 - val_categorical_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5745 - categorical_accuracy: 0.2624\n",
      "Epoch 28: val_categorical_accuracy improved from 0.25312 to 0.27726, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5745 - categorical_accuracy: 0.2624 - val_loss: 1.5798 - val_categorical_accuracy: 0.2773\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5740 - categorical_accuracy: 0.2641\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.27726\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5740 - categorical_accuracy: 0.2641 - val_loss: 1.5828 - val_categorical_accuracy: 0.2469\n",
      "Epoch 30/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5711 - categorical_accuracy: 0.2734\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.27726\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5715 - categorical_accuracy: 0.2726 - val_loss: 1.5795 - val_categorical_accuracy: 0.2640\n"
     ]
    }
   ],
   "source": [
    "train(model_bilstm_pos,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5711 - categorical_accuracy: 0.2720\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.25234, saving model to bilstm_meta_weights_best.hdf5\n",
      "256/256 [==============================] - 10s 22ms/step - loss: 1.5709 - categorical_accuracy: 0.2715 - val_loss: 1.5923 - val_categorical_accuracy: 0.2523\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5696 - categorical_accuracy: 0.2771\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.25234\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5696 - categorical_accuracy: 0.2771 - val_loss: 1.5838 - val_categorical_accuracy: 0.2368\n",
      "Epoch 3/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5701 - categorical_accuracy: 0.2691\n",
      "Epoch 3: val_categorical_accuracy improved from 0.25234 to 0.26168, saving model to bilstm_meta_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5702 - categorical_accuracy: 0.2687 - val_loss: 1.5801 - val_categorical_accuracy: 0.2617\n",
      "Epoch 4/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5677 - categorical_accuracy: 0.2730\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.26168\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5672 - categorical_accuracy: 0.2736 - val_loss: 1.5851 - val_categorical_accuracy: 0.2570\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5684 - categorical_accuracy: 0.2753\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.26168\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5684 - categorical_accuracy: 0.2753 - val_loss: 1.5890 - val_categorical_accuracy: 0.2414\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5677 - categorical_accuracy: 0.2705\n",
      "Epoch 6: val_categorical_accuracy improved from 0.26168 to 0.26402, saving model to bilstm_meta_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5677 - categorical_accuracy: 0.2705 - val_loss: 1.5777 - val_categorical_accuracy: 0.2640\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5667 - categorical_accuracy: 0.2744\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.26402\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5670 - categorical_accuracy: 0.2741 - val_loss: 1.5836 - val_categorical_accuracy: 0.2492\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5671 - categorical_accuracy: 0.2746\n",
      "Epoch 8: val_categorical_accuracy improved from 0.26402 to 0.27103, saving model to bilstm_meta_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5671 - categorical_accuracy: 0.2746 - val_loss: 1.5783 - val_categorical_accuracy: 0.2710\n",
      "Epoch 9/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5659 - categorical_accuracy: 0.2752\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5663 - categorical_accuracy: 0.2749 - val_loss: 1.5799 - val_categorical_accuracy: 0.2562\n",
      "Epoch 10/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5654 - categorical_accuracy: 0.2806\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5656 - categorical_accuracy: 0.2811 - val_loss: 1.5825 - val_categorical_accuracy: 0.2664\n",
      "Epoch 11/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5657 - categorical_accuracy: 0.2727\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5657 - categorical_accuracy: 0.2726 - val_loss: 1.5811 - val_categorical_accuracy: 0.2640\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5651 - categorical_accuracy: 0.2796\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5651 - categorical_accuracy: 0.2796 - val_loss: 1.5936 - val_categorical_accuracy: 0.2484\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5616 - categorical_accuracy: 0.2818\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5616 - categorical_accuracy: 0.2818 - val_loss: 1.5797 - val_categorical_accuracy: 0.2632\n",
      "Epoch 14/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5631 - categorical_accuracy: 0.2737\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5629 - categorical_accuracy: 0.2736 - val_loss: 1.5833 - val_categorical_accuracy: 0.2562\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5618 - categorical_accuracy: 0.2816\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5618 - categorical_accuracy: 0.2816 - val_loss: 1.5808 - val_categorical_accuracy: 0.2664\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5597 - categorical_accuracy: 0.2836\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5597 - categorical_accuracy: 0.2836 - val_loss: 1.5853 - val_categorical_accuracy: 0.2570\n",
      "Epoch 17/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5593 - categorical_accuracy: 0.2802\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5595 - categorical_accuracy: 0.2803 - val_loss: 1.5965 - val_categorical_accuracy: 0.2305\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5584 - categorical_accuracy: 0.2851\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5584 - categorical_accuracy: 0.2851 - val_loss: 1.5987 - val_categorical_accuracy: 0.2531\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5596 - categorical_accuracy: 0.2840\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5596 - categorical_accuracy: 0.2840 - val_loss: 1.5824 - val_categorical_accuracy: 0.2664\n",
      "Epoch 20/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5582 - categorical_accuracy: 0.2884\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5581 - categorical_accuracy: 0.2885 - val_loss: 1.5851 - val_categorical_accuracy: 0.2492\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5569 - categorical_accuracy: 0.2834\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5569 - categorical_accuracy: 0.2834 - val_loss: 1.5839 - val_categorical_accuracy: 0.2593\n",
      "Epoch 22/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5577 - categorical_accuracy: 0.2833\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5582 - categorical_accuracy: 0.2824 - val_loss: 1.5812 - val_categorical_accuracy: 0.2461\n",
      "Epoch 23/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5566 - categorical_accuracy: 0.2807\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5565 - categorical_accuracy: 0.2812 - val_loss: 1.5852 - val_categorical_accuracy: 0.2484\n",
      "Epoch 24/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5550 - categorical_accuracy: 0.2886\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5548 - categorical_accuracy: 0.2891 - val_loss: 1.5880 - val_categorical_accuracy: 0.2601\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5570 - categorical_accuracy: 0.2846\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5566 - categorical_accuracy: 0.2852 - val_loss: 1.5835 - val_categorical_accuracy: 0.2399\n",
      "Epoch 26/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5530 - categorical_accuracy: 0.2922\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5531 - categorical_accuracy: 0.2920 - val_loss: 1.5964 - val_categorical_accuracy: 0.2414\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5560 - categorical_accuracy: 0.2925\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5560 - categorical_accuracy: 0.2925 - val_loss: 1.5835 - val_categorical_accuracy: 0.2586\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5538 - categorical_accuracy: 0.2869\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5537 - categorical_accuracy: 0.2871 - val_loss: 1.5802 - val_categorical_accuracy: 0.2601\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5537 - categorical_accuracy: 0.2893\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5536 - categorical_accuracy: 0.2891 - val_loss: 1.5786 - val_categorical_accuracy: 0.2562\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5504 - categorical_accuracy: 0.2976\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.27103\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 1.5504 - categorical_accuracy: 0.2976 - val_loss: 1.5869 - val_categorical_accuracy: 0.2578\n"
     ]
    }
   ],
   "source": [
    "train(model_bilstm_meta,\n",
    "      'bilstm_meta',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom, 'aux_input': X_train_meta},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom, 'aux_input': X_val_meta}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6631 - categorical_accuracy: 0.2427\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.22508, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 11s 27ms/step - loss: 1.6629 - categorical_accuracy: 0.2428 - val_loss: 1.6282 - val_categorical_accuracy: 0.2251\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6120 - categorical_accuracy: 0.2490\n",
      "Epoch 2: val_categorical_accuracy improved from 0.22508 to 0.22897, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.6120 - categorical_accuracy: 0.2490 - val_loss: 1.6152 - val_categorical_accuracy: 0.2290\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6046 - categorical_accuracy: 0.2462\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.22897\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.6046 - categorical_accuracy: 0.2462 - val_loss: 1.6077 - val_categorical_accuracy: 0.2282\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6022 - categorical_accuracy: 0.2507\n",
      "Epoch 4: val_categorical_accuracy improved from 0.22897 to 0.23442, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.6023 - categorical_accuracy: 0.2503 - val_loss: 1.6115 - val_categorical_accuracy: 0.2344\n",
      "Epoch 5/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.6013 - categorical_accuracy: 0.2502\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.23442\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.6009 - categorical_accuracy: 0.2510 - val_loss: 1.6122 - val_categorical_accuracy: 0.2243\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5999 - categorical_accuracy: 0.2512\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.23442\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.6000 - categorical_accuracy: 0.2510 - val_loss: 1.6067 - val_categorical_accuracy: 0.2313\n",
      "Epoch 7/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5997 - categorical_accuracy: 0.2457\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.23442\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 1.5998 - categorical_accuracy: 0.2457 - val_loss: 1.6096 - val_categorical_accuracy: 0.2321\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5986 - categorical_accuracy: 0.2514\n",
      "Epoch 8: val_categorical_accuracy improved from 0.23442 to 0.23754, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5986 - categorical_accuracy: 0.2514 - val_loss: 1.6131 - val_categorical_accuracy: 0.2375\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5986 - categorical_accuracy: 0.2462\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5986 - categorical_accuracy: 0.2462 - val_loss: 1.6054 - val_categorical_accuracy: 0.2266\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5989 - categorical_accuracy: 0.2513\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5989 - categorical_accuracy: 0.2513 - val_loss: 1.6035 - val_categorical_accuracy: 0.2352\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5980 - categorical_accuracy: 0.2512\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5980 - categorical_accuracy: 0.2512 - val_loss: 1.6075 - val_categorical_accuracy: 0.2344\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5981 - categorical_accuracy: 0.2536\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5981 - categorical_accuracy: 0.2536 - val_loss: 1.6028 - val_categorical_accuracy: 0.2329\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5981 - categorical_accuracy: 0.2517\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5981 - categorical_accuracy: 0.2517 - val_loss: 1.6031 - val_categorical_accuracy: 0.2368\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5971 - categorical_accuracy: 0.2511\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5971 - categorical_accuracy: 0.2511 - val_loss: 1.6010 - val_categorical_accuracy: 0.2321\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5970 - categorical_accuracy: 0.2517\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5970 - categorical_accuracy: 0.2517 - val_loss: 1.6094 - val_categorical_accuracy: 0.2274\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5968 - categorical_accuracy: 0.2519\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5968 - categorical_accuracy: 0.2519 - val_loss: 1.6048 - val_categorical_accuracy: 0.2344\n",
      "Epoch 17/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5968 - categorical_accuracy: 0.2520\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5969 - categorical_accuracy: 0.2521 - val_loss: 1.6033 - val_categorical_accuracy: 0.2344\n",
      "Epoch 18/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5964 - categorical_accuracy: 0.2502\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5962 - categorical_accuracy: 0.2508 - val_loss: 1.6043 - val_categorical_accuracy: 0.2352\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5964 - categorical_accuracy: 0.2536\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.23754\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5964 - categorical_accuracy: 0.2536 - val_loss: 1.6016 - val_categorical_accuracy: 0.2360\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5955 - categorical_accuracy: 0.2540\n",
      "Epoch 20: val_categorical_accuracy improved from 0.23754 to 0.24143, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5955 - categorical_accuracy: 0.2540 - val_loss: 1.6002 - val_categorical_accuracy: 0.2414\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5955 - categorical_accuracy: 0.2547\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5955 - categorical_accuracy: 0.2547 - val_loss: 1.6026 - val_categorical_accuracy: 0.2344\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5949 - categorical_accuracy: 0.2498\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5949 - categorical_accuracy: 0.2498 - val_loss: 1.5987 - val_categorical_accuracy: 0.2336\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.5951 - categorical_accuracy: 0.2540\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.5951 - categorical_accuracy: 0.2541 - val_loss: 1.6059 - val_categorical_accuracy: 0.2399\n",
      "Epoch 24/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5949 - categorical_accuracy: 0.2530\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5950 - categorical_accuracy: 0.2529 - val_loss: 1.6032 - val_categorical_accuracy: 0.2282\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5948 - categorical_accuracy: 0.2535\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5948 - categorical_accuracy: 0.2535 - val_loss: 1.5960 - val_categorical_accuracy: 0.2352\n",
      "Epoch 26/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5940 - categorical_accuracy: 0.2535\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.5941 - categorical_accuracy: 0.2537 - val_loss: 1.6001 - val_categorical_accuracy: 0.2313\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5933 - categorical_accuracy: 0.2558\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5933 - categorical_accuracy: 0.2558 - val_loss: 1.5967 - val_categorical_accuracy: 0.2321\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5921 - categorical_accuracy: 0.2568\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.24143\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5921 - categorical_accuracy: 0.2568 - val_loss: 1.6003 - val_categorical_accuracy: 0.2344\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.5913 - categorical_accuracy: 0.2562\n",
      "Epoch 29: val_categorical_accuracy improved from 0.24143 to 0.24221, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 1.5913 - categorical_accuracy: 0.2562 - val_loss: 1.5950 - val_categorical_accuracy: 0.2422\n",
      "Epoch 30/30\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5901 - categorical_accuracy: 0.2504\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.24221\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 1.5901 - categorical_accuracy: 0.2501 - val_loss: 1.5905 - val_categorical_accuracy: 0.2422\n"
     ]
    }
   ],
   "source": [
    "train(model_bilstm_pos,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_DEFAULT},\n",
    "      {'main_input': X_val_spacy, 'pos_input': X_val_pos_DEFAULT}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# APRIL 8th EXPERIMENTS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6486 - categorical_accuracy: 0.2455\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.22274, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 13s 32ms/step - loss: 1.6485 - categorical_accuracy: 0.2452 - val_loss: 1.6248 - val_categorical_accuracy: 0.2227\n",
      "Epoch 2/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6100 - categorical_accuracy: 0.2455\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6101 - categorical_accuracy: 0.2452 - val_loss: 1.6167 - val_categorical_accuracy: 0.2220\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6063 - categorical_accuracy: 0.2454\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6062 - categorical_accuracy: 0.2455 - val_loss: 1.6155 - val_categorical_accuracy: 0.2204\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6053 - categorical_accuracy: 0.2455\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6052 - categorical_accuracy: 0.2456 - val_loss: 1.6216 - val_categorical_accuracy: 0.2220\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6042 - categorical_accuracy: 0.2453\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 9s 33ms/step - loss: 1.6042 - categorical_accuracy: 0.2451 - val_loss: 1.6105 - val_categorical_accuracy: 0.2204\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6040 - categorical_accuracy: 0.2457\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 33ms/step - loss: 1.6040 - categorical_accuracy: 0.2457 - val_loss: 1.6111 - val_categorical_accuracy: 0.2220\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2421\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6031 - categorical_accuracy: 0.2420 - val_loss: 1.6142 - val_categorical_accuracy: 0.2220\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6036 - categorical_accuracy: 0.2448\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6038 - categorical_accuracy: 0.2445 - val_loss: 1.6176 - val_categorical_accuracy: 0.2227\n",
      "Epoch 9/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2424\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6031 - categorical_accuracy: 0.2424 - val_loss: 1.6116 - val_categorical_accuracy: 0.2220\n",
      "Epoch 10/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6029 - categorical_accuracy: 0.2450\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6029 - categorical_accuracy: 0.2453 - val_loss: 1.6186 - val_categorical_accuracy: 0.1931\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6030 - categorical_accuracy: 0.2413\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6030 - categorical_accuracy: 0.2412 - val_loss: 1.6145 - val_categorical_accuracy: 0.2220\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2455\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6032 - categorical_accuracy: 0.2453 - val_loss: 1.6112 - val_categorical_accuracy: 0.2212\n",
      "Epoch 13/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6032 - categorical_accuracy: 0.2437\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6032 - categorical_accuracy: 0.2435 - val_loss: 1.6109 - val_categorical_accuracy: 0.2220\n",
      "Epoch 14/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.2421\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.6029 - categorical_accuracy: 0.2420 - val_loss: 1.6158 - val_categorical_accuracy: 0.2220\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.2448\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6025 - categorical_accuracy: 0.2449 - val_loss: 1.6200 - val_categorical_accuracy: 0.2220\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.2445\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 29ms/step - loss: 1.6029 - categorical_accuracy: 0.2442 - val_loss: 1.6155 - val_categorical_accuracy: 0.2212\n",
      "Epoch 17/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.2437\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6026 - categorical_accuracy: 0.2439 - val_loss: 1.6164 - val_categorical_accuracy: 0.2220\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2448\n",
      "Epoch 18: val_categorical_accuracy improved from 0.22274 to 0.22352, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 29ms/step - loss: 1.6032 - categorical_accuracy: 0.2444 - val_loss: 1.6090 - val_categorical_accuracy: 0.2235\n",
      "Epoch 19/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.2438\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6026 - categorical_accuracy: 0.2438 - val_loss: 1.6143 - val_categorical_accuracy: 0.2227\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6021 - categorical_accuracy: 0.2440\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6022 - categorical_accuracy: 0.2438 - val_loss: 1.6101 - val_categorical_accuracy: 0.2227\n",
      "Epoch 21/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6025 - categorical_accuracy: 0.2450\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6024 - categorical_accuracy: 0.2452 - val_loss: 1.6114 - val_categorical_accuracy: 0.2227\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.2442\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6028 - categorical_accuracy: 0.2443 - val_loss: 1.6096 - val_categorical_accuracy: 0.2235\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6025 - categorical_accuracy: 0.2439\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.6022 - categorical_accuracy: 0.2443 - val_loss: 1.6181 - val_categorical_accuracy: 0.2220\n",
      "Epoch 24/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6026 - categorical_accuracy: 0.2448\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6025 - categorical_accuracy: 0.2450 - val_loss: 1.6135 - val_categorical_accuracy: 0.2220\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6023 - categorical_accuracy: 0.2440\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6024 - categorical_accuracy: 0.2438 - val_loss: 1.6115 - val_categorical_accuracy: 0.2220\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6026 - categorical_accuracy: 0.2463\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6026 - categorical_accuracy: 0.2460 - val_loss: 1.6100 - val_categorical_accuracy: 0.2227\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6018 - categorical_accuracy: 0.2451\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6017 - categorical_accuracy: 0.2450 - val_loss: 1.6154 - val_categorical_accuracy: 0.1931\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6021 - categorical_accuracy: 0.2442\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6022 - categorical_accuracy: 0.2438 - val_loss: 1.6094 - val_categorical_accuracy: 0.2227\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6015 - categorical_accuracy: 0.2446\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.6013 - categorical_accuracy: 0.2448 - val_loss: 1.6119 - val_categorical_accuracy: 0.2227\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6012 - categorical_accuracy: 0.2484\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6012 - categorical_accuracy: 0.2484 - val_loss: 1.6109 - val_categorical_accuracy: 0.2227\n"
     ]
    }
   ],
   "source": [
    "train(model_bilstm_pos,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"pos_input\". You passed a data dictionary with keys ['main_input']. Expected the following keys: ['main_input', 'pos_input']\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[79], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m### TEST 4: remove pos from equation completely\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m     \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[65], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, train_inputs, val_inputs)\u001B[0m\n\u001B[0;32m     10\u001B[0m compile_model(model)\n\u001B[0;32m     11\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m create_callbacks(name)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filev7lylc5j.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"pos_input\". You passed a data dictionary with keys ['main_input']. Expected the following keys: ['main_input', 'pos_input']\n"
     ]
    }
   ],
   "source": [
    "### TEST 4: remove pos from equation completely\n",
    "train(model_bilstm_pos,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom},\n",
    "      {'main_input': X_val_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/embedding_14/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\3575741395.py\", line 2, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_14/embedding_lookup'\nindices[3,1] = 15 is not in [0, 15)\n\t [[{{node model_1/embedding_14/embedding_lookup}}]] [Op:__inference_train_function_17062]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m### TEST 3: attempting to fix test 2:\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_pos_custom\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m     \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[65], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, train_inputs, val_inputs)\u001B[0m\n\u001B[0;32m     10\u001B[0m compile_model(model)\n\u001B[0;32m     11\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m create_callbacks(name)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'model_1/embedding_14/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\3575741395.py\", line 2, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_14/embedding_lookup'\nindices[3,1] = 15 is not in [0, 15)\n\t [[{{node model_1/embedding_14/embedding_lookup}}]] [Op:__inference_train_function_17062]"
     ]
    }
   ],
   "source": [
    "### TEST 3: attempting to fix test 2:\n",
    "train(model_bilstm_pos,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\2186106441.py\", line 1, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding_2/embedding_lookup'\nindices[0,3] = 14 is not in [0, 14)\n\t [[{{node model/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_5950]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_pos_custom\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m     \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[65], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, train_inputs, val_inputs)\u001B[0m\n\u001B[0;32m     10\u001B[0m compile_model(model)\n\u001B[0;32m     11\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m create_callbacks(name)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'model/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\2186106441.py\", line 1, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding_2/embedding_lookup'\nindices[0,3] = 14 is not in [0, 14)\n\t [[{{node model/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_5950]"
     ]
    }
   ],
   "source": [
    "## TEST 2: ERROR = size of pos embeddings\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 10240, 10240, 1284, 1284\n  y sizes: 10240\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m\t      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[15], line 54\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, *args, **kwargs)\u001B[0m\n\u001B[0;32m     51\u001B[0m inputs \u001B[38;5;241m=\u001B[39m merge_dicts(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     52\u001B[0m validation_inputs \u001B[38;5;241m=\u001B[39m merge_dicts(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 54\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidation_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001B[0m, in \u001B[0;36m_check_data_cardinality\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m   1844\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m sizes: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1845\u001B[0m         label,\n\u001B[0;32m   1846\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m   1847\u001B[0m             \u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(single_data)\n\u001B[0;32m   1848\u001B[0m         ),\n\u001B[0;32m   1849\u001B[0m     )\n\u001B[0;32m   1850\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMake sure all arrays contain the same number of samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1851\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[1;31mValueError\u001B[0m: Data cardinality is ambiguous:\n  x sizes: 10240, 10240, 1284, 1284\n  y sizes: 10240\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      validation_data=(\n",
    "\t      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_custom,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 2\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_custom},\n",
    "      validation_data=(\n",
    "\t      {'main_input': X_val_spacy, 'pos_input': X_val_pos_custom},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_custom,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 3\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_DEFAULT},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_custom, 'pos_input': X_val_pos_DEFAULT},\n",
    "      )\n",
    "      )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 4\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_DEFAULT},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_spacy, 'pos_input': X_val_pos_DEFAULT},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CONFIG 5\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'aux_input': X_train_meta},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_custom, 'pos_input': X_val_pos_custom},\n",
    "          {'aux_input': X_val_meta},\n",
    "      )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m (fw, tb) \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbilstm\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      2\u001B[0m                     X_test_custom,\n\u001B[0;32m      3\u001B[0m                     X_test_pos_custom,\n\u001B[0;32m      4\u001B[0m                     X_test_meta,\n\u001B[0;32m      5\u001B[0m                     \u001B[38;5;66;03m# X_test_dep,\u001B[39;00m\n\u001B[0;32m      6\u001B[0m                     )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_custom,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### CONFIG 6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 6\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_custom},\n",
    "      {'aux_input': X_train_meta}\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_custom,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CONFIG 7\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 7\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_DEFAULT},\n",
    "      {'aux_input': X_train_meta},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_custom, 'pos_input': X_val_pos_DEFAULT},\n",
    "          {'aux_input': X_val_meta},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 8\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_DEFAULT},\n",
    "      {'aux_input': X_train_meta},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_spacy, 'pos_input': X_val_pos_DEFAULT},\n",
    "          {'aux_input': X_val_meta},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
