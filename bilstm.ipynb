{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "import keras.utils\n",
    "import spacy\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense,Flatten,LSTM,Conv1D,GlobalMaxPool1D,Dropout,Bidirectional\n",
    "from keras.utils import pad_sequences\n",
    "from keras_preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from csv to pandas dataframe\n",
    "# train_data = pd.read_csv('processed_train_data.tsv', sep='\\t', index_col=0)\n",
    "# val_data = pd.read_csv('processed_val_data.tsv', sep='\\t', index_col=0)\n",
    "# test_data = pd.read_csv('processed_test_data.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APR 5 TODO\n",
    "    - [ ] finalise experiments set up\n",
    "    - [ ] run experiments\n",
    "    - [ ] go back to preprocessing to add dep parse\n",
    "    - [ ] include dep in experiments set up\n",
    "    - [ ] 2nd run\n",
    "    - [ ] metadata unique size doesnt seem to match the number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Alternative way to load data - pickle to pandas dataframe\n",
    "train_data = pd.read_pickle('processed_train_data.p')\n",
    "val_data = pd.read_pickle('processed_val_data.p')\n",
    "test_data = pd.read_pickle('processed_test_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def format_string2np(string_numpy):\n",
    "#     \"\"\"\n",
    "#     Converts string representation of a numpy array to a numpy array.\n",
    "#     Necessary because pandas dataframe cannot store numpy arrays.\n",
    "#\n",
    "#     :param string_numpy: {str} string representation of an array\n",
    "#     :return: numpy array\n",
    "#     \"\"\"\n",
    "#     \"\"\"formatting : Conversion of String List to List\n",
    "#\n",
    "#     Args:\n",
    "#         string_numpy (str)\n",
    "#     Returns:\n",
    "#         l (list): list of values\n",
    "#     \"\"\"\n",
    "#     list_values = string_numpy.strip('[]').split(', ')\n",
    "#     return np.array(list_values).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # reformat dataframe columns from string to numpy arrays\n",
    "# columns = ['word_id_custom', 'word_id_spacy', 'pos_id', 'pos_id_DEFAULT']\n",
    "#\n",
    "# for col in columns:\n",
    "#     train_data[col] = train_data[col].apply(format_string2np)\n",
    "#     val_data[col] = val_data[col].apply(format_string2np)\n",
    "#     test_data[col] = test_data[col].apply(format_string2np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load POS dictionaries\n",
    "with open('pos_dicts.pickle', 'rb') as f:\n",
    "    pos_dict_custom, pos_dict_default = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrixes: (9607, 100) (9496, 300)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding matrixes\n",
    "embedding_matrix_custom_100d = np.load('embedding_matrix_custom_100d.npy')\n",
    "embedding_matrix_spacy_100d = np.load('embedding_matrix_spacy_100d.npy')\n",
    "embedding_matrix_custom_300d = np.load('embedding_matrix_custom_300d.npy')\n",
    "embedding_matrix_spacy_300d = np.load('embedding_matrix_spacy_300d.npy')\n",
    "\n",
    "print(\"Shape of the embedding matrixes:\", embedding_matrix_custom_100d.shape, embedding_matrix_spacy_300d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the vocabulary dictionary: 9606\n"
     ]
    }
   ],
   "source": [
    "# Load vocabulary dictionaries\n",
    "vocabulary_dict_custom = pickle.load(open('vocabulary_statement_custom.p', 'rb'))\n",
    "vocabulary_dict_spacy = pickle.load(open('vocabulary_statement_spacy.p', 'rb'))\n",
    "vocab_length = len(vocabulary_dict_custom)\n",
    "\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train_data # train_data for where state_id max is 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "       index          id        label  \\\n0          0   2635.json        false   \n1          1  10540.json    half-true   \n2          2    324.json  mostly-true   \n3          3   1123.json        false   \n4          4   9028.json    half-true   \n...      ...         ...          ...   \n10235  10235   5473.json  mostly-true   \n10236  10236   3408.json  mostly-true   \n10237  10237   3959.json    half-true   \n10238  10238   2253.json        false   \n10239  10239   1155.json   pants-fire   \n\n                                               statement  \\\n0      Says the Annies List political group supports ...   \n1      When did the decline of coal start? It started...   \n2      Hillary Clinton agrees with John McCain \"by vo...   \n3      Health care reform legislation is likely to ma...   \n4      The economic turnaround started at the end of ...   \n...                                                  ...   \n10235  There are a larger number of shark attacks in ...   \n10236  Democrats have now become the party of the [At...   \n10237  Says an alternative to Social Security that op...   \n10238  On lifting the U.S. Cuban embargo and allowing...   \n10239  The Department of Veterans Affairs has a manua...   \n\n                                  subject         speaker  \\\n0                                abortion    dwayne-bohac   \n1      energy,history,job-accomplishments  scott-surovell   \n2                          foreign-policy    barack-obama   \n3                             health-care    blog-posting   \n4                            economy,jobs   charlie-crist   \n...                                   ...             ...   \n10235                   animals,elections    aclu-florida   \n10236                           elections     alan-powell   \n10237          retirement,social-security     herman-cain   \n10238              florida,foreign-policy     jeff-greene   \n10239                health-care,veterans  michael-steele   \n\n                                           job_title state_info       party  \\\n0                               State representative      Texas  republican   \n1                                     State delegate   Virginia    democrat   \n2                                          President   Illinois    democrat   \n3                                                                      none   \n4                                                       Florida    democrat   \n...                                              ...        ...         ...   \n10235                                                   Florida        none   \n10236                                                   Georgia  republican   \n10237                                                   Georgia  republican   \n10238                                                   Florida    democrat   \n10239  chairman of the Republican National Committee   Maryland  republican   \n\n       barely true  ...  job_id  state_id  party_id  context_id  \\\n0              0.0  ...       1         1         0           2   \n1              0.0  ...       6         7         1           2   \n2             70.0  ...       2         3         1           8   \n3              7.0  ...       0         0         2           0   \n4             15.0  ...       0         2         1           1   \n...            ...  ...     ...       ...       ...         ...   \n10235          0.0  ...       0         2         2           1   \n10236          0.0  ...       0         7         0           0   \n10237          4.0  ...       0         7         0           7   \n10238          3.0  ...       0         2         1           7   \n10239          0.0  ...       6        20         0           1   \n\n                                                  pos_id  \\\n0          [1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]   \n1      [7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...   \n2      [8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...   \n3             [0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]   \n4                   [14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]   \n...                                                  ...   \n10235  [5, 1, 14, 2, 0, 4, 0, 0, 4, 8, 7, 5, 1, 0, 4,...   \n10236  [8, 11, 3, 1, 14, 0, 4, 14, 14, 8, 10, 8, 0, 1...   \n10237  [1, 14, 0, 4, 8, 8, 5, 1, 4, 8, 8, 10, 8, 10, ...   \n10238            [4, 1, 14, 8, 2, 0, 14, 1, 0, 4, 8, 10]   \n10239  [14, 8, 4, 8, 8, 1, 14, 0, 3, 3, 1, 5, 0, 0, 4...   \n\n                                          pos_id_DEFAULT  \\\n0       [16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]   \n1      [14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...   \n2      [11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...   \n3              [7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]   \n4                   [5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]   \n...                                                  ...   \n10235  [10, 16, 5, 0, 7, 1, 7, 7, 1, 11, 14, 10, 16, ...   \n10236  [11, 3, 2, 16, 5, 7, 1, 5, 13, 11, 12, 11, 7, ...   \n10237  [16, 5, 7, 1, 11, 11, 10, 16, 1, 11, 11, 12, 1...   \n10238         [1, 16, 5, 11, 0, 7, 16, 16, 7, 1, 11, 12]   \n10239  [5, 11, 1, 11, 11, 16, 5, 7, 2, 2, 16, 10, 7, ...   \n\n                                        statement_custom  \\\n0      say annies list political group support third ...   \n1      when do decline coal start start when natural ...   \n2      hillary clinton agree john mccain vote give ge...   \n3      health care reform legislation be likely manda...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  be large number shark attack florida than be c...   \n10236  democrats have now become party atlanta metro ...   \n10237  say alternative social security operate galves...   \n10238      lift u.s. cuban embargo and allow travel cuba   \n10239  department veterans affairs have manual out th...   \n\n                                         statement_spacy  \\\n0      say annies list political group support trimes...   \n1      decline coal start start natural gas take star...   \n2      hillary clinton agree john mccain vote george ...   \n3      health care reform legislation likely mandate ...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  large number shark attack florida case voter f...   \n10236           democrats party atlanta metro area black   \n10237  say alternative social security operate galves...   \n10238          lift u.s. cuban embargo allow travel cuba   \n10239  department veterans affairs manual tell vetera...   \n\n                                          word_id_custom  \\\n0      [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1      [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2      [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3      [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                             [282, 3331, 308, 247, 248]   \n...                                                  ...   \n10235  [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...   \n10236     [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]   \n10237  [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...   \n10238     [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]   \n10239  [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...   \n\n                                           word_id_spacy  \n0           [1, 5315, 633, 423, 332, 37, 3919, 120, 936]  \n1      [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...  \n2      [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...  \n3      [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]  \n4                             [224, 3208, 249, 198, 199]  \n...                                                  ...  \n10235           [126, 100, 5078, 257, 59, 344, 168, 482]  \n10236                    [122, 169, 397, 1298, 574, 325]  \n10237  [1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...  \n10238         [1503, 19, 7, 2738, 2994, 118, 1290, 1374]  \n10239  [172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...  \n\n[10240 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>...</th>\n      <th>job_id</th>\n      <th>state_id</th>\n      <th>party_id</th>\n      <th>context_id</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n      <td>[16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n      <td>[14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...</td>\n      <td>[11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td></td>\n      <td></td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]</td>\n      <td>[7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]</td>\n      <td>[5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10235</th>\n      <td>10235</td>\n      <td>5473.json</td>\n      <td>mostly-true</td>\n      <td>There are a larger number of shark attacks in ...</td>\n      <td>animals,elections</td>\n      <td>aclu-florida</td>\n      <td></td>\n      <td>Florida</td>\n      <td>none</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[5, 1, 14, 2, 0, 4, 0, 0, 4, 8, 7, 5, 1, 0, 4,...</td>\n      <td>[10, 16, 5, 0, 7, 1, 7, 7, 1, 11, 14, 10, 16, ...</td>\n      <td>be large number shark attack florida than be c...</td>\n      <td>large number shark attack florida case voter f...</td>\n      <td>[1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...</td>\n      <td>[126, 100, 5078, 257, 59, 344, 168, 482]</td>\n    </tr>\n    <tr>\n      <th>10236</th>\n      <td>10236</td>\n      <td>3408.json</td>\n      <td>mostly-true</td>\n      <td>Democrats have now become the party of the [At...</td>\n      <td>elections</td>\n      <td>alan-powell</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[8, 11, 3, 1, 14, 0, 4, 14, 14, 8, 10, 8, 0, 1...</td>\n      <td>[11, 3, 2, 16, 5, 7, 1, 5, 13, 11, 12, 11, 7, ...</td>\n      <td>democrats have now become party atlanta metro ...</td>\n      <td>democrats party atlanta metro area black</td>\n      <td>[157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]</td>\n      <td>[122, 169, 397, 1298, 574, 325]</td>\n    </tr>\n    <tr>\n      <th>10237</th>\n      <td>10237</td>\n      <td>3959.json</td>\n      <td>half-true</td>\n      <td>Says an alternative to Social Security that op...</td>\n      <td>retirement,social-security</td>\n      <td>herman-cain</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>7</td>\n      <td>[1, 14, 0, 4, 8, 8, 5, 1, 4, 8, 8, 10, 8, 10, ...</td>\n      <td>[16, 5, 7, 1, 11, 11, 10, 16, 1, 11, 11, 12, 1...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>[3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...</td>\n      <td>[1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...</td>\n    </tr>\n    <tr>\n      <th>10238</th>\n      <td>10238</td>\n      <td>2253.json</td>\n      <td>false</td>\n      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n      <td>florida,foreign-policy</td>\n      <td>jeff-greene</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>[4, 1, 14, 8, 2, 0, 14, 1, 0, 4, 8, 10]</td>\n      <td>[1, 16, 5, 11, 0, 7, 16, 16, 7, 1, 11, 12]</td>\n      <td>lift u.s. cuban embargo and allow travel cuba</td>\n      <td>lift u.s. cuban embargo allow travel cuba</td>\n      <td>[1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]</td>\n      <td>[1503, 19, 7, 2738, 2994, 118, 1290, 1374]</td>\n    </tr>\n    <tr>\n      <th>10239</th>\n      <td>10239</td>\n      <td>1155.json</td>\n      <td>pants-fire</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>health-care,veterans</td>\n      <td>michael-steele</td>\n      <td>chairman of the Republican National Committee</td>\n      <td>Maryland</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>20</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[14, 8, 4, 8, 8, 1, 14, 0, 3, 3, 1, 5, 0, 0, 4...</td>\n      <td>[5, 11, 1, 11, 11, 16, 5, 7, 2, 2, 16, 10, 7, ...</td>\n      <td>department veterans affairs have manual out th...</td>\n      <td>department veterans affairs manual tell vetera...</td>\n      <td>[216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...</td>\n      <td>[172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10240 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data # train_data for where state_id max is 20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  8  7 10  5]\n"
     ]
    }
   ],
   "source": [
    "# print(train_data['party_id'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## to test the different preprocessing methods, the following experiments will be run:\n",
    "1. siddarth - baseline\n",
    "\n",
    "        - ogdict\n",
    "        - nltk stopword removal only\n",
    "\n",
    "****\n",
    "****\n",
    "\n",
    "## todo\n",
    "****\n",
    "### INITIALISE INPUT/OUTPUT\n",
    "1. [x] word_id custom AS X_train_custom\n",
    "  - [x] embedding_matrix_custom\n",
    "  - [x] vocabulary_dict_custom\n",
    "2. [x] word_id spacy AS X_train_spacy\n",
    "  - [x] embedding_matrix_spacy\n",
    "  - [x] vocabulary_dict_spacy\n",
    "  \n",
    "3. [x] pos_id custom AS X_train_pos_custom\n",
    "4. [x] pos_id spacy AS X_train_pos_spacy\n",
    "    \n",
    "#### Input variables to be processed: \n",
    "- [x] meta\n",
    "- [ ] dep parse\n",
    "\n",
    "****\n",
    "### GENERAL\n",
    "- [x] change everything to python 3\n",
    "\n",
    "### variables, init, etc.\n",
    "- [x] pass in vocabulary.p\n",
    "****\n",
    "### BILSTM MODEL\n",
    "- [x] functions: train(), etc\n",
    "        (CODE CELLS COULD BE BETTER, INVESTIGATE)\n",
    "- [ ] verify varibales are correct\n",
    "\n",
    "****\n",
    "*decide which word id to use*\n",
    "- [x] jaccard similarity\n",
    "\n",
    "1. fathan - pos tag check [ ]\n",
    "    - custom pos tag dict\n",
    "    - spacy preprocess - spacy word id\n",
    "    - glove\n",
    " 2. fathan - preprocess [ ]\n",
    "    - custom pos tag dict\n",
    "    - custom preprocess - custom word id\n",
    "    - glove\n",
    "    * check best results with default pos tag [ ]\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "# HYPERPARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 1 with size 18",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m num_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(num_state)\n\u001B[1;32m----> 3\u001B[0m state_train \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstate_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_state\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\np_utils.py:73\u001B[0m, in \u001B[0;36mto_categorical\u001B[1;34m(y, num_classes, dtype)\u001B[0m\n\u001B[0;32m     71\u001B[0m n \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     72\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((n, num_classes), dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m---> 73\u001B[0m categorical[np\u001B[38;5;241m.\u001B[39marange(n), y] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     74\u001B[0m output_shape \u001B[38;5;241m=\u001B[39m input_shape \u001B[38;5;241m+\u001B[39m (num_classes,)\n\u001B[0;32m     75\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(categorical, output_shape)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 20 is out of bounds for axis 1 with size 18"
     ]
    }
   ],
   "source": [
    "# num_state = len(train_data['state_id'].unique())\n",
    "# print(num_state)\n",
    "# state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=num_state)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "18\n",
      "18\n",
      "19\n",
      "25\n",
      "26\n",
      "Index(['index', 'id', 'label', 'statement', 'subject', 'speaker', 'job_title',\n",
      "       'state_info', 'party', 'barely true', 'false', 'half-true',\n",
      "       'mostly-true', 'pants-on-fire', 'context', 'output', 'subject_id',\n",
      "       'speaker_id', 'job_id', 'state_id', 'party_id', 'context_id', 'pos_id',\n",
      "       'pos_id_DEFAULT', 'statement_custom', 'statement_spacy',\n",
      "       'word_id_custom', 'word_id_spacy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 100d GLOVE\n",
    "EMBED_DIM = 100\n",
    "\n",
    "# vocab_length = len(vocabulary_dict.keys())\n",
    "custom_vocabLen = len(vocabulary_dict_custom.keys())\n",
    "spacy_vocabLen = len(vocabulary_dict_spacy.keys())\n",
    "hidden_size = EMBED_DIM #Has to be same as EMBED_DIM\n",
    "lstm_size = 100\n",
    "num_steps = 30\n",
    "num_epochs = 30\n",
    "batch_size = 40\n",
    "\n",
    "embedding_matrix = embedding_matrix_custom_100d\n",
    "\n",
    "#Meta data related hyper params\n",
    "num_party = len(train_data.party_id.unique())\n",
    "num_state = len(train_data['state_id'].unique())\n",
    "num_context = len(train_data['context_id'].unique())\n",
    "num_job = len(train_data['job_id'].unique())\n",
    "num_sub = len(train_data['subject_id'].unique())\n",
    "num_speaker = len(train_data['speaker_id'].unique())\n",
    "\n",
    "print(num_party)\n",
    "print(num_state)\n",
    "print(num_context)\n",
    "print(num_job)\n",
    "print(num_sub)\n",
    "print(num_speaker)\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...\n",
      "1        [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...\n",
      "2        [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...\n",
      "3        [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...\n",
      "4                               [282, 3331, 308, 247, 248]\n",
      "                               ...                        \n",
      "10235    [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...\n",
      "10236       [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]\n",
      "10237    [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...\n",
      "10238       [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]\n",
      "10239    [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...\n",
      "Name: word_id_custom, Length: 10240, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['word_id_custom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        1\n",
      "3        2\n",
      "4        1\n",
      "        ..\n",
      "10235    2\n",
      "10236    0\n",
      "10237    0\n",
      "10238    1\n",
      "10239    0\n",
      "Name: party_id, Length: 10240, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['party_id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input/Output Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# party_train = keras.utils.to_categorical(train_data['party_id'], num_classes=11)\n",
    "# state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=51)\n",
    "# context_train = keras.utils.to_categorical(train_data['context_id'], num_classes=21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# party_train = keras.utils.to_categorical(train_data['party_id'], num_classes=11)\n",
    "# state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=21)\n",
    "# context_train = keras.utils.to_categorical(train_data['context_id'], num_classes=21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apr 6 TODO:\n",
    "    - [ ] fix the input shape for the meta data, as num_party is 11, not 9.\n",
    "            - num_party = len(train_data.party_id.unique()) returns 9 instead of 11.\n",
    "            - or is it expecting 11 wrongly and party_id number of labels should be"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for axis 1 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Meta data preparation\u001B[39;00m\n\u001B[0;32m      2\u001B[0m party_train \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mto_categorical(train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparty_id\u001B[39m\u001B[38;5;124m'\u001B[39m], num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m11\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m state_train \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstate_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m context_train \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mto_categorical(train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontext_id\u001B[39m\u001B[38;5;124m'\u001B[39m], num_classes\u001B[38;5;241m=\u001B[39mnum_context)\n\u001B[0;32m      5\u001B[0m job_train \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mto_categorical(train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjob_id\u001B[39m\u001B[38;5;124m'\u001B[39m], num_classes\u001B[38;5;241m=\u001B[39mnum_job)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\np_utils.py:73\u001B[0m, in \u001B[0;36mto_categorical\u001B[1;34m(y, num_classes, dtype)\u001B[0m\n\u001B[0;32m     71\u001B[0m n \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     72\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((n, num_classes), dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m---> 73\u001B[0m categorical[np\u001B[38;5;241m.\u001B[39marange(n), y] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     74\u001B[0m output_shape \u001B[38;5;241m=\u001B[39m input_shape \u001B[38;5;241m+\u001B[39m (num_classes,)\n\u001B[0;32m     75\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(categorical, output_shape)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 30 is out of bounds for axis 1 with size 30"
     ]
    }
   ],
   "source": [
    "\n",
    "#Meta data preparation\n",
    "party_train = keras.utils.to_categorical(train_data['party_id'], num_classes=num_party)\n",
    "state_train = keras.utils.to_categorical(train_data['state_id'], num_classes=num_state)\n",
    "context_train = keras.utils.to_categorical(train_data['context_id'], num_classes=num_context)\n",
    "job_train = keras.utils.to_categorical(train_data['job_id'], num_classes=num_job)\n",
    "subject_train = keras.utils.to_categorical(train_data['subject_id'], num_classes=num_sub)\n",
    "speaker_train = keras.utils.to_categorical(train_data['speaker_id'], num_classes=num_speaker)\n",
    "\n",
    "\n",
    "party_val = keras.utils.to_categorical(val_data['party_id'], num_classes=num_party)\n",
    "state_val = keras.utils.to_categorical(val_data['state_id'], num_classes=num_state)\n",
    "context_val = keras.utils.to_categorical(val_data['context_id'], num_classes=num_context)\n",
    "job_val = keras.utils.to_categorical(val_data['job_id'], num_classes=num_job)\n",
    "subject_val = keras.utils.to_categorical(val_data['subject_id'], num_classes=num_sub)\n",
    "speaker_val = keras.utils.to_categorical(val_data['speaker_id'], num_classes=num_speaker)\n",
    "\n",
    "\n",
    "party_test = keras.utils.to_categorical(test_data['party_id'], num_classes=num_party)\n",
    "state_test = keras.utils.to_categorical(test_data['state_id'], num_classes=num_state)\n",
    "context_test = keras.utils.to_categorical(test_data['context_id'], num_classes=num_context)\n",
    "job_test = keras.utils.to_categorical(test_data['job_id'], num_classes=num_job)\n",
    "subject_test = keras.utils.to_categorical(test_data['subject_id'], num_classes=num_sub)\n",
    "speaker_test = keras.utils.to_categorical(test_data['speaker_id'], num_classes=num_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def input_pad_sequences(data):\n",
    "    padded_data = sequence.pad_sequences(data, maxlen=num_steps, padding='post', truncating='post')\n",
    "    return padded_data\n",
    "\n",
    "X_train_custom = input_pad_sequences(train_data['word_id_custom'])\n",
    "X_val_custom = input_pad_sequences(val_data['word_id_custom'])\n",
    "X_test_custom = input_pad_sequences(test_data['word_id_custom'])\n",
    "\n",
    "X_train_spacy = input_pad_sequences(train_data['word_id_spacy'])\n",
    "X_val_spacy = input_pad_sequences(val_data['word_id_spacy'])\n",
    "X_test_spacy = input_pad_sequences(test_data['word_id_spacy'])\n",
    "\n",
    "X_train_pos_custom = input_pad_sequences(train_data['pos_id'])\n",
    "X_val_pos_custom = input_pad_sequences(val_data['pos_id'])\n",
    "X_test_pos_custom = input_pad_sequences(test_data['pos_id'])\n",
    "\n",
    "X_train_pos_DEFAULT = input_pad_sequences(train_data['pos_id_DEFAULT'])\n",
    "X_val_pos_DEFAULT = input_pad_sequences(val_data['pos_id_DEFAULT'])\n",
    "X_test_pos_DEFAULT = input_pad_sequences(test_data['pos_id_DEFAULT'])\n",
    "\n",
    "# X_train_meta = np.hstack((party_train,\n",
    "#                           state_train,\n",
    "#                           context_train,\n",
    "#                           job_train,\n",
    "#                           subject_train,\n",
    "#                           speaker_train))\n",
    "#\n",
    "# X_val_meta = np.hstack((party_val,\n",
    "#                         state_val,\n",
    "#                         context_val,\n",
    "#                         job_val,\n",
    "#                         subject_val,\n",
    "#                         speaker_val))\n",
    "#\n",
    "# X_test_meta = np.hstack((party_test,\n",
    "#                          state_test,\n",
    "#                          context_test,\n",
    "#                          job_test,\n",
    "#                          subject_test,\n",
    "#                          speaker_test))\n",
    "\n",
    "#TODO: preprocess dependency parse\n",
    "# X_train_dep = input_pad_sequences(train_data['dep_id'])\n",
    "# X_val_dep = input_pad_sequences(val_data['dep_id'])\n",
    "# X_test_dep = input_pad_sequences(test_data['dep_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 14  8 ...  0  0  0]\n",
      " [ 7  1 14 ...  0  0  0]\n",
      " [ 8  8  1 ...  0  0  0]\n",
      " ...\n",
      " [ 1 14  0 ...  0  0  0]\n",
      " [ 4  1 14 ...  0  0  0]\n",
      " [14  8  4 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pos_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialise input/output\n",
    "\n",
    "## OUTPUT\n",
    "Y_train = train_data['output']\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=6)\n",
    "\n",
    "Y_val = val_data['output']\n",
    "Y_val = keras.utils.to_categorical(Y_val, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 350  425   28 ...    0    0    0]\n",
      " [  64    1 1930 ...    0    0    0]\n",
      " [   3  160  201 ...    0    0    0]\n",
      " ...\n",
      " [ 472 1547  191 ...    0    0    0]\n",
      " [   3 1406  928 ...    0    0    0]\n",
      " [   3   93    1 ...    0    0    0]]\n",
      "[[ 291  358   19 ...    0    0    0]\n",
      " [  45 1829  234 ...    0    0    0]\n",
      " [   1  125  157 ...    0    0    0]\n",
      " ...\n",
      " [ 405 1448  153 ...    0    0    0]\n",
      " [   1 1306  836 ...    0    0    0]\n",
      " [   1   64   34 ...    0    0    0]]\n",
      "[[ 1 14  0 ...  0  0  0]\n",
      " [ 8 11  4 ...  0  0  0]\n",
      " [ 1  8  8 ...  0  0  0]\n",
      " ...\n",
      " [ 4 14  2 ...  0  0  0]\n",
      " [ 1 14  8 ...  0  0  0]\n",
      " [ 1 14  0 ...  0  0  0]]\n",
      "[[16  5  7 ...  0  0  0]\n",
      " [11  3  1 ...  0  0  0]\n",
      " [16 11 11 ...  0  0  0]\n",
      " ...\n",
      " [ 1  5  0 ...  0  0  0]\n",
      " [16  5 11 ...  0  0  0]\n",
      " [16  5  7 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_custom)\n",
    "print(X_test_spacy)\n",
    "print(X_test_pos_custom)\n",
    "print(X_test_pos_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 15) (1284, 15) (1267, 15)\n",
      "(10240, 15) (1284, 15) (1267, 15)\n",
      "(10240, 15) (1284, 15) (1267, 15)\n",
      "(10240, 15) (1284, 15) (1267, 15)\n",
      "(10240, 6) (1284, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_custom.shape, X_val_custom.shape, X_test_custom.shape)\n",
    "print(X_train_spacy.shape, X_val_spacy.shape, X_test_spacy.shape)\n",
    "print(X_train_pos_custom.shape, X_val_pos_custom.shape, X_test_pos_custom.shape)\n",
    "print(X_train_pos_DEFAULT.shape, X_val_pos_DEFAULT.shape, X_test_pos_DEFAULT.shape)\n",
    "print(Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. fathan - pos tag check [ ]\n",
    "    - custom word id [ ]\n",
    "    - custom pos id [ ]\n",
    "    - glove [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in the input data: 14\n"
     ]
    }
   ],
   "source": [
    "max_value = max(np.max(X_train_pos_custom), np.max(X_val_pos_custom))\n",
    "print(\"Maximum value in the input data:\", max_value)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, name, train_inputs, val_inputs):\n",
    "    \"\"\"\n",
    "    Trains the given model with the provided input tensors.\n",
    "\n",
    "    :param model: {tf.keras.Model} model to be trained\n",
    "    :param name: {str} model name used for saving best weights\n",
    "    :param train_inputs: {dict} dictionary containing training input tensors\n",
    "    :param val_inputs: {dict} dictionary containing validation input tensors\n",
    "    \"\"\"\n",
    "    sgd = optimizers.SGD(learning_rate=0.025, clipvalue=0.3, nesterov=True)\n",
    "    adam = optimizers.Adam(learning_rate=0.000075, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    tb = TensorBoard()\n",
    "    csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "    filepath = name + \"_weights_best.hdf5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy',\n",
    "                                                  verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    # model.fit(\n",
    "    #     inputs,\n",
    "    #     {'main_output': Y_train},\n",
    "    #     epochs=num_epochs,\n",
    "    #     batch_size=batch_size,\n",
    "    #     validation_data=(\n",
    "    #         validation_inputs,\n",
    "    #         {'main_output': Y_val}\n",
    "    #     ),\n",
    "    #     callbacks=[tb, csv_logger, checkpoint]\n",
    "    # )\n",
    "\n",
    "    model.fit(\n",
    "        train_inputs,\n",
    "        {'main_output': Y_train},\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(\n",
    "            val_inputs,\n",
    "            {'main_output': Y_val}\n",
    "        ),\n",
    "        callbacks=[tb, csv_logger, checkpoint]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def compile_model(model):\n",
    "#     \"\"\"\n",
    "#     Compiles the given model with SGD optimizer, categorical_crossentropy loss, and categorical_accuracy metrics.\n",
    "#\n",
    "#     :param model: {tf.keras.Model} the model to be compiled\n",
    "#     \"\"\"\n",
    "#     sgd = optimizers.SGD(learning_rate=0.025, clipvalue=0.3, nesterov=True)\n",
    "#     model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#\n",
    "# def create_callbacks(name):\n",
    "#     \"\"\"\n",
    "#     Creates a list of callbacks for model training.\n",
    "#\n",
    "#     :param name: {str} model name used for saving best weights\n",
    "#\n",
    "#     :return: {list} list of callbacks\n",
    "#     \"\"\"\n",
    "#     tb = TensorBoard()\n",
    "#     csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "#     filepath = name + \"_weights_best.hdf5\"\n",
    "#     checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy',\n",
    "#                                                   verbose=1, save_best_only=True, mode='max')\n",
    "#     return [tb, csv_logger, checkpoint]\n",
    "\n",
    "# def merge_dicts(*args, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Merges the input dictionaries from args and kwargs.\n",
    "#\n",
    "#     :param *args: {tuple} variable length argument list for input dictionaries\n",
    "#     :param **kwargs: {dict} arbitrary keyword arguments for input dictionaries\n",
    "#\n",
    "#     :return: {dict} merged dictionary\n",
    "#     \"\"\"\n",
    "#     inputs = {}\n",
    "#     for arg in args:\n",
    "#         inputs.update(arg)\n",
    "#     inputs.update(kwargs)\n",
    "#     return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# def train(model, name, train_inputs, val_inputs):\n",
    "#     \"\"\"\n",
    "#     Trains the given model with the provided input tensors.\n",
    "#\n",
    "#     :param model: {tf.keras.Model} model to be trained\n",
    "#     :param name: {str} model name used for saving best weights\n",
    "#     :param train_inputs: {dict} dictionary containing training input tensors\n",
    "#     :param val_inputs: {dict} dictionary containing validation input tensors\n",
    "#     \"\"\"\n",
    "#     compile_model(model)\n",
    "#     callbacks = create_callbacks(name)\n",
    "#\n",
    "#     model.fit(\n",
    "#         train_inputs,\n",
    "#         {'main_output': Y_train},\n",
    "#         epochs=num_epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_data=(\n",
    "#             val_inputs,\n",
    "#             {'main_output': Y_val}\n",
    "#         ),\n",
    "#         callbacks=callbacks\n",
    "#     )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# def train(model, name, *args, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Trains the given model with the provided input tensors and keyword arguments.\n",
    "#\n",
    "#     :param model: {tf.keras.Model} model to be trained\n",
    "#     :param name: {str} model name used for saving best weights\n",
    "#     :param args: {tuple} variable length argument list for input tensors\n",
    "#     :param kwargs: {dict} keyword arguments for input tensors\n",
    "#     \"\"\"\n",
    "#     compile_model(model)\n",
    "#     callbacks = create_callbacks(name)\n",
    "#     inputs = merge_dicts(*args, **kwargs)\n",
    "#     validation_inputs = merge_dicts(*args, **kwargs)\n",
    "#\n",
    "#     model.fit(\n",
    "#         inputs,\n",
    "#         {'main_output': Y_train},\n",
    "#         epochs=num_epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_data=(\n",
    "#             validation_inputs,\n",
    "#             {'main_output': Y_val}\n",
    "#         ),\n",
    "#         callbacks=callbacks\n",
    "#     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def print_best_false_true_predicted(fw, tb):\n",
    "  sorted_false = sorted(fw.items(), key=operator.itemgetter(1), reverse=True)\n",
    "  sorted_true = sorted(tb.items(), key=operator.itemgetter(1), reverse=True)\n",
    "  print('*****************************************************************')\n",
    "  print('******************** False statements *************************')\n",
    "\n",
    "  for t in sorted_false[:5]:\n",
    "    print(t[1])\n",
    "    print(test_data.loc[t[0]])\n",
    "    print('=============')\n",
    "  print('*****************************************************************')\n",
    "  print('******************** True Statements *************************')\n",
    "  for t in sorted_true[:5]:\n",
    "    print(t[1])\n",
    "    print(test_data.loc[t[0]])\n",
    "    print('=============')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_and_predict(name, inputs):\n",
    "    \"\"\"\n",
    "    Load the model and predict with the provided inputs\n",
    "\n",
    "    :param name: {str} name of the model to load the model weights\n",
    "    :param inputs: {dict} dictionary of inputs to be passed to the model\n",
    "\n",
    "    :return: preds {np.array} array of predicted values/\n",
    "    \"\"\"\n",
    "    model = load_model(name + \"_weights_best.hdf5\")\n",
    "    preds = model.predict(inputs,\n",
    "                          batch_size=batch_size,\n",
    "                          verbose=1)\n",
    "    return preds\n",
    "\n",
    "def calculate_accuracy(predictions, Y_test_gt):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the predictions\n",
    "\n",
    "    :param predictions: {np.array} predicted values\n",
    "    :param Y_test_gt: {np.array} ground truth values\n",
    "\n",
    "    :return: accuracy {float} accuracy of the predictions\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == Y_test_gt[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(predictions)\n",
    "    return accuracy\n",
    "\n",
    "def extract_fw_tb(preds):\n",
    "    \"\"\"\n",
    "    Extracts the worst false predictions and the best true predictions\n",
    "\n",
    "    :param preds: {np.array} array of predicted values\n",
    "\n",
    "    :return: false_worst: {dict} dictionary of worst false predictions\n",
    "    :return: true_best: {dict} dictionary of best true predictions\n",
    "    \"\"\"\n",
    "    false_worst = {}\n",
    "    true_best = {}\n",
    "\n",
    "    for p in range(len(preds)):\n",
    "        if np.argmax(preds[p])==0:\n",
    "            false_worst[p]=preds[p][0]\n",
    "        elif np.argmax(preds[p])==5:\n",
    "            true_best[p]=preds[p][5]\n",
    "\n",
    "    return false_worst, true_best\n",
    "\n",
    "def evaluate(model_name, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluates the given model with provided input tensors\n",
    "\n",
    "    :param model_name: {str} used to load model weights\n",
    "    :param args: {list} of dictionaries of inputs\n",
    "    :param kwargs:\n",
    "\n",
    "    :return: false_worst: {dict} of the worst false predictions\n",
    "    :return: true_best: {dict} of the best true predictions\n",
    "    \"\"\"\n",
    "    inputs = {}\n",
    "    for arg in args:\n",
    "        inputs.update(arg)\n",
    "    inputs.update(kwargs)\n",
    "\n",
    "    preds = load_and_predict(model_name, inputs)\n",
    "\n",
    "    Y_test_groundtruth = list(test_data['output'])\n",
    "    predictions = np.array([np.argmax(pred) for pred in preds])\n",
    "\n",
    "    accuracy = calculate_accuracy(predictions, Y_test_groundtruth)\n",
    "    print(\"Correctly Predicted: \", np.sum(predictions == Y_test_groundtruth), \"/\", len(Y_test_groundtruth))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "    false_worst, true_best = extract_fw_tb(preds)\n",
    "\n",
    "    pickle.dump(predictions, open(model_name + \"_predictions.p\", \"wb\"))\n",
    "    return false_worst, true_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def evaluate(name, *args, **kwargs):\n",
    "#     model = load_model(name + \"_weights_best.hdf5\")\n",
    "#     inputs = {}\n",
    "#     for arg in args:\n",
    "#         inputs.update(arg)\n",
    "#     inputs.update(kwargs)\n",
    "#\n",
    "#     preds = model.predict(inputs,\n",
    "#                           batch_size=batch_size,\n",
    "#                           verbose=1)\n",
    "#\n",
    "#     false_worst = {}\n",
    "#     true_best = {}\n",
    "#\n",
    "#     Y_test_gt = list(test_data['output'])\n",
    "#     predictions = np.array([np.argmax(pred) for pred in preds])\n",
    "#\n",
    "#     for p in range(len(preds)):\n",
    "#         if np.argmax(preds[p])==0:\n",
    "#             false_worst[p]=preds[p][0]\n",
    "#         elif np.argmax(preds[p])==5:\n",
    "#             true_best[p]=preds[p][5]\n",
    "#\n",
    "#     # print(len(predictions))==len(Y_test_gt)\n",
    "#     correct = np.sum(predictions == Y_test_gt)\n",
    "#     print(\"Correctly Predicted: \", correct,\"/\",len(Y_test_gt))\n",
    "#     print(\"Accuracy: \", correct*100.0/len(Y_test_gt))\n",
    "#\n",
    "#     pickle.dump(predictions, open(name+\"_predictions.p\", \"wb\"))\n",
    "#     return false_worst, true_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configurations = [\n",
    "\t{\n",
    "        \"name\": \"fathan_1\",\n",
    "        \"inputs\": [X_test_custom, X_test_pos],\n",
    "    },\n",
    "\t{\n",
    "        \"name\": \"fathan_2\",\n",
    "        \"inputs\": [X_test_spacy, X_test_pos],\n",
    "    },\n",
    "\t{\n",
    "        \"name\": \"fathan_3\",\n",
    "        \"inputs\": [X_test_custom, X_test_pos_DEFAULT],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fathan_4\",\n",
    "        \"inputs\": [X_test_custom, X_test_pos_DEFAULT],\n",
    "    },\n",
    "\t# {\n",
    "    #     \"name\": \"fathan_5\",\n",
    "    #     \"inputs\": [X_test_best, X_test_pos_best, X_test_meta],\n",
    "    # },\n",
    "\t# {\n",
    "    #     \"name\": \"fathan_6\",\n",
    "    #     \"inputs\": [X_test_best, X_test_pos_best, X_test_meta, X_test_dep],\n",
    "    # },\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# model_name = \"bilstm\"\n",
    "#\n",
    "# for config in configurations:\n",
    "#     print(f\"Running {config['name']}...\")\n",
    "#     (fw, tb) = evaluate(model_name, *config[\"inputs\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "       index          id        label  \\\n0          0   2635.json        false   \n1          1  10540.json    half-true   \n2          2    324.json  mostly-true   \n3          3   1123.json        false   \n4          4   9028.json    half-true   \n...      ...         ...          ...   \n10235  10235   5473.json  mostly-true   \n10236  10236   3408.json  mostly-true   \n10237  10237   3959.json    half-true   \n10238  10238   2253.json        false   \n10239  10239   1155.json   pants-fire   \n\n                                               statement  \\\n0      Says the Annies List political group supports ...   \n1      When did the decline of coal start? It started...   \n2      Hillary Clinton agrees with John McCain \"by vo...   \n3      Health care reform legislation is likely to ma...   \n4      The economic turnaround started at the end of ...   \n...                                                  ...   \n10235  There are a larger number of shark attacks in ...   \n10236  Democrats have now become the party of the [At...   \n10237  Says an alternative to Social Security that op...   \n10238  On lifting the U.S. Cuban embargo and allowing...   \n10239  The Department of Veterans Affairs has a manua...   \n\n                                  subject         speaker  \\\n0                                abortion    dwayne-bohac   \n1      energy,history,job-accomplishments  scott-surovell   \n2                          foreign-policy    barack-obama   \n3                             health-care    blog-posting   \n4                            economy,jobs   charlie-crist   \n...                                   ...             ...   \n10235                   animals,elections    aclu-florida   \n10236                           elections     alan-powell   \n10237          retirement,social-security     herman-cain   \n10238              florida,foreign-policy     jeff-greene   \n10239                health-care,veterans  michael-steele   \n\n                                           job_title state_info       party  \\\n0                               State representative      Texas  republican   \n1                                     State delegate   Virginia    democrat   \n2                                          President   Illinois    democrat   \n3                                                                      none   \n4                                                       Florida    democrat   \n...                                              ...        ...         ...   \n10235                                                   Florida        none   \n10236                                                   Georgia  republican   \n10237                                                   Georgia  republican   \n10238                                                   Florida    democrat   \n10239  chairman of the Republican National Committee   Maryland  republican   \n\n       barely true  ...  job_id  state_id  party_id  context_id  \\\n0              0.0  ...       1         1         0           2   \n1              0.0  ...       6         7         1           2   \n2             70.0  ...       2         3         1           8   \n3              7.0  ...       0         0         2           0   \n4             15.0  ...       0         2         1           1   \n...            ...  ...     ...       ...       ...         ...   \n10235          0.0  ...       0         2         2           1   \n10236          0.0  ...       0         7         0           0   \n10237          4.0  ...       0         7         0           7   \n10238          3.0  ...       0         2         1           7   \n10239          0.0  ...       6        20         0           1   \n\n                                                  pos_id  \\\n0          [1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]   \n1      [7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...   \n2      [8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...   \n3             [0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]   \n4                   [14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]   \n...                                                  ...   \n10235  [5, 1, 14, 2, 0, 4, 0, 0, 4, 8, 7, 5, 1, 0, 4,...   \n10236  [8, 11, 3, 1, 14, 0, 4, 14, 14, 8, 10, 8, 0, 1...   \n10237  [1, 14, 0, 4, 8, 8, 5, 1, 4, 8, 8, 10, 8, 10, ...   \n10238            [4, 1, 14, 8, 2, 0, 14, 1, 0, 4, 8, 10]   \n10239  [14, 8, 4, 8, 8, 1, 14, 0, 3, 3, 1, 5, 0, 0, 4...   \n\n                                          pos_id_DEFAULT  \\\n0       [16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]   \n1      [14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...   \n2      [11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...   \n3              [7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]   \n4                   [5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]   \n...                                                  ...   \n10235  [10, 16, 5, 0, 7, 1, 7, 7, 1, 11, 14, 10, 16, ...   \n10236  [11, 3, 2, 16, 5, 7, 1, 5, 13, 11, 12, 11, 7, ...   \n10237  [16, 5, 7, 1, 11, 11, 10, 16, 1, 11, 11, 12, 1...   \n10238         [1, 16, 5, 11, 0, 7, 16, 16, 7, 1, 11, 12]   \n10239  [5, 11, 1, 11, 11, 16, 5, 7, 2, 2, 16, 10, 7, ...   \n\n                                        statement_custom  \\\n0      say annies list political group support third ...   \n1      when do decline coal start start when natural ...   \n2      hillary clinton agree john mccain vote give ge...   \n3      health care reform legislation be likely manda...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  be large number shark attack florida than be c...   \n10236  democrats have now become party atlanta metro ...   \n10237  say alternative social security operate galves...   \n10238      lift u.s. cuban embargo and allow travel cuba   \n10239  department veterans affairs have manual out th...   \n\n                                         statement_spacy  \\\n0      say annies list political group support trimes...   \n1      decline coal start start natural gas take star...   \n2      hillary clinton agree john mccain vote george ...   \n3      health care reform legislation likely mandate ...   \n4                     economic turnaround start end term   \n...                                                  ...   \n10235  large number shark attack florida case voter f...   \n10236           democrats party atlanta metro area black   \n10237  say alternative social security operate galves...   \n10238          lift u.s. cuban embargo allow travel cuba   \n10239  department veterans affairs manual tell vetera...   \n\n                                          word_id_custom  \\\n0      [3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...   \n1      [37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...   \n2      [104, 69, 734, 160, 201, 18, 89, 262, 137, 258...   \n3      [19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...   \n4                             [282, 3331, 308, 247, 248]   \n...                                                  ...   \n10235  [1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...   \n10236     [157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]   \n10237  [3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...   \n10238     [1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]   \n10239  [216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...   \n\n                                           word_id_spacy  \n0           [1, 5315, 633, 423, 332, 37, 3919, 120, 936]  \n1      [720, 773, 249, 249, 891, 204, 46, 249, 527, 1...  \n2      [74, 49, 649, 125, 157, 12, 212, 103, 208, 274...  \n3      [13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]  \n4                             [224, 3208, 249, 198, 199]  \n...                                                  ...  \n10235           [126, 100, 5078, 257, 59, 344, 168, 482]  \n10236                    [122, 169, 397, 1298, 574, 325]  \n10237  [1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...  \n10238         [1503, 19, 7, 2738, 2994, 118, 1290, 1374]  \n10239  [172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...  \n\n[10240 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party</th>\n      <th>barely true</th>\n      <th>...</th>\n      <th>job_id</th>\n      <th>state_id</th>\n      <th>party_id</th>\n      <th>context_id</th>\n      <th>pos_id</th>\n      <th>pos_id_DEFAULT</th>\n      <th>statement_custom</th>\n      <th>statement_spacy</th>\n      <th>word_id_custom</th>\n      <th>word_id_spacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[1, 14, 8, 8, 2, 0, 1, 2, 10, 0, 0, 4, 0, 10]</td>\n      <td>[16, 5, 11, 11, 0, 7, 16, 0, 12, 7, 7, 1, 7, 12]</td>\n      <td>say annies list political group support third ...</td>\n      <td>say annies list political group support trimes...</td>\n      <td>[3, 5440, 717, 493, 396, 54, 274, 4039, 155, 1...</td>\n      <td>[1, 5315, 633, 423, 332, 37, 3919, 120, 936]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[7, 1, 14, 0, 4, 0, 0, 10, 5, 1, 7, 2, 0, 1, 4...</td>\n      <td>[14, 16, 5, 7, 1, 7, 7, 12, 10, 16, 14, 0, 7, ...</td>\n      <td>when do decline coal start start when natural ...</td>\n      <td>decline coal start start natural gas take star...</td>\n      <td>[37, 9, 804, 861, 308, 308, 37, 981, 254, 39, ...</td>\n      <td>[720, 773, 249, 249, 891, 204, 46, 249, 527, 1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8</td>\n      <td>[8, 8, 1, 4, 8, 8, 10, 4, 1, 12, 1, 8, 8, 14, ...</td>\n      <td>[11, 11, 16, 1, 11, 11, 12, 1, 16, 9, 16, 11, ...</td>\n      <td>hillary clinton agree john mccain vote give ge...</td>\n      <td>hillary clinton agree john mccain vote george ...</td>\n      <td>[104, 69, 734, 160, 201, 18, 89, 262, 137, 258...</td>\n      <td>[74, 49, 649, 125, 157, 12, 212, 103, 208, 274...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td></td>\n      <td></td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 11, 2, 12, 1, 2, 0, 0, 0, 10]</td>\n      <td>[7, 7, 7, 7, 3, 0, 9, 16, 0, 7, 7, 7, 12]</td>\n      <td>health care reform legislation be likely manda...</td>\n      <td>health care reform legislation likely mandate ...</td>\n      <td>[19, 22, 209, 252, 1, 592, 406, 361, 439, 176,...</td>\n      <td>[13, 16, 165, 202, 514, 342, 301, 372, 140, 2747]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[14, 2, 0, 1, 4, 14, 0, 4, 5, 0, 10]</td>\n      <td>[5, 0, 7, 16, 1, 5, 7, 1, 10, 7, 12]</td>\n      <td>economic turnaround start end term</td>\n      <td>economic turnaround start end term</td>\n      <td>[282, 3331, 308, 247, 248]</td>\n      <td>[224, 3208, 249, 198, 199]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10235</th>\n      <td>10235</td>\n      <td>5473.json</td>\n      <td>mostly-true</td>\n      <td>There are a larger number of shark attacks in ...</td>\n      <td>animals,elections</td>\n      <td>aclu-florida</td>\n      <td></td>\n      <td>Florida</td>\n      <td>none</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[5, 1, 14, 2, 0, 4, 0, 0, 4, 8, 7, 5, 1, 0, 4,...</td>\n      <td>[10, 16, 5, 0, 7, 1, 7, 7, 1, 11, 14, 10, 16, ...</td>\n      <td>be large number shark attack florida than be c...</td>\n      <td>large number shark attack florida case voter f...</td>\n      <td>[1, 161, 133, 5206, 314, 84, 86, 1, 408, 212, ...</td>\n      <td>[126, 100, 5078, 257, 59, 344, 168, 482]</td>\n    </tr>\n    <tr>\n      <th>10236</th>\n      <td>10236</td>\n      <td>3408.json</td>\n      <td>mostly-true</td>\n      <td>Democrats have now become the party of the [At...</td>\n      <td>elections</td>\n      <td>alan-powell</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[8, 11, 3, 1, 14, 0, 4, 14, 14, 8, 10, 8, 0, 1...</td>\n      <td>[11, 3, 2, 16, 5, 7, 1, 5, 13, 11, 12, 11, 7, ...</td>\n      <td>democrats have now become party atlanta metro ...</td>\n      <td>democrats party atlanta metro area black</td>\n      <td>[157, 2, 52, 283, 213, 464, 1399, 653, 4, 389]</td>\n      <td>[122, 169, 397, 1298, 574, 325]</td>\n    </tr>\n    <tr>\n      <th>10237</th>\n      <td>10237</td>\n      <td>3959.json</td>\n      <td>half-true</td>\n      <td>Says an alternative to Social Security that op...</td>\n      <td>retirement,social-security</td>\n      <td>herman-cain</td>\n      <td></td>\n      <td>Georgia</td>\n      <td>republican</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>7</td>\n      <td>[1, 14, 0, 4, 8, 8, 5, 1, 4, 8, 8, 10, 8, 10, ...</td>\n      <td>[16, 5, 7, 1, 11, 11, 10, 16, 1, 11, 11, 12, 1...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>say alternative social security operate galves...</td>\n      <td>[3, 2024, 154, 110, 1205, 3983, 124, 38, 2, 42...</td>\n      <td>[1, 1919, 119, 80, 1110, 3862, 93, 26, 360, 52...</td>\n    </tr>\n    <tr>\n      <th>10238</th>\n      <td>10238</td>\n      <td>2253.json</td>\n      <td>false</td>\n      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n      <td>florida,foreign-policy</td>\n      <td>jeff-greene</td>\n      <td></td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>[4, 1, 14, 8, 2, 0, 14, 1, 0, 4, 8, 10]</td>\n      <td>[1, 16, 5, 11, 0, 7, 16, 16, 7, 1, 11, 12]</td>\n      <td>lift u.s. cuban embargo and allow travel cuba</td>\n      <td>lift u.s. cuban embargo allow travel cuba</td>\n      <td>[1604, 28, 13, 2857, 3115, 4, 153, 1391, 1473]</td>\n      <td>[1503, 19, 7, 2738, 2994, 118, 1290, 1374]</td>\n    </tr>\n    <tr>\n      <th>10239</th>\n      <td>10239</td>\n      <td>1155.json</td>\n      <td>pants-fire</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>health-care,veterans</td>\n      <td>michael-steele</td>\n      <td>chairman of the Republican National Committee</td>\n      <td>Maryland</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>20</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[14, 8, 4, 8, 8, 1, 14, 0, 3, 3, 1, 5, 0, 0, 4...</td>\n      <td>[5, 11, 1, 11, 11, 16, 5, 7, 2, 2, 16, 10, 7, ...</td>\n      <td>department veterans affairs have manual out th...</td>\n      <td>department veterans affairs manual tell vetera...</td>\n      <td>[216, 1429, 2087, 2, 5142, 826, 494, 327, 441,...</td>\n      <td>[172, 1331, 1980, 5014, 268, 374, 2717, 117, 1...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10240 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please initialize `Bidirectional` layer with a `tf.keras.layers.Layer` instance. Received: 100",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[99], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m statement_input \u001B[38;5;241m=\u001B[39m Input(shape\u001B[38;5;241m=\u001B[39mnum_steps, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint32\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmain_input\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m x \u001B[38;5;241m=\u001B[39m Embedding(vocab_length\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m,EMBED_DIM,weights\u001B[38;5;241m=\u001B[39m[embedding_matrix],input_length\u001B[38;5;241m=\u001B[39mnum_steps,trainable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)(statement_input)\n\u001B[1;32m---> 10\u001B[0m bilstm_word_input \u001B[38;5;241m=\u001B[39m \u001B[43mBidirectional\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlstm_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m(x)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# SPECIFY POS_DICT USED FOR POS EMBEDDING\u001B[39;00m\n\u001B[0;32m     13\u001B[0m pos_dict \u001B[38;5;241m=\u001B[39m pos_dict_custom\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py:117\u001B[0m, in \u001B[0;36mBidirectional.__init__\u001B[1;34m(self, layer, merge_mode, weights, backward_layer, **kwargs)\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    109\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    110\u001B[0m     layer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    115\u001B[0m ):\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer, Layer):\n\u001B[1;32m--> 117\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    118\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease initialize `Bidirectional` layer with a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    119\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.keras.layers.Layer` instance. Received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    120\u001B[0m         )\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m backward_layer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(backward_layer, Layer):\n\u001B[0;32m    122\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    123\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`backward_layer` need to be a `tf.keras.layers.Layer` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    124\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minstance. Received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackward_layer\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    125\u001B[0m         )\n",
      "\u001B[1;31mValueError\u001B[0m: Please initialize `Bidirectional` layer with a `tf.keras.layers.Layer` instance. Received: 100"
     ]
    }
   ],
   "source": [
    "model_bilstm = Sequential()\n",
    "model_bilstm.add(Embedding(vocab_length+1, hidden_size, input_length=num_steps))\n",
    "model_bilstm.add(Bidirectional(LSTM(hidden_size)))\n",
    "model_bilstm.add(Dense(6, activation='softmax'))\n",
    "# model_bilstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# statement embed bilstm\n",
    "statement_input = Input(shape=num_steps, dtype='int32', name='main_input')\n",
    "x = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=num_steps,trainable=False)(statement_input)\n",
    "bilstm_word_input = LSTM(lstm_size, dropout=0.2)(x)\n",
    "\n",
    "# SPECIFY POS_DICT USED FOR POS EMBEDDING\n",
    "pos_dict = pos_dict_custom\n",
    "# pos_embeddings = np.identity(len(set(pos_dict.values())), dtype=int)\n",
    "pos_embeddings = np.identity(max(pos_dict.values())+1, dtype=int)\n",
    "\n",
    "# pos embed bilstm\n",
    "pos_input = Input(shape=num_steps, dtype='int32', name='pos_input')\n",
    "x2 = Embedding(max(pos_dict.values())+1, max(pos_dict.values())+1, weights=[pos_embeddings], input_length=num_steps, trainable=False)(pos_input)\n",
    "# x2 = Embedding(len(set(pos_dict.values())), len(set(pos_dict.values())), weights=[pos_embeddings], input_length=num_steps, trainable=False)(pos_input)\n",
    "bilstm_pos_in = LSTM(lstm_size, dropout=0.2)(x2)\n",
    "\n",
    "# todo: DEP PARSE\n",
    "# # dep embed LSTM X3\n",
    "# dep_input = Input(shape=(num_steps,), dtype='int32', name='dep_input')\n",
    "# x3 = Embedding(max(dep_dict.values()), max(dep_dict.values()), weights=[dep_embeddings], input_length=num_steps, trainable=False)(dep_input)\n",
    "# lstm_in3 = LSTM(lstm_size, dropout=0.2)(x3)\n",
    "\n",
    "# meta data Dense layer\n",
    "# meta_input = Input(shape=(X_train_meta.shape[1],), name='aux_input')\n",
    "# x_meta = Dense(64, activation='relu')(meta_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, 50, 100)           960700    \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 200)              160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 1206      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,122,706\n",
      "Trainable params: 1,122,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, 20, 100)           960700    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 200)              160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 1206      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,122,706\n",
      "Trainable params: 1,122,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(max(pos_dict.values()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def concat_lstm_layers(bilstm_input, layers_to_concat):\n",
    "    layers = [bilstm_input] + layers_to_concat\n",
    "    x = keras.layers.concatenate(layers)\n",
    "    return x\n",
    "\n",
    "\n",
    "# extra_layers_for_pos_dep_meta = [bilstm_pos_in, bilstm_dep_in, x_meta]\n",
    "\n",
    "#, lstm_in3, x_meta]\n",
    "# exp1_layers = [bilstm_pos_in, lstm_in3, x_meta]\n",
    "# exp2_layers = [bilstm_pos_in, x_meta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# model_lstm = Model(inputs=[statement_input, pos_input, dep_input, meta_input], outputs=[main_output])\n",
    "# model_lstm = Model(inputs=[statement_input, pos_input, meta_input], outputs=[main_output])\n",
    "# model_lstm = Model(inputs=[statement_input, dep_input, meta_input], outputs=[main_output])\n",
    "# model_lstm = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "\n",
    "extra_layers_for_pos = [bilstm_pos_in]\n",
    "# extra_layers_for_pos_meta = [bilstm_pos_in, x_meta]\n",
    "# extra_layeres_for_pos_dep_meta = [bilstm_pos_in, bi_lstm_dep_in, x_meta]\n",
    "\n",
    "x = concat_lstm_layers(bilstm_word_input, extra_layers_for_pos)\n",
    "main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "\n",
    "experiment1input = [statement_input, pos_input]\n",
    "# experiment2input = [statement_input, pos_input, meta_input]\n",
    "# experiment3input = [statement_input, pos_input, meta_input, dep_input]\n",
    "\n",
    "model_bilstm = Model(inputs=experiment1input, outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_36 (Embedding)       (None, 50, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_37 (Embedding)       (None, 50, 15)       225         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_32 (LSTM)                 (None, 100)          80400       ['embedding_36[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_33 (LSTM)                 (None, 100)          46400       ['embedding_37[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 200)          0           ['lstm_32[0][0]',                \n",
      "                                                                  'lstm_33[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,088,931\n",
      "Trainable params: 128,006\n",
      "Non-trainable params: 960,925\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_25 (Embedding)       (None, 50, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_26 (Embedding)       (None, 50, 14)       196         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 (None, 100)          80400       ['embedding_25[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)                 (None, 100)          46000       ['embedding_26[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 200)          0           ['lstm_22[0][0]',                \n",
      "                                                                  'lstm_23[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,088,502\n",
      "Trainable params: 127,606\n",
      "Non-trainable params: 960,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_22 (Embedding)       (None, 20, 100)      960700      ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_23 (Embedding)       (None, 20, 14)       196         ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_19 (LSTM)                 (None, 100)          80400       ['embedding_22[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_20 (LSTM)                 (None, 100)          46000       ['embedding_23[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 200)          0           ['lstm_19[0][0]',                \n",
      "                                                                  'lstm_20[0][0]']                \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 6)            1206        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,088,502\n",
      "Trainable params: 127,606\n",
      "Non-trainable params: 960,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrixes: (9607, 100)\n",
      "Length of the vocabulary dictionary: 9606\n",
      "X_train_custom shape: (10240, 50)\n",
      "X_val_custom shape: (1284, 50)\n"
     ]
    }
   ],
   "source": [
    "vocab_length = len(vocabulary_dict_custom)\n",
    "\n",
    "print(\"Shape of the embedding matrixes:\", embedding_matrix_custom_100d.shape)\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length)\n",
    "print(\"X_train_custom shape:\", X_train_custom.shape)\n",
    "print(\"X_val_custom shape:\", X_val_custom.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrixes: (9607, 100)\n",
      "Length of the vocabulary dictionary: 9606\n",
      "X_train_custom shape: (10240, 14)\n",
      "X_val_custom shape: (1284, 14)\n"
     ]
    }
   ],
   "source": [
    "vocab_length = len(vocabulary_dict_custom)\n",
    "\n",
    "print(\"Shape of the embedding matrixes:\", embedding_matrix_custom_100d.shape)\n",
    "print(\"Length of the vocabulary dictionary:\", vocab_length)\n",
    "print(\"X_train_custom shape:\", X_train_custom.shape)\n",
    "print(\"X_val_custom shape:\", X_val_custom.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max index in X_train_custom: 9606\n",
      "Max index in X_val_custom: 9545\n"
     ]
    }
   ],
   "source": [
    "print(\"Max index in X_train_custom:\", np.max(X_train_custom))\n",
    "print(\"Max index in X_val_custom:\", np.max(X_val_custom))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "word_index = {word: i+1 for i, word in enumerate(vocabulary_dict_custom)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austin be burden fast grow tax increase major city nation     \n",
      "say have organization parade be social welfare organization and then be involve political combat back\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(sequence, index_to_word):\n",
    "    return \" \".join([index_to_word.get(idx, \"\") for idx in sequence])\n",
    "\n",
    "index_to_word = {i: word for word, i in word_index.items()}\n",
    "\n",
    "# Print a decoded sample from X_train_custom\n",
    "sample_idx = 89  # You can change this to any valid index\n",
    "print(decode_sequence(X_train_custom[sample_idx], index_to_word))\n",
    "\n",
    "# Print a decoded sample from X_val_custom\n",
    "sample_idx = 2  # You can change this to any valid index\n",
    "print(decode_sequence(X_val_custom[sample_idx], index_to_word))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6486 - categorical_accuracy: 0.2455\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.22274, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 13s 32ms/step - loss: 1.6485 - categorical_accuracy: 0.2452 - val_loss: 1.6248 - val_categorical_accuracy: 0.2227\n",
      "Epoch 2/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6100 - categorical_accuracy: 0.2455\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6101 - categorical_accuracy: 0.2452 - val_loss: 1.6167 - val_categorical_accuracy: 0.2220\n",
      "Epoch 3/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6063 - categorical_accuracy: 0.2454\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6062 - categorical_accuracy: 0.2455 - val_loss: 1.6155 - val_categorical_accuracy: 0.2204\n",
      "Epoch 4/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6053 - categorical_accuracy: 0.2455\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6052 - categorical_accuracy: 0.2456 - val_loss: 1.6216 - val_categorical_accuracy: 0.2220\n",
      "Epoch 5/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6042 - categorical_accuracy: 0.2453\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 9s 33ms/step - loss: 1.6042 - categorical_accuracy: 0.2451 - val_loss: 1.6105 - val_categorical_accuracy: 0.2204\n",
      "Epoch 6/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6040 - categorical_accuracy: 0.2457\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 33ms/step - loss: 1.6040 - categorical_accuracy: 0.2457 - val_loss: 1.6111 - val_categorical_accuracy: 0.2220\n",
      "Epoch 7/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2421\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6031 - categorical_accuracy: 0.2420 - val_loss: 1.6142 - val_categorical_accuracy: 0.2220\n",
      "Epoch 8/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6036 - categorical_accuracy: 0.2448\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6038 - categorical_accuracy: 0.2445 - val_loss: 1.6176 - val_categorical_accuracy: 0.2227\n",
      "Epoch 9/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2424\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6031 - categorical_accuracy: 0.2424 - val_loss: 1.6116 - val_categorical_accuracy: 0.2220\n",
      "Epoch 10/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6029 - categorical_accuracy: 0.2450\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 1.6029 - categorical_accuracy: 0.2453 - val_loss: 1.6186 - val_categorical_accuracy: 0.1931\n",
      "Epoch 11/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6030 - categorical_accuracy: 0.2413\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6030 - categorical_accuracy: 0.2412 - val_loss: 1.6145 - val_categorical_accuracy: 0.2220\n",
      "Epoch 12/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2455\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6032 - categorical_accuracy: 0.2453 - val_loss: 1.6112 - val_categorical_accuracy: 0.2212\n",
      "Epoch 13/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6032 - categorical_accuracy: 0.2437\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6032 - categorical_accuracy: 0.2435 - val_loss: 1.6109 - val_categorical_accuracy: 0.2220\n",
      "Epoch 14/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.2421\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.6029 - categorical_accuracy: 0.2420 - val_loss: 1.6158 - val_categorical_accuracy: 0.2220\n",
      "Epoch 15/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.2448\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6025 - categorical_accuracy: 0.2449 - val_loss: 1.6200 - val_categorical_accuracy: 0.2220\n",
      "Epoch 16/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.2445\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 29ms/step - loss: 1.6029 - categorical_accuracy: 0.2442 - val_loss: 1.6155 - val_categorical_accuracy: 0.2212\n",
      "Epoch 17/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.2437\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.22274\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6026 - categorical_accuracy: 0.2439 - val_loss: 1.6164 - val_categorical_accuracy: 0.2220\n",
      "Epoch 18/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6031 - categorical_accuracy: 0.2448\n",
      "Epoch 18: val_categorical_accuracy improved from 0.22274 to 0.22352, saving model to bilstm_weights_best.hdf5\n",
      "256/256 [==============================] - 8s 29ms/step - loss: 1.6032 - categorical_accuracy: 0.2444 - val_loss: 1.6090 - val_categorical_accuracy: 0.2235\n",
      "Epoch 19/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6027 - categorical_accuracy: 0.2438\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6026 - categorical_accuracy: 0.2438 - val_loss: 1.6143 - val_categorical_accuracy: 0.2227\n",
      "Epoch 20/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6021 - categorical_accuracy: 0.2440\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6022 - categorical_accuracy: 0.2438 - val_loss: 1.6101 - val_categorical_accuracy: 0.2227\n",
      "Epoch 21/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6025 - categorical_accuracy: 0.2450\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6024 - categorical_accuracy: 0.2452 - val_loss: 1.6114 - val_categorical_accuracy: 0.2227\n",
      "Epoch 22/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.2442\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6028 - categorical_accuracy: 0.2443 - val_loss: 1.6096 - val_categorical_accuracy: 0.2235\n",
      "Epoch 23/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6025 - categorical_accuracy: 0.2439\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.6022 - categorical_accuracy: 0.2443 - val_loss: 1.6181 - val_categorical_accuracy: 0.2220\n",
      "Epoch 24/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6026 - categorical_accuracy: 0.2448\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6025 - categorical_accuracy: 0.2450 - val_loss: 1.6135 - val_categorical_accuracy: 0.2220\n",
      "Epoch 25/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6023 - categorical_accuracy: 0.2440\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6024 - categorical_accuracy: 0.2438 - val_loss: 1.6115 - val_categorical_accuracy: 0.2220\n",
      "Epoch 26/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6026 - categorical_accuracy: 0.2463\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6026 - categorical_accuracy: 0.2460 - val_loss: 1.6100 - val_categorical_accuracy: 0.2227\n",
      "Epoch 27/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6018 - categorical_accuracy: 0.2451\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6017 - categorical_accuracy: 0.2450 - val_loss: 1.6154 - val_categorical_accuracy: 0.1931\n",
      "Epoch 28/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6021 - categorical_accuracy: 0.2442\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6022 - categorical_accuracy: 0.2438 - val_loss: 1.6094 - val_categorical_accuracy: 0.2227\n",
      "Epoch 29/30\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.6015 - categorical_accuracy: 0.2446\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 1.6013 - categorical_accuracy: 0.2448 - val_loss: 1.6119 - val_categorical_accuracy: 0.2227\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 1.6012 - categorical_accuracy: 0.2484\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.22352\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.6012 - categorical_accuracy: 0.2484 - val_loss: 1.6109 - val_categorical_accuracy: 0.2227\n"
     ]
    }
   ],
   "source": [
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"pos_input\". You passed a data dictionary with keys ['main_input']. Expected the following keys: ['main_input', 'pos_input']\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[79], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m### TEST 4: remove pos from equation completely\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m     \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[65], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, train_inputs, val_inputs)\u001B[0m\n\u001B[0;32m     10\u001B[0m compile_model(model)\n\u001B[0;32m     11\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m create_callbacks(name)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filev7lylc5j.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"pos_input\". You passed a data dictionary with keys ['main_input']. Expected the following keys: ['main_input', 'pos_input']\n"
     ]
    }
   ],
   "source": [
    "### TEST 4: remove pos from equation completely\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom},\n",
    "      {'main_input': X_val_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/embedding_14/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\3575741395.py\", line 2, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_14/embedding_lookup'\nindices[3,1] = 15 is not in [0, 15)\n\t [[{{node model_1/embedding_14/embedding_lookup}}]] [Op:__inference_train_function_17062]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m### TEST 3: attempting to fix test 2:\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_pos_custom\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m     \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[65], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, train_inputs, val_inputs)\u001B[0m\n\u001B[0;32m     10\u001B[0m compile_model(model)\n\u001B[0;32m     11\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m create_callbacks(name)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'model_1/embedding_14/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\3575741395.py\", line 2, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_14/embedding_lookup'\nindices[3,1] = 15 is not in [0, 15)\n\t [[{{node model_1/embedding_14/embedding_lookup}}]] [Op:__inference_train_function_17062]"
     ]
    }
   ],
   "source": [
    "### TEST 3: attempting to fix test 2:\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\2186106441.py\", line 1, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding_2/embedding_lookup'\nindices[0,3] = 14 is not in [0, 14)\n\t [[{{node model/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_5950]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_pos_custom\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m     \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[65], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, train_inputs, val_inputs)\u001B[0m\n\u001B[0;32m     10\u001B[0m compile_model(model)\n\u001B[0;32m     11\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m create_callbacks(name)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'model/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\2186106441.py\", line 1, in <module>\n      train(model_bilstm,\n    File \"C:\\Users\\fatha\\AppData\\Local\\Temp\\ipykernel_4516\\995398677.py\", line 13, in train\n      model.fit(\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding_2/embedding_lookup'\nindices[0,3] = 14 is not in [0, 14)\n\t [[{{node model/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_5950]"
     ]
    }
   ],
   "source": [
    "## TEST 2: ERROR = size of pos embeddings\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom}\n",
    "     )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatha\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 10240, 10240, 1284, 1284\n  y sizes: 10240\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bilstm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbilstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m      \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m\t      \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_custom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpos_input\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val_pos_custom\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[15], line 54\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, name, *args, **kwargs)\u001B[0m\n\u001B[0;32m     51\u001B[0m inputs \u001B[38;5;241m=\u001B[39m merge_dicts(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     52\u001B[0m validation_inputs \u001B[38;5;241m=\u001B[39m merge_dicts(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 54\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidation_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmain_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\fyp\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001B[0m, in \u001B[0;36m_check_data_cardinality\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m   1844\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m sizes: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1845\u001B[0m         label,\n\u001B[0;32m   1846\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m   1847\u001B[0m             \u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(single_data)\n\u001B[0;32m   1848\u001B[0m         ),\n\u001B[0;32m   1849\u001B[0m     )\n\u001B[0;32m   1850\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMake sure all arrays contain the same number of samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1851\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[1;31mValueError\u001B[0m: Data cardinality is ambiguous:\n  x sizes: 10240, 10240, 1284, 1284\n  y sizes: 10240\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      validation_data=(\n",
    "\t      {'main_input': X_val_custom, 'pos_input': X_val_pos_custom},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_custom,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 2\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_custom},\n",
    "      validation_data=(\n",
    "\t      {'main_input': X_val_spacy, 'pos_input': X_val_pos_custom},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_custom,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 3\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_DEFAULT},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_custom, 'pos_input': X_val_pos_DEFAULT},\n",
    "      )\n",
    "      )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 4\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_DEFAULT},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_spacy, 'pos_input': X_val_pos_DEFAULT},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# CONFIG 5\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_custom},\n",
    "      {'aux_input': X_train_meta},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_custom, 'pos_input': X_val_pos_custom},\n",
    "          {'aux_input': X_val_meta},\n",
    "      )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m (fw, tb) \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbilstm\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      2\u001B[0m                     X_test_custom,\n\u001B[0;32m      3\u001B[0m                     X_test_pos_custom,\n\u001B[0;32m      4\u001B[0m                     X_test_meta,\n\u001B[0;32m      5\u001B[0m                     \u001B[38;5;66;03m# X_test_dep,\u001B[39;00m\n\u001B[0;32m      6\u001B[0m                     )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_custom,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### CONFIG 6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 6\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_custom},\n",
    "      {'aux_input': X_train_meta},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_spacy, 'pos_input': X_val_pos_custom},\n",
    "          {'aux_input': X_val_meta},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_custom,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CONFIG 7\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 7\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_custom, 'pos_input': X_train_pos_DEFAULT},\n",
    "      {'aux_input': X_train_meta},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_custom, 'pos_input': X_val_pos_DEFAULT},\n",
    "          {'aux_input': X_val_meta},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_custom,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONFIG 8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG 8\n",
    "train(model_bilstm,\n",
    "      'bilstm',\n",
    "      {'main_input': X_train_spacy, 'pos_input': X_train_pos_DEFAULT},\n",
    "      {'aux_input': X_train_meta},\n",
    "      validation_data=(\n",
    "          {'main_input': X_val_spacy, 'pos_input': X_val_pos_DEFAULT},\n",
    "          {'aux_input': X_val_meta},\n",
    "      )\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fw, tb) = evaluate('bilstm',\n",
    "                    X_test_spacy,\n",
    "                    X_test_pos_DEFAULT,\n",
    "                    X_test_meta,\n",
    "                    # X_test_dep,\n",
    "                    )\n",
    "print_best_false_true_predicted(fw, tb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# train(model, name, {'main_input': X_train, 'pos_input': X_train_pos}, {'aux_input': X_train_meta})\n",
    "# train(model, name, main_input=X_train, pos_input=X_train_pos, aux_input=X_train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def train(model, name, use_pos=False, use_meta=False, use_dep=False):\n",
    "#     sgd = optimizers.SGD(lr=0.025, clipvalue=0.3, nesterov=True)\n",
    "#     adam = optimizers.Adam(lr=0.000075, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#     model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     tb = TensorBoard()\n",
    "#     csv_logger = ker\n",
    "#     as.callbacks.CSVLogger('training.log')\n",
    "#     filepath = name + \"_weights_best.hdf5\"\n",
    "#     checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#\n",
    "#     if use_pos and use_meta:\n",
    "#         if use_dep:\n",
    "#             model.fit(\n",
    "#                 {'main_input': X_train, 'pos_input': X_train_pos, 'aux_input': X_train_meta, 'dep_input': X_train_dep},\n",
    "#                 {'main_output': Y_train},\n",
    "#                 epochs=num_epochs,\n",
    "#                 batch_size=batch_size,\n",
    "#                 validation_data=(\n",
    "#                     {'main_input': X_val, 'pos_input': X_val_pos, 'aux_input': X_val_meta, 'dep_input': X_val_dep},\n",
    "#                     {'main_output': Y_val}),\n",
    "#                 callbacks=[tb, csv_logger, checkpoint])\n",
    "#         else:\n",
    "#             model.fit(\n",
    "#                 {'main_input': X_train, 'pos_input': X_train_pos, 'aux_input': X_train_meta},\n",
    "#                 {'main_output': Y_train},\n",
    "#                 epochs=num_epochs,\n",
    "#                 batch_size=batch_size,\n",
    "#                 validation_data=(\n",
    "#                     {'main_input': X_val, 'pos_input': X_val_pos, 'aux_input': X_val_meta},\n",
    "#                     {'main_output': Y_val}),\n",
    "#                 callbacks=[tb, csv_logger, checkpoint])\n",
    "#     elif use_meta:\n",
    "#         if use_dep:\n",
    "#             model.fit(\n",
    "#                 {'main_input': X_train, 'aux_input': X_train_meta, 'dep_input': X_train_dep},\n",
    "#                 {'main_output': Y_train},\n",
    "#                 epochs=num_epochs,\n",
    "#                 batch_size=batch_size,\n",
    "#                 validation_data=(\n",
    "#                     {'main_input': X_val, 'aux_input': X_val_meta, 'dep_input': X_val_dep},\n",
    "#                     {'main_output': Y_val}),\n",
    "#                 callbacks=[tb, csv_logger, checkpoint])\n",
    "#         else:\n",
    "#             model.fit(\n",
    "#                 {'main_input': X_train, 'aux_input': X_train_meta},\n",
    "#                 {'main_output': Y_train},\n",
    "#                 epochs=num_epochs,\n",
    "#                 batch_size=batch_size,\n",
    "#                 validation_data=(\n",
    "#                     {'main_input': X_val, 'aux_input': X_val_meta},\n",
    "#                     {'main_output': Y_val}),\n",
    "#                 callbacks=[tb, csv_logger, checkpoint])\n",
    "#     elif use_pos:\n",
    "#         if use_dep:\n",
    "#             model.fit(\n",
    "#                 {'main_input': X_train, 'pos_input': X_train_pos, 'dep_input': X_train_dep},\n",
    "#                 {'main_output': Y_train},\n",
    "#                 epochs=num_epochs,\n",
    "#                 batch_size=batch_size,\n",
    "#                 validation_data=(\n",
    "#                     {'main_input': X_val, 'pos_input': X_val_pos, 'dep_input': X_val_dep},\n",
    "#                     {'main_output': Y_val}),\n",
    "#                 callbacks=[tb, csv_logger, checkpoint])\n",
    "#         else:\n",
    "#             model.fit(\n",
    "#                 {'main_input': X_train, 'pos_input': X_train_pos},\n",
    "#                 {'main_output': Y_train},\n",
    "#                 epochs=num_epochs,\n",
    "#                 batch_size=batch_size,\n",
    "#                 validation_data=(\n",
    "#                     {'main_input': X_val, 'pos_input': X_val_pos},\n",
    "#                     {'main_output': Y_val}),\n",
    "#                 callbacks=[tb, csv_logger, checkpoint])\n",
    "#     else:\n",
    "#         if use_dep:\n",
    "#             model.fit(\n",
    "#             {'main_input': X_train,'dep_input':X_train_dep},\n",
    "#             {'main_output': Y_train}, epochs = num_epochs, batch_size = batch_size,\n",
    "#             validation_data = (\n",
    "#                                 {'main_input': X_val, 'dep_input':X_val_dep},\n",
    "#                                 {'main_output': Y_val}\n",
    "#                                 ), callbacks=[tb,csv_logger,checkpoint])\n",
    "#     else:\n",
    "#       model.fit(\n",
    "#         {'main_input': X_train},\n",
    "#         {'main_output': Y_train}, epochs = num_epochs, batch_size = batch_size,\n",
    "#         validation_data = (\n",
    "#             {'main_input': X_val},\n",
    "#             {'main_output': Y_val}\n",
    "#         ), callbacks=[tb,csv_logger,checkpoint])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# use_pos=False\n",
    "# use_meta=True\n",
    "# use_dep=True\n",
    "#\n",
    "# # LSTM model\n",
    "# model_lstm = Sequential()\n",
    "# model_lstm.add(Embedding(vocab_length+1, hidden_size, input_length=num_steps))\n",
    "# model_lstm.add(Bidirectional(LSTM(hidden_size)))\n",
    "# model_lstm.add(Dense(6, activation='softmax'))\n",
    "#\n",
    "#\n",
    "# # statement embed LSTM\n",
    "# statement_input = Input(shape=(num_steps,), dtype='int32', name='main_input')\n",
    "# x = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=num_steps,trainable=False)(statement_input)\n",
    "# lstm_in = LSTM(lstm_size,dropout=0.2)(x)\n",
    "#\n",
    "#\n",
    "#\n",
    "# # pos embed LSTM\n",
    "# pos_input = Input(shape=(num_steps,), dtype='int32', name='pos_input')\n",
    "# x2 = Embedding(max(pos_dict.values()), max(pos_dict.values()), weights=[pos_embeddings], input_length=num_steps, trainable=False)(pos_input)\n",
    "# lstm_in2 = LSTM(lstm_size, dropout=0.2)(x2)\n",
    "#\n",
    "#\n",
    "# # dep embed LSTM\n",
    "# dep_input = Input(shape=(num_steps,), dtype='int32', name='dep_input')\n",
    "# x3 = Embedding(max(dep_dict.values()), max(dep_dict.values()), weights=[dep_embeddings], input_length=num_steps, trainable=False)(dep_input)\n",
    "# lstm_in3 = LSTM(lstm_size, dropout=0.2)(x3)\n",
    "#\n",
    "#\n",
    "# # meta data Dense\n",
    "# meta_input = Input(shape=(X_train_meta.shape[1],), name='aux_input')\n",
    "# x_meta = Dense(64, activation='relu')(meta_input)\n",
    "#\n",
    "#\n",
    "# if use_pos and use_meta:\n",
    "#   if use_dep:\n",
    "#     x = keras.layers.concatenate([lstm_in, lstm_in2, lstm_in3, x_meta])\n",
    "#   else:\n",
    "#     x = keras.layers.concatenate([lstm_in, lstm_in2, x_meta])\n",
    "# elif use_meta:\n",
    "#   if use_dep:\n",
    "#     x = keras.layers.concatenate([lstm_in, lstm_in3, x_meta])\n",
    "#   else:\n",
    "#     x = keras.layers.concatenate([lstm_in, x_meta])\n",
    "# elif use_pos:\n",
    "#   if use_dep:\n",
    "#     x = keras.layers.concatenate([lstm_in, lstm_in3, lstm_in2])\n",
    "#   else:\n",
    "#     x = keras.layers.concatenate([lstm_in, lstm_in2])\n",
    "# else:\n",
    "#   if use_dep:\n",
    "#     x = keras.layers.concatenate([lstm_in, lstm_in3])\n",
    "#   else:\n",
    "#     x = lstm_in\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "#\n",
    "# if use_pos and use_meta:\n",
    "#   if use_dep:\n",
    "#     model_lstm = Model(inputs=[statement_input, pos_input, dep_input, meta_input], outputs=[main_output])\n",
    "#   else:\n",
    "#     model_lstm = Model(inputs=[statement_input, pos_input, meta_input], outputs=[main_output])\n",
    "# elif use_meta:\n",
    "#   if use_dep:\n",
    "#     model_lstm = Model(inputs=[statement_input, dep_input, meta_input], outputs=[main_output])\n",
    "#   else:\n",
    "#     model_lstm = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "# elif use_pos:\n",
    "#   if use_dep:\n",
    "#     model_lstm = Model(inputs=[statement_input, dep_input, pos_input], outputs=[main_output])\n",
    "#   else:\n",
    "#     model_lstm = Model(inputs=[statement_input, pos_input], outputs=[main_output])\n",
    "# else:\n",
    "#   if use_dep:\n",
    "#     model_lstm = Model(inputs=[statement_input, dep_input], outputs=[main_output])\n",
    "#   else:\n",
    "#     model_lstm = Model(inputs=[statement_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
